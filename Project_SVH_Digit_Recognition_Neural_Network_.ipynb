{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amikoshimrah/sothingshimrah/blob/main/Project_SVH_Digit_Recognition_Neural_Network_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXQuW3JcI0Cd"
      },
      "source": [
        "## Project -Neural Network\n",
        "#### Street View Housing Number Digit Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCTmShBpI0Ce"
      },
      "source": [
        "#### The Problem Description:\n",
        "Recognizing multi-digit numbers in photographs captured at street level is an important component of modernday map making. A classic example of a corpus of such street-level photographs is Googleâ€™s Street View\n",
        "imagery comprised of hundreds of millions of geo-located 360-degree panoramic images. The ability to\n",
        "automatically transcribe an address number from a geo-located patch of pixels and associate the transcribed\n",
        "number with a known street address helps pinpoint, with a high degree of accuracy, the location of the building\n",
        "it represents. More broadly, recognizing numbers in photographs is a problem of interest to the optical\n",
        "character recognition community. While OCR on constrained domains like document processing is well\n",
        "studied, arbitrary multi-character text recognition in photographs is still highly challenging. This difficulty arises\n",
        "due to the wide variability in the visual appearance of text in the wild on account of a large range of fonts,\n",
        "colours, styles, orientations, and character arrangements. The recognition problem is further complicated by\n",
        "environmental factors such as lighting, shadows, specularities, and occlusions as well as by image acquisition\n",
        "factors such as resolution, motion, and focus blurs. In this project, we will use the dataset with images centred\n",
        "around a single digit (many of the images do contain some distractors at the sides). Although we are taking a\n",
        "sample of the data which is simpler, it is more complex than MNIST because of the distractors.\n",
        "\n",
        "#### Dataset\n",
        "SVHN is a real-world image dataset for developing machine learning and object recognition algorithms with the\n",
        "minimal requirement on data formatting but comes from a significantly harder, unsolved, real-world problem\n",
        "(recognizing digits and numbers in natural scene images). SVHN is obtained from house numbers in Google\n",
        "Street View images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMMhj2s8I0Cf"
      },
      "source": [
        "#### Import Libraries and Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KfcuVrRNI0Cf",
        "outputId": "fdb3a13b-653a-4a24-cb72-5ed3ce972a30"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "execution_count": 1,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers, optimizers\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization,Activation,Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "import math\n",
        "import numpy as np\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(2)\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "# Ignore the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "O_HA7mcOI0Ci",
        "outputId": "898b3958-aca0-4b90-88d3-d6e70619c49c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Rl00rK3GI0Cl",
        "outputId": "5ebbfb89-080a-440f-880d-597a01c4e2c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<KeysViewHDF5 ['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']>"
            ]
          },
          "execution_count": 3,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import h5py\n",
        "#df = h5py.File('SVHN_single_grey1.h5','r')\n",
        "df = h5py.File('/content/drive/My Drive/SVHN_single_grey1.h5','r')\n",
        "df.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aF56QlMXI0Cn"
      },
      "source": [
        "### Getting details of dataset\n",
        "- We will see how many rows are there in the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "TI4ag27lI0Co",
        "outputId": "4ffb6c82-1109-40bf-d465-68b385f0e3dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X_train:(42000, 32, 32)\n",
            "Shape of y_train:(42000,)\n",
            "Shape of X_test:(18000, 32, 32)\n",
            "Shape of y_test:(18000,)\n"
          ]
        }
      ],
      "source": [
        "X_train = df['X_train'][:]\n",
        "y_train = df['y_train'][:]\n",
        "X_test = df['X_test'][:]\n",
        "y_test = df['y_test'][:]\n",
        "X_val = df['X_val'][:]\n",
        "y_val = df['y_val'][:]\n",
        "print(f'Shape of X_train:{X_train.shape}')\n",
        "print(f'Shape of y_train:{y_train.shape}')\n",
        "print(f'Shape of X_test:{X_test.shape}')\n",
        "print(f'Shape of y_test:{y_test.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DiZyI4xhI0Cq",
        "outputId": "f871e905-b716-41b0-a3fc-b6c4075dd8a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 7, 2, ..., 7, 9, 2], dtype=uint8)"
            ]
          },
          "execution_count": 5,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test.view()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFppY9xLI0Cs"
      },
      "source": [
        "### Visualize the data\n",
        "Plot first 10 images in the triaining set and their labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95
        },
        "id": "_wlX9ZqgI0Ct",
        "outputId": "6b94a884-543b-49cf-c5a2-bc89d8d343ae"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x72 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label for each of the above image: [2 6 7 4 4 0 3 0 7 3]\n"
          ]
        }
      ],
      "source": [
        "# visualizing the first 10 images in the dataset and their labels\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 1))\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i+1)\n",
        "    plt.imshow(X_train[i].reshape(32,32), cmap=\"gray\")\n",
        "    plt.axis('off')\n",
        "plt.show()\n",
        "print('label for each of the above image: %s' % (y_train[:10]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ftYY6C8I0Cw"
      },
      "source": [
        "## Data Pre-processing\n",
        "### 1. Reshape features\n",
        "- reshape() method gives a new shape to an array without changing its data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "gN6n_QQ6I0Cw",
        "outputId": "83f20bc0-797c-4674-947b-94fdba5b5acd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(42000, 1024, 1)\n",
            "(18000, 1024, 1)\n"
          ]
        }
      ],
      "source": [
        "X_train = X_train.reshape(X_train.shape[0],1024, 1)\n",
        "print(X_train.shape)\n",
        "X_test = X_test.reshape(X_test.shape[0],1024, 1)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-q-3TifXI0Cy"
      },
      "source": [
        "\n",
        "### 2. Normalize features\n",
        "- Normalize features from 0-255 to 0-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "_K6ViayoI0Cz",
        "outputId": "a3edd6db-1708-463d-c3ee-21028b5f0e0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "254.9745\n",
            "0.0\n",
            "0.9999\n",
            "0.0\n"
          ]
        }
      ],
      "source": [
        "print(X_train.max())\n",
        "print(X_train.min())\n",
        "\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "#X_train = tf.keras.utils.normalize(X_train,axis=1)\n",
        "#X_test = tf.keras.utils.normalize(X_test,axis=1)\n",
        "print(X_train.max())\n",
        "print(X_train.min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYgzFP3oI0C1"
      },
      "source": [
        "### 3. Convert both training and testing labels into one-hot vectors.\n",
        "- convert class vectors (integers) to binary class matrix\n",
        "- convert y_train and y_test\n",
        "- number of classes: 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "3bpDjsrcI0C1",
        "outputId": "3e95028d-ea44-4564-9d91-5dfa1907d7c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "print(y_train[10])\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "print(y_train[10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2KyJvHVI0C3"
      },
      "source": [
        "Expected output should look like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "qkZJZn2pI0C4",
        "outputId": "f85a41be-aef3-428d-9598-041149cc8354"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(42000, 10)\n",
            "  First 10 examples now are: \n",
            " [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "print(y_train.shape)\n",
        "print('  First 10 examples now are: \\n', y_train[0:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zqLxgxQI0C6"
      },
      "source": [
        "## Building Model with a cross entropy loss function and  optimizer in Keras\n",
        "## 1. Basic NN model for the output layer with 10 neurons as we have 10 classes.\n",
        "\n",
        "Naive MLP model without any alterations\n",
        "\n",
        "Let's build vanilla model activation as sigmoid and optimizer as adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ob4vMZG1I0C6"
      },
      "outputs": [],
      "source": [
        "np.random.seed(1)\n",
        "tf.random.set_seed(2)\n",
        "#Initialize sequenial model\n",
        "model = Sequential()\n",
        "#Add Dense Layer which provides hidden neurons\n",
        "model.add(Flatten(input_shape=X_train[0].shape))\n",
        "model.add(Dense(256,activation ='sigmoid'))\n",
        "model.add(Dense(128,activation ='sigmoid'))\n",
        "model.add(Dense(64,activation ='sigmoid'))\n",
        "model.add(Dense(32,activation ='sigmoid'))\n",
        "#Add Dense layer which provides 10 outputs after applying softmax\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "adam = optimizers.Adam()\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=128, verbose= 0);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "AT7-cAEHI0C8",
        "outputId": "f2cf18fe-0774-4f07-c50b-5268875c5018"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Train</th>\n",
              "      <td>0.595542</td>\n",
              "      <td>0.812500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Test</th>\n",
              "      <td>0.737677</td>\n",
              "      <td>0.774222</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Loss  Accuracy\n",
              "Train  0.595542  0.812500\n",
              "Test   0.737677  0.774222"
            ]
          },
          "execution_count": 13,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Check the final out come of the model\n",
        "train = model.evaluate(X_train, y_train, verbose=0)\n",
        "test = model.evaluate(X_test, y_test, verbose=0)\n",
        "results = pd.DataFrame({'Train':train,'Test':test}).T\n",
        "results.columns=['Loss','Accuracy']\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giKxq5xeI0C_"
      },
      "source": [
        "#### We saw the good accuracy  .\n",
        "lets try other advance technique as well"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwd3jr4eI0C_"
      },
      "source": [
        "## 2. Advanced techniques for training neural networks\n",
        "### Let's try out all the techniques\n",
        "### 2.1. Weight Initialization\n",
        "Changing weight initialization scheme can significantly improve training of the model by preventing vanishing gradient problem up to some degree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8nnVvacI0DA"
      },
      "outputs": [],
      "source": [
        "np.random.seed(1)\n",
        "tf.random.set_seed(2)\n",
        "#Initialize sequenial model\n",
        "model = Sequential()\n",
        "#Add Dense Layer which provides hidden neurons\n",
        "model.add(Flatten(input_shape=X_train[0].shape))\n",
        "model.add(Dense(256,activation ='sigmoid',kernel_initializer='he_normal')) # Weight initialization with He_normal\n",
        "model.add(Dense(128,activation ='sigmoid',kernel_initializer='he_normal'))\n",
        "model.add(Dense(64,activation ='sigmoid',kernel_initializer='he_normal'))\n",
        "model.add(Dense(32,activation ='sigmoid',kernel_initializer='he_normal'))\n",
        "#Add Dense layer which provides 10 outputs after applying softmax\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "adam = optimizers.Adam()\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=128, verbose= 0);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "MnK5bD2EI0DC",
        "outputId": "c80c26ed-93ac-4640-8cb5-2bba966b1461"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Train</th>\n",
              "      <td>0.596405</td>\n",
              "      <td>0.809405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Test</th>\n",
              "      <td>0.754721</td>\n",
              "      <td>0.767056</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Loss  Accuracy\n",
              "Train  0.596405  0.809405\n",
              "Test   0.754721  0.767056"
            ]
          },
          "execution_count": 15,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Check the final out come of the model\n",
        "train = model.evaluate(X_train, y_train, verbose=0)\n",
        "test = model.evaluate(X_test, y_test, verbose=0)\n",
        "results = pd.DataFrame({'Train':train,'Test':test}).T\n",
        "results.columns=['Loss','Accuracy']\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcLmdyHcI0DE"
      },
      "source": [
        "There is slight decline after Weight initialisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yoyPPXTI0DE"
      },
      "source": [
        "### 2.2. Nonlinearity (Activation function)\n",
        "\n",
        "Sigmoid functions suffer from gradient vanishing problem, making training slower\n",
        "\n",
        "There are many choices apart from sigmoid and tanh.'relu' (rectified linear unit) is one of the most popular ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSO705mCI0DF"
      },
      "outputs": [],
      "source": [
        "np.random.seed(1)\n",
        "tf.random.set_seed(2)\n",
        "#Initialize sequenial model\n",
        "model = Sequential()\n",
        "#Add Dense Layer which provides hidden neurons\n",
        "model.add(Flatten(input_shape=X_train[0].shape))\n",
        "model.add(Dense(256,activation ='relu',kernel_initializer='he_normal'))\n",
        "model.add(Dense(128,activation ='relu',kernel_initializer='he_normal'))\n",
        "model.add(Dense(64,activation ='relu',kernel_initializer='he_normal'))\n",
        "model.add(Dense(32,activation ='relu',kernel_initializer='he_normal'))\n",
        "#Add Dense layer which provides 10 outputs after applying softmax\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "adam = optimizers.Adam()\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=128, verbose= 0);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "gdYNcXW1I0DH",
        "outputId": "723e5a10-3642-4bd0-d77e-3be48a75b5ed"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Train</th>\n",
              "      <td>0.408672</td>\n",
              "      <td>0.869619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Test</th>\n",
              "      <td>0.673165</td>\n",
              "      <td>0.810944</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Loss  Accuracy\n",
              "Train  0.408672  0.869619\n",
              "Test   0.673165  0.810944"
            ]
          },
          "execution_count": 17,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Check the final out come of the model\n",
        "train = model.evaluate(X_train, y_train, verbose=0)\n",
        "test = model.evaluate(X_test, y_test, verbose=0)\n",
        "results = pd.DataFrame({'Train':train,'Test':test}).T\n",
        "results.columns=['Loss','Accuracy']\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCViMDYiI0DK"
      },
      "source": [
        "#### Accuracy is improve after activation changed to relu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQt0kh3YI0DK"
      },
      "source": [
        "### 2.3.  Batch Normalization\n",
        "Batch Normalization, one of the methods to prevent the \"internal covariance shift\" problem, has proven to be highly effective\n",
        "\n",
        "Normalize each mini-batch before nonlinearity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cRJmLtdI0DK"
      },
      "outputs": [],
      "source": [
        "np.random.seed(1)\n",
        "tf.random.set_seed(2)\n",
        "#Initialize sequenial model\n",
        "model = Sequential()\n",
        "#Add Dense Layer which provides hidden neurons\n",
        "model.add(Flatten(input_shape=X_train[0].shape))\n",
        "model.add(Dense(256,activation ='relu',kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(128,activation ='relu',kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(64,activation ='relu',kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(32,activation ='relu',kernel_initializer='he_normal'))\n",
        "#Add Dense layer which provides 10 outputs after applying softmax\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "adam = optimizers.Adam()\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=128, verbose= 0);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "oJX5JWd4I0DM",
        "outputId": "a5d15ae5-468e-42fd-b061-98acfcc9369e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Train</th>\n",
              "      <td>0.593493</td>\n",
              "      <td>0.81381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Test</th>\n",
              "      <td>0.844679</td>\n",
              "      <td>0.76500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Loss  Accuracy\n",
              "Train  0.593493   0.81381\n",
              "Test   0.844679   0.76500"
            ]
          },
          "execution_count": 19,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Check the final out come of the model\n",
        "train = model.evaluate(X_train, y_train, verbose=0)\n",
        "test = model.evaluate(X_test, y_test, verbose=0)\n",
        "results = pd.DataFrame({'Train':train,'Test':test}).T\n",
        "results.columns=['Loss','Accuracy']\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPqlfm1TI0DO"
      },
      "source": [
        "### 2.4. Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8fpNRUfI0DP"
      },
      "outputs": [],
      "source": [
        "np.random.seed(1)\n",
        "tf.random.set_seed(2)\n",
        "#Initialize sequenial model\n",
        "model = Sequential()\n",
        "#Add Dense Layer which provides hidden neurons\n",
        "model.add(Flatten(input_shape=X_train[0].shape))\n",
        "model.add(Dense(256,activation ='relu',kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(128,activation ='relu',kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(64,activation ='relu',kernel_initializer='he_normal'))\n",
        "model.add(Dense(32,activation ='relu',kernel_initializer='he_normal'))\n",
        "#Add Dense layer which provides 10 outputs after applying softmax\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "adam = optimizers.Adam()\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=128,verbose= 0);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "ZWuPOSbnI0DR",
        "outputId": "cdb445cb-8744-41f7-b5e1-4ba37ad6e9d9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Train</th>\n",
              "      <td>0.545705</td>\n",
              "      <td>0.828238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Test</th>\n",
              "      <td>0.661044</td>\n",
              "      <td>0.795889</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Loss  Accuracy\n",
              "Train  0.545705  0.828238\n",
              "Test   0.661044  0.795889"
            ]
          },
          "execution_count": 21,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Check the final out come of the model\n",
        "train = model.evaluate(X_train, y_train, verbose=0)\n",
        "test = model.evaluate(X_test, y_test, verbose=0)\n",
        "results = pd.DataFrame({'Train':train,'Test':test}).T\n",
        "results.columns=['Loss','Accuracy']\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPGvDrckI0DT"
      },
      "source": [
        "## 3. Hyper Parameter Tuning\n",
        "- We saw that 2.2. Nonlinearity (Activation function) has good accuracy. I would like the perform the the hyper parameter tuning\n",
        "\n",
        "### Creating model 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vBno4zMI0DU"
      },
      "outputs": [],
      "source": [
        "def model_nn(iterations,lr,Lambda, verb=True):\n",
        "    np.random.seed(1)\n",
        "    tf.random.set_seed(2)\n",
        "    ## hyperparameters\n",
        "    iterations = iterations\n",
        "    learning_rate = lr\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=X_train[0].shape))\n",
        "    model.add(Dense(256, kernel_initializer='he_uniform', activation='relu')) ###Multiple Dense units with Relu activation\n",
        "    model.add(Dense(256, kernel_initializer='he_uniform',activation='relu'))\n",
        "    model.add(Dense(64, kernel_initializer='he_uniform',activation='relu'))\n",
        "    model.add(Dense(32, kernel_initializer='he_uniform',activation='relu'))\n",
        "    model.add(Dense(10, activation='softmax',kernel_regularizer=regularizers.l2(Lambda)))\n",
        "\n",
        "    # Compile model\n",
        "    adam = optimizers.Adam(lr=learning_rate, decay=1e-6)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4V41zfGI0DW"
      },
      "source": [
        "### Creating model 2\n",
        "- Same model as above\n",
        "- Instead of accuracy at each epoch below code gives the consolidate accuracy\n",
        "- Notice: The model.evaluate line at the last is the only difference from model 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yzgg70pvI0DW"
      },
      "outputs": [],
      "source": [
        "def train_and_test_loop1(iterations, lr,Lambda, verb=True):\n",
        "\n",
        "    ## hyperparameters\n",
        "    iterations = iterations\n",
        "    learning_rate = lr\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=X_train[0].shape))\n",
        "    model.add(Dense(256, kernel_initializer='he_normal', activation='relu')) ###Multiple Dense units with Relu activation\n",
        "    model.add(Dense(128, kernel_initializer='he_normal',activation='relu'))\n",
        "    model.add(Dense(64, kernel_initializer='he_normal',activation='relu'))\n",
        "    model.add(Dense(32, kernel_initializer='he_normal',activation='relu'))\n",
        "    model.add(Dense(10, activation='softmax',kernel_regularizer=regularizers.l2(Lambda)))\n",
        "\n",
        "    # Compile model\n",
        "    adam = optimizers.Adam(lr=learning_rate, decay=1e-6)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "\n",
        "    model.fit(X_train, y_train, epochs=50, batch_size=128,validation_data=(X_test, y_test), verbose= 2)\n",
        "\n",
        "    score = model.evaluate(X_train, y_train)\n",
        "    return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYFDuK_aI0DZ"
      },
      "source": [
        "### Next steps\n",
        "- Double Check that the loss is reasonable\n",
        "- Disable the regularization (Lambda = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kRkRbDQJI0DZ",
        "outputId": "fc3a8301-0710-4b99-d420-ff0710f699e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "329/329 [==============================] - 2s 7ms/step - loss: 2.3119 - accuracy: 0.1196\n"
          ]
        }
      ],
      "source": [
        "lr = 0.00001\n",
        "Lambda = 0\n",
        "iterations = 1\n",
        "model = model_nn(iterations,lr,Lambda)\n",
        "model.fit(X_train, y_train, epochs = iterations,batch_size=128 , verbose = 1);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIrMiGWNI0Db"
      },
      "source": [
        "### Validation\n",
        "- There are 10 output classes and the model is correctly predicting 1 up on 10 times (1/10 = 0.1% approx) as it is untrained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_2mnM-xTI0Dc",
        "outputId": "97d0bc78-3825-40d9-dedb-e2b39716ea8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "329/329 [==============================] - 2s 7ms/step - loss: 34235803648.0000 - accuracy: 0.1006\n"
          ]
        }
      ],
      "source": [
        "lr = 1e1\n",
        "Lambda =1e-5\n",
        "iterations = 1\n",
        "model = model_nn(iterations,lr,Lambda)\n",
        "model.fit(X_train, y_train, epochs = iterations,batch_size=128 , verbose = 1);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-IILWIII0De"
      },
      "source": [
        "loss went up. Good! (Another sanity check)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4bRkeTOI0De"
      },
      "source": [
        "### Start with small regularization and find learning rate that makes the loss go down.\n",
        "\n",
        "- we start with Lambda(small regularization) = 1e-5\n",
        "- we start with a small learning rate = 1e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHbgoOGWI0De"
      },
      "outputs": [],
      "source": [
        "lr = 1e-5\n",
        "Lambda = 1e-5\n",
        "iterations = 20\n",
        "model = model_nn(iterations,lr,Lambda)\n",
        "model.fit(X_train, y_train, epochs = iterations,batch_size=128 ,verbose = 0);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "jYp5qjqWI0Dg",
        "outputId": "791b8d54-8e93-4861-b3fa-0f70a67d61af"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Train</th>\n",
              "      <td>1.589038</td>\n",
              "      <td>0.532643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Test</th>\n",
              "      <td>1.589882</td>\n",
              "      <td>0.535611</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Loss  Accuracy\n",
              "Train  1.589038  0.532643\n",
              "Test   1.589882  0.535611"
            ]
          },
          "execution_count": 27,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Check the final out come of the model\n",
        "train = model.evaluate(X_train, y_train, verbose=0)\n",
        "test = model.evaluate(X_test, y_test, verbose=0)\n",
        "results = pd.DataFrame({'Train':train,'Test':test}).T\n",
        "results.columns=['Loss','Accuracy']\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5GUrXR1I0Dj"
      },
      "source": [
        "### Loss barely changing. Learning rate is probably too low.\n",
        "### Okay now lets try a (larger) learning rate 1e5. What could possibly go wrong?\n",
        "\n",
        "- Learning rate lr = 1e5\n",
        "- Regularization lambda = 1e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KbulqVXI0Dj"
      },
      "outputs": [],
      "source": [
        "lr = 1e5\n",
        "Lambda = 1e-5\n",
        "iterations = 20\n",
        "model = model_nn(iterations,lr,Lambda)\n",
        "model.fit(X_train, y_train, epochs = iterations,batch_size=128 ,verbose = 0);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "uia2F4w0I0Dl",
        "outputId": "4ef5f2ab-34aa-4cce-c87b-e70444440766"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Train</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.099667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Test</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.100778</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Loss  Accuracy\n",
              "Train   NaN  0.099667\n",
              "Test    NaN  0.100778"
            ]
          },
          "execution_count": 29,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Check the final out come of the model\n",
        "train = model.evaluate(X_train, y_train, verbose=0)\n",
        "test = model.evaluate(X_test, y_test, verbose=0)\n",
        "results = pd.DataFrame({'Train':train,'Test':test}).T\n",
        "results.columns=['Loss','Accuracy']\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SX0uVhsRI0Dn"
      },
      "source": [
        "### Loss is exploding.Learning rate is too high.\n",
        "### Cost is very high. Always means high learning rate\n",
        "### Lets try to train now with a value of learning rate between 1e1 and 1e-4\n",
        "\n",
        "- learning rate = 1e1\n",
        "- regularization remains the small, lambda = 1e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-N6ivNVfI0Dn"
      },
      "outputs": [],
      "source": [
        "lr = 1e1\n",
        "Lambda = 1e-5\n",
        "iterations = 20\n",
        "model = model_nn(iterations,lr,Lambda)\n",
        "model.fit(X_train, y_train, epochs = iterations,batch_size=128 , verbose = 0);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "PRsAqx8rI0Dp",
        "outputId": "44b322d1-58df-4532-dc8e-7d6acf8fab91"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Train</th>\n",
              "      <td>11.978251</td>\n",
              "      <td>0.100762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Test</th>\n",
              "      <td>11.979209</td>\n",
              "      <td>0.098222</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Loss  Accuracy\n",
              "Train  11.978251  0.100762\n",
              "Test   11.979209  0.098222"
            ]
          },
          "execution_count": 31,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Check the final out come of the model\n",
        "train = model.evaluate(X_train, y_train, verbose=0)\n",
        "test = model.evaluate(X_test, y_test, verbose=0)\n",
        "results = pd.DataFrame({'Train':train,'Test':test}).T\n",
        "results.columns=['Loss','Accuracy']\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Rg1JvaWI0Dr"
      },
      "source": [
        "### Still too high learning rate. Loss is not decreasing. The rough range of learning rate we should be cross validating is somewhere between [1e-1 to 1e-5]\n",
        "### Hyperparameter Optimization\n",
        "\n",
        "### Cross validation Strategy\n",
        "\n",
        "\n",
        "- Do coarse -> fine cross-validation in stages\n",
        "\n",
        "- First stage: only a few epochs to get rough idea of what params work\n",
        "- Second stage: longer running time, finer search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3vrbSbAI0Ds"
      },
      "source": [
        "### For example: Run coarse search for 10 times with different lr and Lambda values each with 20 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9RtkFM5I0Ds",
        "outputId": "e8bfb4b1-e127-4093-d830-5338ad2cacb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "329/329 - 2s - loss: 2.3438 - accuracy: 0.1936 - val_loss: 2.0452 - val_accuracy: 0.2932\n",
            "Epoch 2/50\n",
            "329/329 - 2s - loss: 1.7985 - accuracy: 0.4019 - val_loss: 1.6546 - val_accuracy: 0.4638\n",
            "Epoch 3/50\n",
            "329/329 - 3s - loss: 1.5560 - accuracy: 0.5104 - val_loss: 1.5236 - val_accuracy: 0.5352\n",
            "Epoch 4/50\n",
            "329/329 - 2s - loss: 1.3933 - accuracy: 0.5786 - val_loss: 1.3048 - val_accuracy: 0.6152\n",
            "Epoch 5/50\n",
            "329/329 - 2s - loss: 1.2733 - accuracy: 0.6237 - val_loss: 1.3256 - val_accuracy: 0.5937\n",
            "Epoch 6/50\n",
            "329/329 - 3s - loss: 1.1975 - accuracy: 0.6501 - val_loss: 1.1401 - val_accuracy: 0.6731\n",
            "Epoch 7/50\n",
            "329/329 - 2s - loss: 1.1261 - accuracy: 0.6750 - val_loss: 1.1184 - val_accuracy: 0.6761\n",
            "Epoch 8/50\n",
            "329/329 - 3s - loss: 1.0603 - accuracy: 0.6955 - val_loss: 1.0762 - val_accuracy: 0.6876\n",
            "Epoch 9/50\n",
            "329/329 - 2s - loss: 1.0204 - accuracy: 0.7070 - val_loss: 1.0499 - val_accuracy: 0.7001\n",
            "Epoch 10/50\n",
            "329/329 - 2s - loss: 0.9820 - accuracy: 0.7202 - val_loss: 0.9516 - val_accuracy: 0.7344\n",
            "Epoch 11/50\n",
            "329/329 - 2s - loss: 0.9469 - accuracy: 0.7290 - val_loss: 0.9700 - val_accuracy: 0.7227\n",
            "Epoch 12/50\n",
            "329/329 - 2s - loss: 0.9104 - accuracy: 0.7413 - val_loss: 0.9447 - val_accuracy: 0.7305\n",
            "Epoch 13/50\n",
            "329/329 - 2s - loss: 0.8880 - accuracy: 0.7479 - val_loss: 0.9124 - val_accuracy: 0.7425\n",
            "Epoch 14/50\n",
            "329/329 - 2s - loss: 0.8616 - accuracy: 0.7528 - val_loss: 0.8831 - val_accuracy: 0.7491\n",
            "Epoch 15/50\n",
            "329/329 - 2s - loss: 0.8514 - accuracy: 0.7548 - val_loss: 0.8694 - val_accuracy: 0.7559\n",
            "Epoch 16/50\n",
            "329/329 - 2s - loss: 0.8212 - accuracy: 0.7658 - val_loss: 0.8528 - val_accuracy: 0.7590\n",
            "Epoch 17/50\n",
            "329/329 - 2s - loss: 0.8079 - accuracy: 0.7681 - val_loss: 0.8467 - val_accuracy: 0.7601\n",
            "Epoch 18/50\n",
            "329/329 - 2s - loss: 0.7885 - accuracy: 0.7732 - val_loss: 0.8337 - val_accuracy: 0.7626\n",
            "Epoch 19/50\n",
            "329/329 - 2s - loss: 0.7703 - accuracy: 0.7776 - val_loss: 0.8308 - val_accuracy: 0.7648\n",
            "Epoch 20/50\n",
            "329/329 - 2s - loss: 0.7561 - accuracy: 0.7824 - val_loss: 0.8447 - val_accuracy: 0.7589\n",
            "Epoch 21/50\n",
            "329/329 - 2s - loss: 0.7355 - accuracy: 0.7904 - val_loss: 0.8018 - val_accuracy: 0.7693\n",
            "Epoch 22/50\n",
            "329/329 - 2s - loss: 0.7271 - accuracy: 0.7916 - val_loss: 0.8258 - val_accuracy: 0.7656\n",
            "Epoch 23/50\n",
            "329/329 - 2s - loss: 0.7103 - accuracy: 0.7967 - val_loss: 0.7825 - val_accuracy: 0.7810\n",
            "Epoch 24/50\n",
            "329/329 - 2s - loss: 0.6922 - accuracy: 0.8030 - val_loss: 0.7638 - val_accuracy: 0.7866\n",
            "Epoch 25/50\n",
            "329/329 - 2s - loss: 0.6893 - accuracy: 0.8019 - val_loss: 0.7813 - val_accuracy: 0.7831\n",
            "Epoch 26/50\n",
            "329/329 - 2s - loss: 0.6730 - accuracy: 0.8070 - val_loss: 0.7569 - val_accuracy: 0.7875\n",
            "Epoch 27/50\n",
            "329/329 - 2s - loss: 0.6649 - accuracy: 0.8086 - val_loss: 0.7410 - val_accuracy: 0.7949\n",
            "Epoch 28/50\n",
            "329/329 - 2s - loss: 0.6567 - accuracy: 0.8111 - val_loss: 0.7426 - val_accuracy: 0.7890\n",
            "Epoch 29/50\n",
            "329/329 - 2s - loss: 0.6499 - accuracy: 0.8128 - val_loss: 0.7647 - val_accuracy: 0.7852\n",
            "Epoch 30/50\n",
            "329/329 - 2s - loss: 0.6372 - accuracy: 0.8186 - val_loss: 0.7055 - val_accuracy: 0.8052\n",
            "Epoch 31/50\n",
            "329/329 - 2s - loss: 0.6221 - accuracy: 0.8214 - val_loss: 0.7198 - val_accuracy: 0.8006\n",
            "Epoch 32/50\n",
            "329/329 - 2s - loss: 0.6173 - accuracy: 0.8226 - val_loss: 0.7418 - val_accuracy: 0.7919\n",
            "Epoch 33/50\n",
            "329/329 - 2s - loss: 0.6036 - accuracy: 0.8266 - val_loss: 0.7220 - val_accuracy: 0.7954\n",
            "Epoch 34/50\n",
            "329/329 - 2s - loss: 0.6002 - accuracy: 0.8278 - val_loss: 0.7230 - val_accuracy: 0.7911\n",
            "Epoch 35/50\n",
            "329/329 - 2s - loss: 0.5971 - accuracy: 0.8281 - val_loss: 0.6771 - val_accuracy: 0.8116\n",
            "Epoch 36/50\n",
            "329/329 - 2s - loss: 0.5822 - accuracy: 0.8332 - val_loss: 0.6803 - val_accuracy: 0.8118\n",
            "Epoch 37/50\n",
            "329/329 - 2s - loss: 0.5798 - accuracy: 0.8331 - val_loss: 0.7102 - val_accuracy: 0.7994\n",
            "Epoch 38/50\n",
            "329/329 - 2s - loss: 0.5708 - accuracy: 0.8365 - val_loss: 0.6770 - val_accuracy: 0.8108\n",
            "Epoch 39/50\n",
            "329/329 - 2s - loss: 0.5646 - accuracy: 0.8369 - val_loss: 0.6911 - val_accuracy: 0.8080\n",
            "Epoch 40/50\n",
            "329/329 - 2s - loss: 0.5579 - accuracy: 0.8393 - val_loss: 0.6672 - val_accuracy: 0.8154\n",
            "Epoch 41/50\n",
            "329/329 - 2s - loss: 0.5565 - accuracy: 0.8398 - val_loss: 0.6557 - val_accuracy: 0.8181\n",
            "Epoch 42/50\n",
            "329/329 - 2s - loss: 0.5429 - accuracy: 0.8445 - val_loss: 0.6549 - val_accuracy: 0.8212\n",
            "Epoch 43/50\n",
            "329/329 - 2s - loss: 0.5379 - accuracy: 0.8428 - val_loss: 0.6902 - val_accuracy: 0.8081\n",
            "Epoch 44/50\n",
            "329/329 - 2s - loss: 0.5297 - accuracy: 0.8468 - val_loss: 0.7111 - val_accuracy: 0.8005\n",
            "Epoch 45/50\n",
            "329/329 - 2s - loss: 0.5308 - accuracy: 0.8453 - val_loss: 0.6778 - val_accuracy: 0.8084\n",
            "Epoch 46/50\n",
            "Epoch 47/50\n",
            "329/329 - 2s - loss: 0.5225 - accuracy: 0.8481 - val_loss: 0.6702 - val_accuracy: 0.8112\n",
            "Epoch 48/50\n",
            "329/329 - 2s - loss: 0.5144 - accuracy: 0.8490 - val_loss: 0.6687 - val_accuracy: 0.8119\n",
            "Epoch 49/50\n",
            "329/329 - 2s - loss: 0.5043 - accuracy: 0.8530 - val_loss: 0.6348 - val_accuracy: 0.8236\n",
            "Epoch 50/50\n",
            "329/329 - 2s - loss: 0.4997 - accuracy: 0.8552 - val_loss: 0.6654 - val_accuracy: 0.8122\n",
            "1313/1313 [==============================] - 2s 2ms/step - loss: 0.4953 - accuracy: 0.8547\n",
            "Try 1/10: Best_val_acc: [0.4952699840068817, 0.8546666502952576], lr: 0.0004656804637919565, Lambda: 0.014486833887239339\n",
            "\n",
            "Epoch 1/50\n",
            "329/329 - 2s - loss: 2.3162 - accuracy: 0.1189 - val_loss: 2.2992 - val_accuracy: 0.1404\n",
            "Epoch 2/50\n",
            "329/329 - 2s - loss: 2.2907 - accuracy: 0.1499 - val_loss: 2.2825 - val_accuracy: 0.1523\n",
            "Epoch 3/50\n",
            "329/329 - 2s - loss: 2.2737 - accuracy: 0.1743 - val_loss: 2.2646 - val_accuracy: 0.1784\n",
            "Epoch 4/50\n",
            "329/329 - 2s - loss: 2.2530 - accuracy: 0.2015 - val_loss: 2.2384 - val_accuracy: 0.2228\n",
            "Epoch 5/50\n",
            "329/329 - 2s - loss: 2.2262 - accuracy: 0.2337 - val_loss: 2.2109 - val_accuracy: 0.2434\n",
            "Epoch 6/50\n",
            "329/329 - 2s - loss: 2.1972 - accuracy: 0.2553 - val_loss: 2.1807 - val_accuracy: 0.2636\n",
            "Epoch 7/50\n",
            "329/329 - 2s - loss: 2.1649 - accuracy: 0.2766 - val_loss: 2.1442 - val_accuracy: 0.2922\n",
            "Epoch 8/50\n",
            "329/329 - 2s - loss: 2.1293 - accuracy: 0.3014 - val_loss: 2.1081 - val_accuracy: 0.3180\n",
            "Epoch 9/50\n",
            "329/329 - 2s - loss: 2.0924 - accuracy: 0.3231 - val_loss: 2.0706 - val_accuracy: 0.3412\n",
            "Epoch 10/50\n",
            "329/329 - 2s - loss: 2.0556 - accuracy: 0.3453 - val_loss: 2.0350 - val_accuracy: 0.3584\n",
            "Epoch 11/50\n",
            "329/329 - 2s - loss: 2.0180 - accuracy: 0.3680 - val_loss: 1.9944 - val_accuracy: 0.3804\n",
            "Epoch 12/50\n",
            "329/329 - 2s - loss: 1.9788 - accuracy: 0.3901 - val_loss: 1.9576 - val_accuracy: 0.4020\n",
            "Epoch 13/50\n",
            "329/329 - 2s - loss: 1.9411 - accuracy: 0.4094 - val_loss: 1.9181 - val_accuracy: 0.4232\n",
            "Epoch 14/50\n",
            "329/329 - 2s - loss: 1.9030 - accuracy: 0.4298 - val_loss: 1.8798 - val_accuracy: 0.4407\n",
            "Epoch 15/50\n",
            "329/329 - 2s - loss: 1.8653 - accuracy: 0.4465 - val_loss: 1.8435 - val_accuracy: 0.4538\n",
            "Epoch 16/50\n",
            "329/329 - 2s - loss: 1.8282 - accuracy: 0.4616 - val_loss: 1.8059 - val_accuracy: 0.4694\n",
            "Epoch 17/50\n",
            "329/329 - 2s - loss: 1.7911 - accuracy: 0.4748 - val_loss: 1.7674 - val_accuracy: 0.4832\n",
            "Epoch 18/50\n",
            "329/329 - 2s - loss: 1.7553 - accuracy: 0.4859 - val_loss: 1.7328 - val_accuracy: 0.4933\n",
            "Epoch 19/50\n",
            "329/329 - 2s - loss: 1.7218 - accuracy: 0.4967 - val_loss: 1.6989 - val_accuracy: 0.5074\n",
            "Epoch 20/50\n",
            "329/329 - 2s - loss: 1.6896 - accuracy: 0.5094 - val_loss: 1.6675 - val_accuracy: 0.5173\n",
            "Epoch 21/50\n",
            "329/329 - 3s - loss: 1.6593 - accuracy: 0.5189 - val_loss: 1.6376 - val_accuracy: 0.5252\n",
            "Epoch 22/50\n",
            "329/329 - 3s - loss: 1.6298 - accuracy: 0.5290 - val_loss: 1.6095 - val_accuracy: 0.5404\n",
            "Epoch 23/50\n",
            "329/329 - 3s - loss: 1.6019 - accuracy: 0.5386 - val_loss: 1.5813 - val_accuracy: 0.5479\n",
            "Epoch 24/50\n",
            "329/329 - 2s - loss: 1.5757 - accuracy: 0.5456 - val_loss: 1.5566 - val_accuracy: 0.5569\n",
            "Epoch 25/50\n",
            "329/329 - 2s - loss: 1.5505 - accuracy: 0.5525 - val_loss: 1.5328 - val_accuracy: 0.5607\n",
            "Epoch 26/50\n",
            "329/329 - 2s - loss: 1.5268 - accuracy: 0.5612 - val_loss: 1.5097 - val_accuracy: 0.5659\n",
            "Epoch 27/50\n",
            "329/329 - 2s - loss: 1.5041 - accuracy: 0.5702 - val_loss: 1.4873 - val_accuracy: 0.5787\n",
            "Epoch 28/50\n",
            "329/329 - 2s - loss: 1.4833 - accuracy: 0.5745 - val_loss: 1.4662 - val_accuracy: 0.5857\n",
            "Epoch 29/50\n",
            "329/329 - 2s - loss: 1.4628 - accuracy: 0.5829 - val_loss: 1.4472 - val_accuracy: 0.5908\n",
            "Epoch 30/50\n",
            "329/329 - 2s - loss: 1.4434 - accuracy: 0.5882 - val_loss: 1.4270 - val_accuracy: 0.5949\n",
            "Epoch 31/50\n",
            "329/329 - 2s - loss: 1.4248 - accuracy: 0.5965 - val_loss: 1.4124 - val_accuracy: 0.5994\n",
            "Epoch 32/50\n",
            "329/329 - 2s - loss: 1.4085 - accuracy: 0.5989 - val_loss: 1.3924 - val_accuracy: 0.6069\n",
            "Epoch 33/50\n",
            "329/329 - 2s - loss: 1.3910 - accuracy: 0.6042 - val_loss: 1.3787 - val_accuracy: 0.6093\n",
            "Epoch 34/50\n",
            "329/329 - 2s - loss: 1.3752 - accuracy: 0.6078 - val_loss: 1.3635 - val_accuracy: 0.6109\n",
            "Epoch 35/50\n",
            "329/329 - 2s - loss: 1.3606 - accuracy: 0.6123 - val_loss: 1.3464 - val_accuracy: 0.6170\n",
            "Epoch 36/50\n",
            "329/329 - 2s - loss: 1.3453 - accuracy: 0.6171 - val_loss: 1.3329 - val_accuracy: 0.6232\n",
            "Epoch 37/50\n",
            "329/329 - 2s - loss: 1.3322 - accuracy: 0.6209 - val_loss: 1.3198 - val_accuracy: 0.6239\n",
            "Epoch 38/50\n",
            "329/329 - 2s - loss: 1.3193 - accuracy: 0.6241 - val_loss: 1.3079 - val_accuracy: 0.6286\n",
            "Epoch 39/50\n",
            "329/329 - 2s - loss: 1.3065 - accuracy: 0.6273 - val_loss: 1.2966 - val_accuracy: 0.6293\n",
            "Epoch 40/50\n",
            "329/329 - 2s - loss: 1.2947 - accuracy: 0.6307 - val_loss: 1.2837 - val_accuracy: 0.6359\n",
            "Epoch 41/50\n",
            "329/329 - 2s - loss: 1.2839 - accuracy: 0.6353 - val_loss: 1.2760 - val_accuracy: 0.6352\n",
            "Epoch 42/50\n",
            "329/329 - 2s - loss: 1.2727 - accuracy: 0.6373 - val_loss: 1.2646 - val_accuracy: 0.6380\n",
            "Epoch 43/50\n",
            "329/329 - 2s - loss: 1.2624 - accuracy: 0.6390 - val_loss: 1.2544 - val_accuracy: 0.6432\n",
            "Epoch 44/50\n",
            "329/329 - 2s - loss: 1.2520 - accuracy: 0.6432 - val_loss: 1.2448 - val_accuracy: 0.6461\n",
            "Epoch 45/50\n",
            "329/329 - 2s - loss: 1.2426 - accuracy: 0.6455 - val_loss: 1.2362 - val_accuracy: 0.6457\n",
            "Epoch 46/50\n",
            "329/329 - 2s - loss: 1.2337 - accuracy: 0.6478 - val_loss: 1.2271 - val_accuracy: 0.6480\n",
            "Epoch 47/50\n",
            "329/329 - 2s - loss: 1.2249 - accuracy: 0.6494 - val_loss: 1.2219 - val_accuracy: 0.6518\n",
            "Epoch 48/50\n",
            "329/329 - 2s - loss: 1.2167 - accuracy: 0.6513 - val_loss: 1.2128 - val_accuracy: 0.6512\n",
            "Epoch 49/50\n",
            "329/329 - 2s - loss: 1.2077 - accuracy: 0.6539 - val_loss: 1.2042 - val_accuracy: 0.6563\n",
            "Epoch 50/50\n",
            "329/329 - 2s - loss: 1.2008 - accuracy: 0.6553 - val_loss: 1.1969 - val_accuracy: 0.6560\n",
            "1313/1313 [==============================] - 2s 2ms/step - loss: 1.1941 - accuracy: 0.6578\n",
            "Try 2/10: Best_val_acc: [1.1941288709640503, 0.6578333377838135], lr: 1.0010539860510488e-05, Lambda: 0.0008072307884499759\n",
            "\n",
            "Epoch 1/50\n",
            "329/329 - 2s - loss: 2.2700 - accuracy: 0.1608 - val_loss: 2.2131 - val_accuracy: 0.2279\n",
            "Epoch 2/50\n",
            "329/329 - 2s - loss: 2.1449 - accuracy: 0.2733 - val_loss: 2.0689 - val_accuracy: 0.2847\n",
            "Epoch 3/50\n",
            "329/329 - 2s - loss: 1.9840 - accuracy: 0.3418 - val_loss: 1.8978 - val_accuracy: 0.3873\n",
            "Epoch 4/50\n",
            "329/329 - 2s - loss: 1.8209 - accuracy: 0.4267 - val_loss: 1.7449 - val_accuracy: 0.4479\n",
            "Epoch 5/50\n",
            "329/329 - 2s - loss: 1.6726 - accuracy: 0.4907 - val_loss: 1.6018 - val_accuracy: 0.5247\n",
            "Epoch 6/50\n",
            "329/329 - 2s - loss: 1.5529 - accuracy: 0.5401 - val_loss: 1.5001 - val_accuracy: 0.5554\n",
            "Epoch 7/50\n",
            "329/329 - 2s - loss: 1.4628 - accuracy: 0.5682 - val_loss: 1.4233 - val_accuracy: 0.5774\n",
            "Epoch 8/50\n",
            "329/329 - 2s - loss: 1.3938 - accuracy: 0.5908 - val_loss: 1.3878 - val_accuracy: 0.5898\n",
            "Epoch 9/50\n",
            "329/329 - 2s - loss: 1.3409 - accuracy: 0.6058 - val_loss: 1.3231 - val_accuracy: 0.6013\n",
            "Epoch 10/50\n",
            "329/329 - 2s - loss: 1.2962 - accuracy: 0.6189 - val_loss: 1.2870 - val_accuracy: 0.6167\n",
            "Epoch 11/50\n",
            "329/329 - 2s - loss: 1.2577 - accuracy: 0.6318 - val_loss: 1.2511 - val_accuracy: 0.6276\n",
            "Epoch 12/50\n",
            "329/329 - 2s - loss: 1.2290 - accuracy: 0.6394 - val_loss: 1.2272 - val_accuracy: 0.6342\n",
            "Epoch 13/50\n",
            "329/329 - 2s - loss: 1.1996 - accuracy: 0.6467 - val_loss: 1.2148 - val_accuracy: 0.6378\n",
            "Epoch 14/50\n",
            "329/329 - 2s - loss: 1.1737 - accuracy: 0.6534 - val_loss: 1.1698 - val_accuracy: 0.6571\n",
            "Epoch 15/50\n",
            "329/329 - 2s - loss: 1.1562 - accuracy: 0.6601 - val_loss: 1.1569 - val_accuracy: 0.6549\n",
            "Epoch 16/50\n",
            "329/329 - 2s - loss: 1.1349 - accuracy: 0.6646 - val_loss: 1.1560 - val_accuracy: 0.6535\n",
            "Epoch 17/50\n",
            "329/329 - 2s - loss: 1.1171 - accuracy: 0.6691 - val_loss: 1.1289 - val_accuracy: 0.6650\n",
            "Epoch 18/50\n",
            "329/329 - 2s - loss: 1.0992 - accuracy: 0.6740 - val_loss: 1.1150 - val_accuracy: 0.6694\n",
            "Epoch 19/50\n",
            "329/329 - 2s - loss: 1.0848 - accuracy: 0.6802 - val_loss: 1.0963 - val_accuracy: 0.6749\n",
            "Epoch 20/50\n",
            "329/329 - 2s - loss: 1.0704 - accuracy: 0.6833 - val_loss: 1.0813 - val_accuracy: 0.6817\n",
            "Epoch 21/50\n",
            "329/329 - 2s - loss: 1.0558 - accuracy: 0.6882 - val_loss: 1.0665 - val_accuracy: 0.6879\n",
            "Epoch 22/50\n",
            "329/329 - 2s - loss: 1.0435 - accuracy: 0.6914 - val_loss: 1.0637 - val_accuracy: 0.6844\n",
            "Epoch 23/50\n",
            "329/329 - 2s - loss: 1.0307 - accuracy: 0.6953 - val_loss: 1.0501 - val_accuracy: 0.6906\n",
            "Epoch 24/50\n",
            "329/329 - 2s - loss: 1.0194 - accuracy: 0.6978 - val_loss: 1.0554 - val_accuracy: 0.6833\n",
            "Epoch 25/50\n",
            "329/329 - 2s - loss: 1.0087 - accuracy: 0.6996 - val_loss: 1.0314 - val_accuracy: 0.6930\n",
            "Epoch 26/50\n",
            "329/329 - 2s - loss: 1.0001 - accuracy: 0.7036 - val_loss: 1.0183 - val_accuracy: 0.6963\n",
            "Epoch 27/50\n",
            "329/329 - 2s - loss: 0.9885 - accuracy: 0.7092 - val_loss: 1.0096 - val_accuracy: 0.7039\n",
            "Epoch 28/50\n",
            "329/329 - 2s - loss: 0.9792 - accuracy: 0.7090 - val_loss: 1.0068 - val_accuracy: 0.7013\n",
            "Epoch 29/50\n",
            "329/329 - 2s - loss: 0.9717 - accuracy: 0.7103 - val_loss: 1.0102 - val_accuracy: 0.6990\n",
            "Epoch 30/50\n",
            "329/329 - 2s - loss: 0.9597 - accuracy: 0.7158 - val_loss: 0.9867 - val_accuracy: 0.7107\n",
            "Epoch 31/50\n",
            "329/329 - 2s - loss: 0.9527 - accuracy: 0.7167 - val_loss: 1.0140 - val_accuracy: 0.6986\n",
            "Epoch 32/50\n",
            "329/329 - 2s - loss: 0.9462 - accuracy: 0.7185 - val_loss: 0.9716 - val_accuracy: 0.7138\n",
            "Epoch 33/50\n",
            "329/329 - 2s - loss: 0.9369 - accuracy: 0.7218 - val_loss: 0.9761 - val_accuracy: 0.7114\n",
            "Epoch 34/50\n",
            "329/329 - 2s - loss: 0.9283 - accuracy: 0.7245 - val_loss: 0.9688 - val_accuracy: 0.7127\n",
            "Epoch 35/50\n",
            "329/329 - 2s - loss: 0.9213 - accuracy: 0.7278 - val_loss: 0.9521 - val_accuracy: 0.7178\n",
            "Epoch 36/50\n",
            "329/329 - 2s - loss: 0.9132 - accuracy: 0.7279 - val_loss: 0.9463 - val_accuracy: 0.7202\n",
            "Epoch 37/50\n",
            "329/329 - 2s - loss: 0.9068 - accuracy: 0.7313 - val_loss: 0.9407 - val_accuracy: 0.7211\n",
            "Epoch 38/50\n",
            "329/329 - 2s - loss: 0.9013 - accuracy: 0.7320 - val_loss: 0.9346 - val_accuracy: 0.7238\n",
            "Epoch 39/50\n",
            "329/329 - 3s - loss: 0.8931 - accuracy: 0.7341 - val_loss: 0.9384 - val_accuracy: 0.7237\n",
            "Epoch 40/50\n",
            "329/329 - 3s - loss: 0.8864 - accuracy: 0.7370 - val_loss: 0.9323 - val_accuracy: 0.7252\n",
            "Epoch 41/50\n",
            "329/329 - 3s - loss: 0.8811 - accuracy: 0.7394 - val_loss: 0.9434 - val_accuracy: 0.7183\n",
            "Epoch 42/50\n",
            "329/329 - 3s - loss: 0.8748 - accuracy: 0.7411 - val_loss: 0.9216 - val_accuracy: 0.7278\n",
            "Epoch 43/50\n",
            "329/329 - 3s - loss: 0.8673 - accuracy: 0.7442 - val_loss: 0.9387 - val_accuracy: 0.7222\n",
            "Epoch 44/50\n",
            "329/329 - 2s - loss: 0.8642 - accuracy: 0.7443 - val_loss: 0.9208 - val_accuracy: 0.7269\n",
            "Epoch 45/50\n",
            "329/329 - 2s - loss: 0.8588 - accuracy: 0.7465 - val_loss: 0.9029 - val_accuracy: 0.7336\n",
            "Epoch 46/50\n",
            "329/329 - 2s - loss: 0.8520 - accuracy: 0.7473 - val_loss: 0.9015 - val_accuracy: 0.7343\n",
            "Epoch 47/50\n",
            "329/329 - 2s - loss: 0.8475 - accuracy: 0.7490 - val_loss: 0.9097 - val_accuracy: 0.7326\n",
            "Epoch 48/50\n",
            "329/329 - 2s - loss: 0.8408 - accuracy: 0.7521 - val_loss: 0.8984 - val_accuracy: 0.7333\n",
            "Epoch 49/50\n",
            "329/329 - 2s - loss: 0.8390 - accuracy: 0.7515 - val_loss: 0.8909 - val_accuracy: 0.7393\n",
            "Epoch 50/50\n",
            "329/329 - 2s - loss: 0.8305 - accuracy: 0.7541 - val_loss: 0.8880 - val_accuracy: 0.7404\n",
            "1313/1313 [==============================] - 3s 2ms/step - loss: 0.8240 - accuracy: 0.7547\n",
            "Try 3/10: Best_val_acc: [0.8239633440971375, 0.7546666860580444], lr: 3.863879405158734e-05, Lambda: 0.00018924123965722252\n",
            "\n",
            "Epoch 1/50\n",
            "329/329 - 2s - loss: 2.2978 - accuracy: 0.1348 - val_loss: 2.2456 - val_accuracy: 0.1971\n",
            "Epoch 2/50\n",
            "329/329 - 2s - loss: 2.1834 - accuracy: 0.2339 - val_loss: 2.1046 - val_accuracy: 0.2828\n",
            "Epoch 3/50\n",
            "329/329 - 2s - loss: 2.0310 - accuracy: 0.3234 - val_loss: 1.9465 - val_accuracy: 0.3668\n",
            "Epoch 4/50\n",
            "329/329 - 2s - loss: 1.8646 - accuracy: 0.4040 - val_loss: 1.7750 - val_accuracy: 0.4243\n",
            "Epoch 5/50\n",
            "329/329 - 2s - loss: 1.7021 - accuracy: 0.4693 - val_loss: 1.6297 - val_accuracy: 0.4979\n",
            "Epoch 6/50\n",
            "329/329 - 2s - loss: 1.5675 - accuracy: 0.5277 - val_loss: 1.5017 - val_accuracy: 0.5492\n",
            "Epoch 7/50\n",
            "329/329 - 3s - loss: 1.4622 - accuracy: 0.5657 - val_loss: 1.4207 - val_accuracy: 0.5699\n",
            "Epoch 8/50\n",
            "329/329 - 4s - loss: 1.3817 - accuracy: 0.5953 - val_loss: 1.3477 - val_accuracy: 0.6000\n",
            "Epoch 9/50\n",
            "329/329 - 4s - loss: 1.3226 - accuracy: 0.6099 - val_loss: 1.3178 - val_accuracy: 0.6026\n",
            "Epoch 10/50\n",
            "329/329 - 3s - loss: 1.2755 - accuracy: 0.6257 - val_loss: 1.2538 - val_accuracy: 0.6302\n",
            "Epoch 11/50\n",
            "329/329 - 2s - loss: 1.2352 - accuracy: 0.6375 - val_loss: 1.2190 - val_accuracy: 0.6410\n",
            "Epoch 12/50\n",
            "329/329 - 2s - loss: 1.2045 - accuracy: 0.6448 - val_loss: 1.1887 - val_accuracy: 0.6519\n",
            "Epoch 13/50\n",
            "329/329 - 2s - loss: 1.1738 - accuracy: 0.6538 - val_loss: 1.1871 - val_accuracy: 0.6458\n",
            "Epoch 14/50\n",
            "329/329 - 2s - loss: 1.1482 - accuracy: 0.6622 - val_loss: 1.1498 - val_accuracy: 0.6618\n",
            "Epoch 15/50\n",
            "329/329 - 2s - loss: 1.1263 - accuracy: 0.6685 - val_loss: 1.1278 - val_accuracy: 0.6667\n",
            "Epoch 16/50\n",
            "329/329 - 2s - loss: 1.1048 - accuracy: 0.6760 - val_loss: 1.1130 - val_accuracy: 0.6708\n",
            "Epoch 17/50\n",
            "329/329 - 2s - loss: 1.0867 - accuracy: 0.6804 - val_loss: 1.0993 - val_accuracy: 0.6753\n",
            "Epoch 18/50\n",
            "329/329 - 2s - loss: 1.0691 - accuracy: 0.6869 - val_loss: 1.0847 - val_accuracy: 0.6795\n",
            "Epoch 19/50\n",
            "329/329 - 2s - loss: 1.0532 - accuracy: 0.6910 - val_loss: 1.0707 - val_accuracy: 0.6813\n",
            "Epoch 20/50\n",
            "329/329 - 2s - loss: 1.0377 - accuracy: 0.6945 - val_loss: 1.0565 - val_accuracy: 0.6871\n",
            "Epoch 21/50\n",
            "329/329 - 2s - loss: 1.0240 - accuracy: 0.7009 - val_loss: 1.0393 - val_accuracy: 0.6942\n",
            "Epoch 22/50\n",
            "329/329 - 2s - loss: 1.0095 - accuracy: 0.7044 - val_loss: 1.0171 - val_accuracy: 0.7015\n",
            "Epoch 23/50\n",
            "329/329 - 2s - loss: 0.9935 - accuracy: 0.7090 - val_loss: 1.0246 - val_accuracy: 0.7013\n",
            "Epoch 24/50\n",
            "329/329 - 2s - loss: 0.9793 - accuracy: 0.7119 - val_loss: 1.0005 - val_accuracy: 0.7055\n",
            "Epoch 25/50\n",
            "329/329 - 2s - loss: 0.9683 - accuracy: 0.7158 - val_loss: 0.9916 - val_accuracy: 0.7085\n",
            "Epoch 26/50\n",
            "Epoch 27/50\n",
            "329/329 - 2s - loss: 0.9467 - accuracy: 0.7215 - val_loss: 0.9725 - val_accuracy: 0.7151\n",
            "Epoch 28/50\n",
            "329/329 - 2s - loss: 0.9351 - accuracy: 0.7249 - val_loss: 0.9592 - val_accuracy: 0.7198\n",
            "Epoch 29/50\n",
            "329/329 - 2s - loss: 0.9272 - accuracy: 0.7285 - val_loss: 0.9649 - val_accuracy: 0.7148\n",
            "Epoch 30/50\n",
            "329/329 - 2s - loss: 0.9148 - accuracy: 0.7320 - val_loss: 0.9491 - val_accuracy: 0.7231\n",
            "Epoch 31/50\n",
            "329/329 - 2s - loss: 0.9051 - accuracy: 0.7330 - val_loss: 0.9581 - val_accuracy: 0.7188\n",
            "Epoch 32/50\n",
            "329/329 - 2s - loss: 0.8993 - accuracy: 0.7366 - val_loss: 0.9301 - val_accuracy: 0.7283\n",
            "Epoch 33/50\n",
            "329/329 - 2s - loss: 0.8847 - accuracy: 0.7412 - val_loss: 0.9457 - val_accuracy: 0.7202\n",
            "Epoch 34/50\n",
            "329/329 - 2s - loss: 0.8797 - accuracy: 0.7410 - val_loss: 0.9227 - val_accuracy: 0.7293\n",
            "Epoch 35/50\n",
            "329/329 - 2s - loss: 0.8711 - accuracy: 0.7432 - val_loss: 0.9138 - val_accuracy: 0.7326\n",
            "Epoch 36/50\n",
            "329/329 - 2s - loss: 0.8612 - accuracy: 0.7480 - val_loss: 0.9238 - val_accuracy: 0.7246\n",
            "Epoch 37/50\n",
            "329/329 - 2s - loss: 0.8528 - accuracy: 0.7493 - val_loss: 0.8973 - val_accuracy: 0.7401\n",
            "Epoch 38/50\n",
            "329/329 - 2s - loss: 0.8440 - accuracy: 0.7519 - val_loss: 0.8923 - val_accuracy: 0.7402\n",
            "Epoch 39/50\n",
            "329/329 - 2s - loss: 0.8355 - accuracy: 0.7555 - val_loss: 0.8895 - val_accuracy: 0.7413\n",
            "Epoch 40/50\n",
            "329/329 - 2s - loss: 0.8306 - accuracy: 0.7577 - val_loss: 0.8782 - val_accuracy: 0.7451\n",
            "Epoch 41/50\n",
            "329/329 - 2s - loss: 0.8230 - accuracy: 0.7594 - val_loss: 0.8806 - val_accuracy: 0.7410\n",
            "Epoch 42/50\n",
            "329/329 - 2s - loss: 0.8131 - accuracy: 0.7622 - val_loss: 0.8725 - val_accuracy: 0.7472\n",
            "Epoch 43/50\n",
            "329/329 - 2s - loss: 0.8067 - accuracy: 0.7634 - val_loss: 0.8723 - val_accuracy: 0.7498\n",
            "Epoch 44/50\n",
            "329/329 - 2s - loss: 0.8026 - accuracy: 0.7660 - val_loss: 0.8720 - val_accuracy: 0.7447\n",
            "Epoch 45/50\n",
            "329/329 - 2s - loss: 0.7929 - accuracy: 0.7684 - val_loss: 0.8657 - val_accuracy: 0.7485\n",
            "Epoch 46/50\n",
            "329/329 - 2s - loss: 0.7873 - accuracy: 0.7698 - val_loss: 0.8559 - val_accuracy: 0.7491\n",
            "Epoch 47/50\n",
            "329/329 - 2s - loss: 0.7816 - accuracy: 0.7709 - val_loss: 0.8574 - val_accuracy: 0.7522\n",
            "Epoch 48/50\n",
            "329/329 - 2s - loss: 0.7736 - accuracy: 0.7757 - val_loss: 0.8460 - val_accuracy: 0.7557\n",
            "Epoch 49/50\n",
            "329/329 - 3s - loss: 0.7734 - accuracy: 0.7755 - val_loss: 0.8390 - val_accuracy: 0.7594\n",
            "Epoch 50/50\n",
            "329/329 - 3s - loss: 0.7639 - accuracy: 0.7765 - val_loss: 0.8376 - val_accuracy: 0.7589\n",
            "1313/1313 [==============================] - 3s 2ms/step - loss: 0.7568 - accuracy: 0.7816\n",
            "Try 4/10: Best_val_acc: [0.7568460702896118, 0.7816428542137146], lr: 5.559565426712562e-05, Lambda: 0.001088133500363588\n",
            "\n",
            "Epoch 1/50\n",
            "329/329 - 2s - loss: 2.3130 - accuracy: 0.1462 - val_loss: 2.1711 - val_accuracy: 0.2225\n",
            "Epoch 2/50\n",
            "329/329 - 2s - loss: 1.8328 - accuracy: 0.3908 - val_loss: 1.5212 - val_accuracy: 0.5161\n",
            "Epoch 3/50\n",
            "329/329 - 2s - loss: 1.4212 - accuracy: 0.5562 - val_loss: 1.3095 - val_accuracy: 0.6004\n",
            "Epoch 4/50\n",
            "329/329 - 2s - loss: 1.2908 - accuracy: 0.6063 - val_loss: 1.2308 - val_accuracy: 0.6276\n",
            "Epoch 5/50\n",
            "329/329 - 2s - loss: 1.1998 - accuracy: 0.6430 - val_loss: 1.2196 - val_accuracy: 0.6285\n",
            "Epoch 6/50\n",
            "329/329 - 2s - loss: 1.1493 - accuracy: 0.6607 - val_loss: 1.1573 - val_accuracy: 0.6593\n",
            "Epoch 7/50\n",
            "329/329 - 2s - loss: 1.0971 - accuracy: 0.6773 - val_loss: 1.0702 - val_accuracy: 0.6840\n",
            "Epoch 8/50\n",
            "329/329 - 2s - loss: 1.0625 - accuracy: 0.6885 - val_loss: 1.1188 - val_accuracy: 0.6631\n",
            "Epoch 9/50\n",
            "329/329 - 2s - loss: 1.0277 - accuracy: 0.6996 - val_loss: 1.0459 - val_accuracy: 0.6897\n",
            "Epoch 10/50\n",
            "329/329 - 2s - loss: 0.9967 - accuracy: 0.7092 - val_loss: 1.0085 - val_accuracy: 0.7014\n",
            "Epoch 11/50\n",
            "329/329 - 2s - loss: 0.9775 - accuracy: 0.7125 - val_loss: 1.0104 - val_accuracy: 0.6998\n",
            "Epoch 12/50\n",
            "329/329 - 2s - loss: 0.9399 - accuracy: 0.7265 - val_loss: 0.9741 - val_accuracy: 0.7133\n",
            "Epoch 13/50\n",
            "329/329 - 2s - loss: 0.9169 - accuracy: 0.7347 - val_loss: 0.9307 - val_accuracy: 0.7316\n",
            "Epoch 14/50\n",
            "329/329 - 2s - loss: 0.8884 - accuracy: 0.7422 - val_loss: 0.8921 - val_accuracy: 0.7456\n",
            "Epoch 15/50\n",
            "329/329 - 2s - loss: 0.8783 - accuracy: 0.7451 - val_loss: 0.9133 - val_accuracy: 0.7354\n",
            "Epoch 16/50\n",
            "329/329 - 2s - loss: 0.8490 - accuracy: 0.7571 - val_loss: 0.8610 - val_accuracy: 0.7553\n",
            "Epoch 17/50\n",
            "329/329 - 2s - loss: 0.8272 - accuracy: 0.7607 - val_loss: 0.8763 - val_accuracy: 0.7472\n",
            "Epoch 18/50\n",
            "329/329 - 2s - loss: 0.8167 - accuracy: 0.7648 - val_loss: 0.8929 - val_accuracy: 0.7443\n",
            "Epoch 19/50\n",
            "329/329 - 2s - loss: 0.7965 - accuracy: 0.7704 - val_loss: 0.8585 - val_accuracy: 0.7543\n",
            "Epoch 20/50\n",
            "329/329 - 2s - loss: 0.7849 - accuracy: 0.7714 - val_loss: 0.8282 - val_accuracy: 0.7666\n",
            "Epoch 21/50\n",
            "329/329 - 2s - loss: 0.7674 - accuracy: 0.7768 - val_loss: 0.8216 - val_accuracy: 0.7651\n",
            "Epoch 22/50\n",
            "329/329 - 2s - loss: 0.7558 - accuracy: 0.7824 - val_loss: 0.8289 - val_accuracy: 0.7612\n",
            "Epoch 23/50\n",
            "329/329 - 2s - loss: 0.7390 - accuracy: 0.7866 - val_loss: 0.7772 - val_accuracy: 0.7829\n",
            "Epoch 24/50\n",
            "329/329 - 2s - loss: 0.7261 - accuracy: 0.7907 - val_loss: 0.7993 - val_accuracy: 0.7708\n",
            "Epoch 25/50\n",
            "329/329 - 2s - loss: 0.7179 - accuracy: 0.7929 - val_loss: 0.7971 - val_accuracy: 0.7727\n",
            "Epoch 26/50\n",
            "329/329 - 2s - loss: 0.7095 - accuracy: 0.7964 - val_loss: 0.7729 - val_accuracy: 0.7827\n",
            "Epoch 27/50\n",
            "329/329 - 2s - loss: 0.7037 - accuracy: 0.7964 - val_loss: 0.7966 - val_accuracy: 0.7724\n",
            "Epoch 28/50\n",
            "329/329 - 2s - loss: 0.6897 - accuracy: 0.8015 - val_loss: 0.7793 - val_accuracy: 0.7783\n",
            "Epoch 29/50\n",
            "329/329 - 2s - loss: 0.6832 - accuracy: 0.8030 - val_loss: 0.7566 - val_accuracy: 0.7861\n",
            "Epoch 30/50\n",
            "329/329 - 2s - loss: 0.6676 - accuracy: 0.8073 - val_loss: 0.7474 - val_accuracy: 0.7872\n",
            "Epoch 31/50\n",
            "329/329 - 2s - loss: 0.6579 - accuracy: 0.8107 - val_loss: 0.7404 - val_accuracy: 0.7933\n",
            "Epoch 32/50\n",
            "329/329 - 3s - loss: 0.6501 - accuracy: 0.8121 - val_loss: 0.7827 - val_accuracy: 0.7722\n",
            "Epoch 33/50\n",
            "329/329 - 2s - loss: 0.6390 - accuracy: 0.8147 - val_loss: 0.7268 - val_accuracy: 0.7957\n",
            "Epoch 34/50\n",
            "329/329 - 2s - loss: 0.6346 - accuracy: 0.8174 - val_loss: 0.7037 - val_accuracy: 0.8034\n",
            "Epoch 35/50\n",
            "329/329 - 2s - loss: 0.6293 - accuracy: 0.8177 - val_loss: 0.7315 - val_accuracy: 0.7941\n",
            "Epoch 36/50\n",
            "329/329 - 2s - loss: 0.6193 - accuracy: 0.8213 - val_loss: 0.7340 - val_accuracy: 0.7934\n",
            "Epoch 37/50\n",
            "329/329 - 2s - loss: 0.6096 - accuracy: 0.8228 - val_loss: 0.7219 - val_accuracy: 0.7967\n",
            "Epoch 38/50\n",
            "329/329 - 2s - loss: 0.6007 - accuracy: 0.8260 - val_loss: 0.7266 - val_accuracy: 0.7933\n",
            "Epoch 39/50\n",
            "329/329 - 2s - loss: 0.6013 - accuracy: 0.8256 - val_loss: 0.7235 - val_accuracy: 0.7947\n",
            "Epoch 40/50\n",
            "329/329 - 2s - loss: 0.5872 - accuracy: 0.8304 - val_loss: 0.7184 - val_accuracy: 0.7954\n",
            "Epoch 41/50\n",
            "329/329 - 2s - loss: 0.5881 - accuracy: 0.8280 - val_loss: 0.7264 - val_accuracy: 0.7959\n",
            "Epoch 42/50\n",
            "329/329 - 2s - loss: 0.5783 - accuracy: 0.8297 - val_loss: 0.7231 - val_accuracy: 0.7990\n",
            "Epoch 43/50\n",
            "329/329 - 2s - loss: 0.5693 - accuracy: 0.8337 - val_loss: 0.7045 - val_accuracy: 0.8017\n",
            "Epoch 44/50\n",
            "329/329 - 2s - loss: 0.5658 - accuracy: 0.8355 - val_loss: 0.7325 - val_accuracy: 0.7966\n",
            "Epoch 45/50\n",
            "329/329 - 2s - loss: 0.5552 - accuracy: 0.8379 - val_loss: 0.7050 - val_accuracy: 0.8011\n",
            "Epoch 46/50\n",
            "329/329 - 2s - loss: 0.5545 - accuracy: 0.8387 - val_loss: 0.7000 - val_accuracy: 0.8042\n",
            "Epoch 47/50\n",
            "329/329 - 2s - loss: 0.5502 - accuracy: 0.8403 - val_loss: 0.7020 - val_accuracy: 0.8048\n",
            "Epoch 48/50\n",
            "329/329 - 2s - loss: 0.5420 - accuracy: 0.8413 - val_loss: 0.7157 - val_accuracy: 0.8014\n",
            "Epoch 49/50\n",
            "329/329 - 2s - loss: 0.5398 - accuracy: 0.8430 - val_loss: 0.6852 - val_accuracy: 0.8068\n",
            "Epoch 50/50\n",
            "329/329 - 2s - loss: 0.5270 - accuracy: 0.8450 - val_loss: 0.6744 - val_accuracy: 0.8124\n",
            "1313/1313 [==============================] - 2s 2ms/step - loss: 0.5090 - accuracy: 0.8512\n",
            "Try 5/10: Best_val_acc: [0.5089772343635559, 0.8512142896652222], lr: 0.00038642916535526505, Lambda: 0.004134759007834719\n",
            "\n",
            "Epoch 1/50\n",
            "329/329 - 2s - loss: 2.3384 - accuracy: 0.1682 - val_loss: 2.0866 - val_accuracy: 0.2780\n",
            "Epoch 2/50\n",
            "329/329 - 2s - loss: 1.7732 - accuracy: 0.4254 - val_loss: 1.5083 - val_accuracy: 0.5370\n",
            "Epoch 3/50\n",
            "329/329 - 2s - loss: 1.4221 - accuracy: 0.5654 - val_loss: 1.3298 - val_accuracy: 0.5994\n",
            "Epoch 4/50\n",
            "329/329 - 2s - loss: 1.2912 - accuracy: 0.6135 - val_loss: 1.2344 - val_accuracy: 0.6369\n",
            "Epoch 5/50\n",
            "329/329 - 2s - loss: 1.2117 - accuracy: 0.6405 - val_loss: 1.2113 - val_accuracy: 0.6383\n",
            "Epoch 6/50\n",
            "329/329 - 2s - loss: 1.1499 - accuracy: 0.6636 - val_loss: 1.1077 - val_accuracy: 0.6818\n",
            "Epoch 7/50\n",
            "329/329 - 2s - loss: 1.0895 - accuracy: 0.6832 - val_loss: 1.1132 - val_accuracy: 0.6727\n",
            "Epoch 8/50\n",
            "329/329 - 2s - loss: 1.0323 - accuracy: 0.7035 - val_loss: 1.0401 - val_accuracy: 0.6991\n",
            "Epoch 9/50\n",
            "329/329 - 2s - loss: 0.9911 - accuracy: 0.7165 - val_loss: 1.0540 - val_accuracy: 0.6918\n",
            "Epoch 10/50\n",
            "329/329 - 2s - loss: 0.9494 - accuracy: 0.7278 - val_loss: 0.9852 - val_accuracy: 0.7146\n",
            "Epoch 11/50\n",
            "329/329 - 2s - loss: 0.9193 - accuracy: 0.7374 - val_loss: 0.9303 - val_accuracy: 0.7393\n",
            "Epoch 12/50\n",
            "329/329 - 2s - loss: 0.8844 - accuracy: 0.7486 - val_loss: 0.9031 - val_accuracy: 0.7456\n",
            "Epoch 13/50\n",
            "329/329 - 2s - loss: 0.8592 - accuracy: 0.7562 - val_loss: 0.8776 - val_accuracy: 0.7564\n",
            "Epoch 14/50\n",
            "329/329 - 2s - loss: 0.8365 - accuracy: 0.7601 - val_loss: 0.8626 - val_accuracy: 0.7604\n",
            "Epoch 15/50\n",
            "329/329 - 2s - loss: 0.8151 - accuracy: 0.7674 - val_loss: 0.8281 - val_accuracy: 0.7671\n",
            "Epoch 16/50\n",
            "329/329 - 2s - loss: 0.8004 - accuracy: 0.7699 - val_loss: 0.8346 - val_accuracy: 0.7669\n",
            "Epoch 17/50\n",
            "329/329 - 2s - loss: 0.7765 - accuracy: 0.7777 - val_loss: 0.8347 - val_accuracy: 0.7628\n",
            "Epoch 18/50\n",
            "329/329 - 2s - loss: 0.7618 - accuracy: 0.7812 - val_loss: 0.8091 - val_accuracy: 0.7722\n",
            "Epoch 19/50\n",
            "329/329 - 3s - loss: 0.7454 - accuracy: 0.7866 - val_loss: 0.7935 - val_accuracy: 0.7771\n",
            "Epoch 20/50\n",
            "329/329 - 3s - loss: 0.7323 - accuracy: 0.7911 - val_loss: 0.7757 - val_accuracy: 0.7813\n",
            "Epoch 21/50\n",
            "329/329 - 3s - loss: 0.7180 - accuracy: 0.7947 - val_loss: 0.8138 - val_accuracy: 0.7697\n",
            "Epoch 22/50\n",
            "329/329 - 3s - loss: 0.6999 - accuracy: 0.8007 - val_loss: 0.8195 - val_accuracy: 0.7656\n",
            "Epoch 23/50\n",
            "329/329 - 2s - loss: 0.6886 - accuracy: 0.8015 - val_loss: 0.7453 - val_accuracy: 0.7938\n",
            "Epoch 24/50\n",
            "329/329 - 2s - loss: 0.6755 - accuracy: 0.8068 - val_loss: 0.7588 - val_accuracy: 0.7858\n",
            "Epoch 25/50\n",
            "329/329 - 2s - loss: 0.6707 - accuracy: 0.8057 - val_loss: 0.7697 - val_accuracy: 0.7849\n",
            "Epoch 26/50\n",
            "329/329 - 2s - loss: 0.6555 - accuracy: 0.8117 - val_loss: 0.7602 - val_accuracy: 0.7853\n",
            "Epoch 27/50\n",
            "329/329 - 2s - loss: 0.6533 - accuracy: 0.8103 - val_loss: 0.7294 - val_accuracy: 0.7978\n",
            "Epoch 28/50\n",
            "329/329 - 2s - loss: 0.6370 - accuracy: 0.8176 - val_loss: 0.7235 - val_accuracy: 0.7983\n",
            "Epoch 29/50\n",
            "329/329 - 2s - loss: 0.6316 - accuracy: 0.8190 - val_loss: 0.7861 - val_accuracy: 0.7753\n",
            "Epoch 30/50\n",
            "329/329 - 2s - loss: 0.6277 - accuracy: 0.8195 - val_loss: 0.7168 - val_accuracy: 0.7991\n",
            "Epoch 31/50\n",
            "329/329 - 2s - loss: 0.6129 - accuracy: 0.8230 - val_loss: 0.6966 - val_accuracy: 0.8058\n",
            "Epoch 32/50\n",
            "329/329 - 2s - loss: 0.6094 - accuracy: 0.8242 - val_loss: 0.7288 - val_accuracy: 0.7935\n",
            "Epoch 33/50\n",
            "329/329 - 2s - loss: 0.5977 - accuracy: 0.8274 - val_loss: 0.6935 - val_accuracy: 0.8068\n",
            "Epoch 34/50\n",
            "329/329 - 2s - loss: 0.5914 - accuracy: 0.8278 - val_loss: 0.6753 - val_accuracy: 0.8122\n",
            "Epoch 35/50\n",
            "329/329 - 2s - loss: 0.5891 - accuracy: 0.8279 - val_loss: 0.7117 - val_accuracy: 0.8016\n",
            "Epoch 36/50\n",
            "329/329 - 2s - loss: 0.5771 - accuracy: 0.8337 - val_loss: 0.6761 - val_accuracy: 0.8129\n",
            "Epoch 37/50\n",
            "329/329 - 2s - loss: 0.5746 - accuracy: 0.8330 - val_loss: 0.7203 - val_accuracy: 0.7945\n",
            "Epoch 38/50\n",
            "329/329 - 2s - loss: 0.5598 - accuracy: 0.8390 - val_loss: 0.6945 - val_accuracy: 0.8038\n",
            "Epoch 39/50\n",
            "329/329 - 2s - loss: 0.5609 - accuracy: 0.8389 - val_loss: 0.6923 - val_accuracy: 0.8043\n",
            "Epoch 40/50\n",
            "329/329 - 2s - loss: 0.5500 - accuracy: 0.8406 - val_loss: 0.6697 - val_accuracy: 0.8127\n",
            "Epoch 41/50\n",
            "329/329 - 2s - loss: 0.5482 - accuracy: 0.8415 - val_loss: 0.6854 - val_accuracy: 0.8062\n",
            "Epoch 42/50\n",
            "329/329 - 2s - loss: 0.5448 - accuracy: 0.8405 - val_loss: 0.6711 - val_accuracy: 0.8123\n",
            "Epoch 43/50\n",
            "329/329 - 2s - loss: 0.5360 - accuracy: 0.8443 - val_loss: 0.6816 - val_accuracy: 0.8109\n",
            "Epoch 44/50\n",
            "329/329 - 2s - loss: 0.5269 - accuracy: 0.8472 - val_loss: 0.6653 - val_accuracy: 0.8134\n",
            "Epoch 45/50\n",
            "329/329 - 2s - loss: 0.5248 - accuracy: 0.8492 - val_loss: 0.6890 - val_accuracy: 0.8052\n",
            "Epoch 46/50\n",
            "329/329 - 2s - loss: 0.5215 - accuracy: 0.8504 - val_loss: 0.6477 - val_accuracy: 0.8221\n",
            "Epoch 47/50\n",
            "329/329 - 2s - loss: 0.5163 - accuracy: 0.8500 - val_loss: 0.6531 - val_accuracy: 0.8184\n",
            "Epoch 48/50\n",
            "329/329 - 2s - loss: 0.5115 - accuracy: 0.8511 - val_loss: 0.6523 - val_accuracy: 0.8191\n",
            "Epoch 49/50\n",
            "329/329 - 2s - loss: 0.5090 - accuracy: 0.8521 - val_loss: 0.6600 - val_accuracy: 0.8182\n",
            "Epoch 50/50\n",
            "329/329 - 2s - loss: 0.5014 - accuracy: 0.8540 - val_loss: 0.6517 - val_accuracy: 0.8183\n",
            "1313/1313 [==============================] - 2s 2ms/step - loss: 0.4795 - accuracy: 0.8593\n",
            "Try 6/10: Best_val_acc: [0.47947120666503906, 0.859333336353302], lr: 0.00047509237210306113, Lambda: 0.011367330868956228\n",
            "\n",
            "Epoch 1/50\n",
            "329/329 - 3s - loss: 2.8473 - accuracy: 0.1660 - val_loss: 2.7237 - val_accuracy: 0.2569\n",
            "Epoch 2/50\n",
            "329/329 - 2s - loss: 2.5803 - accuracy: 0.3005 - val_loss: 2.4346 - val_accuracy: 0.3159\n",
            "Epoch 3/50\n",
            "329/329 - 2s - loss: 2.2998 - accuracy: 0.4092 - val_loss: 2.1759 - val_accuracy: 0.4637\n",
            "Epoch 4/50\n",
            "329/329 - 2s - loss: 2.0883 - accuracy: 0.4790 - val_loss: 2.0016 - val_accuracy: 0.4987\n",
            "Epoch 5/50\n",
            "329/329 - 2s - loss: 1.9248 - accuracy: 0.5290 - val_loss: 1.8519 - val_accuracy: 0.5476\n",
            "Epoch 6/50\n",
            "329/329 - 2s - loss: 1.7980 - accuracy: 0.5660 - val_loss: 1.7379 - val_accuracy: 0.5814\n",
            "Epoch 7/50\n",
            "329/329 - 2s - loss: 1.6907 - accuracy: 0.5921 - val_loss: 1.6529 - val_accuracy: 0.6004\n",
            "Epoch 8/50\n",
            "329/329 - 2s - loss: 1.6062 - accuracy: 0.6126 - val_loss: 1.5805 - val_accuracy: 0.6186\n",
            "Epoch 9/50\n",
            "329/329 - 2s - loss: 1.5365 - accuracy: 0.6307 - val_loss: 1.5261 - val_accuracy: 0.6209\n",
            "Epoch 10/50\n",
            "329/329 - 2s - loss: 1.4767 - accuracy: 0.6430 - val_loss: 1.4510 - val_accuracy: 0.6502\n",
            "Epoch 11/50\n",
            "329/329 - 2s - loss: 1.4253 - accuracy: 0.6559 - val_loss: 1.4188 - val_accuracy: 0.6522\n",
            "Epoch 12/50\n",
            "329/329 - 2s - loss: 1.3793 - accuracy: 0.6660 - val_loss: 1.3788 - val_accuracy: 0.6618\n",
            "Epoch 13/50\n",
            "329/329 - 2s - loss: 1.3397 - accuracy: 0.6748 - val_loss: 1.3467 - val_accuracy: 0.6671\n",
            "Epoch 14/50\n",
            "329/329 - 2s - loss: 1.3031 - accuracy: 0.6810 - val_loss: 1.2970 - val_accuracy: 0.6828\n",
            "Epoch 15/50\n",
            "329/329 - 2s - loss: 1.2767 - accuracy: 0.6882 - val_loss: 1.2703 - val_accuracy: 0.6885\n",
            "Epoch 16/50\n",
            "329/329 - 2s - loss: 1.2426 - accuracy: 0.6970 - val_loss: 1.2553 - val_accuracy: 0.6913\n",
            "Epoch 17/50\n",
            "329/329 - 2s - loss: 1.2137 - accuracy: 0.7040 - val_loss: 1.2201 - val_accuracy: 0.7011\n",
            "Epoch 18/50\n",
            "329/329 - 2s - loss: 1.1902 - accuracy: 0.7101 - val_loss: 1.2057 - val_accuracy: 0.7036\n",
            "Epoch 19/50\n",
            "329/329 - 2s - loss: 1.1674 - accuracy: 0.7144 - val_loss: 1.1820 - val_accuracy: 0.7096\n",
            "Epoch 20/50\n",
            "329/329 - 2s - loss: 1.1470 - accuracy: 0.7193 - val_loss: 1.1571 - val_accuracy: 0.7136\n",
            "Epoch 21/50\n",
            "329/329 - 2s - loss: 1.1257 - accuracy: 0.7238 - val_loss: 1.1487 - val_accuracy: 0.7168\n",
            "Epoch 22/50\n",
            "329/329 - 2s - loss: 1.1053 - accuracy: 0.7303 - val_loss: 1.1246 - val_accuracy: 0.7242\n",
            "Epoch 23/50\n",
            "329/329 - 2s - loss: 1.0865 - accuracy: 0.7351 - val_loss: 1.1177 - val_accuracy: 0.7231\n",
            "Epoch 24/50\n",
            "329/329 - 2s - loss: 1.0722 - accuracy: 0.7368 - val_loss: 1.0993 - val_accuracy: 0.7302\n",
            "Epoch 25/50\n",
            "329/329 - 2s - loss: 1.0543 - accuracy: 0.7405 - val_loss: 1.0754 - val_accuracy: 0.7343\n",
            "Epoch 26/50\n",
            "329/329 - 2s - loss: 1.0396 - accuracy: 0.7452 - val_loss: 1.0642 - val_accuracy: 0.7388\n",
            "Epoch 27/50\n",
            "329/329 - 3s - loss: 1.0256 - accuracy: 0.7493 - val_loss: 1.0534 - val_accuracy: 0.7422\n",
            "Epoch 28/50\n",
            "329/329 - 3s - loss: 1.0101 - accuracy: 0.7534 - val_loss: 1.0493 - val_accuracy: 0.7400\n",
            "Epoch 29/50\n",
            "329/329 - 3s - loss: 0.9995 - accuracy: 0.7547 - val_loss: 1.0468 - val_accuracy: 0.7372\n",
            "Epoch 30/50\n",
            "329/329 - 2s - loss: 0.9857 - accuracy: 0.7590 - val_loss: 1.0250 - val_accuracy: 0.7462\n",
            "Epoch 31/50\n",
            "329/329 - 2s - loss: 0.9721 - accuracy: 0.7609 - val_loss: 1.0400 - val_accuracy: 0.7384\n",
            "Epoch 32/50\n",
            "329/329 - 2s - loss: 0.9604 - accuracy: 0.7622 - val_loss: 1.0107 - val_accuracy: 0.7503\n",
            "Epoch 33/50\n",
            "329/329 - 2s - loss: 0.9470 - accuracy: 0.7672 - val_loss: 0.9920 - val_accuracy: 0.7547\n",
            "Epoch 34/50\n",
            "329/329 - 2s - loss: 0.9372 - accuracy: 0.7679 - val_loss: 0.9810 - val_accuracy: 0.7577\n",
            "Epoch 35/50\n",
            "329/329 - 2s - loss: 0.9300 - accuracy: 0.7697 - val_loss: 0.9948 - val_accuracy: 0.7509\n",
            "Epoch 36/50\n",
            "329/329 - 2s - loss: 0.9179 - accuracy: 0.7745 - val_loss: 0.9721 - val_accuracy: 0.7553\n",
            "Epoch 37/50\n",
            "329/329 - 2s - loss: 0.9089 - accuracy: 0.7752 - val_loss: 0.9668 - val_accuracy: 0.7576\n",
            "Epoch 38/50\n",
            "329/329 - 2s - loss: 0.8975 - accuracy: 0.7771 - val_loss: 0.9429 - val_accuracy: 0.7682\n",
            "Epoch 39/50\n",
            "329/329 - 2s - loss: 0.8895 - accuracy: 0.7790 - val_loss: 0.9391 - val_accuracy: 0.7691\n",
            "Epoch 40/50\n",
            "329/329 - 2s - loss: 0.8823 - accuracy: 0.7811 - val_loss: 0.9498 - val_accuracy: 0.7622\n",
            "Epoch 41/50\n",
            "329/329 - 2s - loss: 0.8741 - accuracy: 0.7823 - val_loss: 0.9392 - val_accuracy: 0.7618\n",
            "Epoch 42/50\n",
            "329/329 - 2s - loss: 0.8639 - accuracy: 0.7857 - val_loss: 0.9328 - val_accuracy: 0.7656\n",
            "Epoch 43/50\n",
            "329/329 - 2s - loss: 0.8593 - accuracy: 0.7855 - val_loss: 0.9098 - val_accuracy: 0.7739\n",
            "Epoch 44/50\n",
            "329/329 - 2s - loss: 0.8470 - accuracy: 0.7902 - val_loss: 0.9110 - val_accuracy: 0.7714\n",
            "Epoch 45/50\n",
            "329/329 - 2s - loss: 0.8410 - accuracy: 0.7902 - val_loss: 0.9093 - val_accuracy: 0.7722\n",
            "Epoch 46/50\n",
            "329/329 - 2s - loss: 0.8333 - accuracy: 0.7909 - val_loss: 0.9115 - val_accuracy: 0.7690\n",
            "Epoch 47/50\n",
            "329/329 - 2s - loss: 0.8267 - accuracy: 0.7941 - val_loss: 0.9215 - val_accuracy: 0.7641\n",
            "Epoch 48/50\n",
            "329/329 - 2s - loss: 0.8204 - accuracy: 0.7958 - val_loss: 0.8865 - val_accuracy: 0.7789\n",
            "Epoch 49/50\n",
            "329/329 - 2s - loss: 0.8127 - accuracy: 0.7977 - val_loss: 0.8902 - val_accuracy: 0.7764\n",
            "Epoch 50/50\n",
            "329/329 - 3s - loss: 0.8076 - accuracy: 0.7965 - val_loss: 0.8744 - val_accuracy: 0.7837\n",
            "1313/1313 [==============================] - 3s 2ms/step - loss: 0.7918 - accuracy: 0.8025\n",
            "Try 7/10: Best_val_acc: [0.7918456792831421, 0.8024523854255676], lr: 6.573686655138339e-05, Lambda: 0.043087600478391316\n",
            "\n",
            "Epoch 1/50\n",
            "329/329 - 3s - loss: 2.4571 - accuracy: 0.1196 - val_loss: 2.4357 - val_accuracy: 0.1351\n",
            "Epoch 2/50\n",
            "329/329 - 2s - loss: 2.4219 - accuracy: 0.1630 - val_loss: 2.4069 - val_accuracy: 0.1773\n",
            "Epoch 3/50\n",
            "329/329 - 2s - loss: 2.3920 - accuracy: 0.1919 - val_loss: 2.3742 - val_accuracy: 0.2112\n",
            "Epoch 4/50\n",
            "329/329 - 2s - loss: 2.3579 - accuracy: 0.2171 - val_loss: 2.3356 - val_accuracy: 0.2341\n",
            "Epoch 5/50\n",
            "329/329 - 2s - loss: 2.3169 - accuracy: 0.2486 - val_loss: 2.2945 - val_accuracy: 0.2568\n",
            "Epoch 6/50\n",
            "329/329 - 2s - loss: 2.2739 - accuracy: 0.2700 - val_loss: 2.2483 - val_accuracy: 0.2871\n",
            "Epoch 7/50\n",
            "329/329 - 2s - loss: 2.2270 - accuracy: 0.2960 - val_loss: 2.2005 - val_accuracy: 0.3099\n",
            "Epoch 8/50\n",
            "329/329 - 2s - loss: 2.1772 - accuracy: 0.3204 - val_loss: 2.1501 - val_accuracy: 0.3301\n",
            "Epoch 9/50\n",
            "329/329 - 2s - loss: 2.1265 - accuracy: 0.3419 - val_loss: 2.0985 - val_accuracy: 0.3533\n",
            "Epoch 10/50\n",
            "329/329 - 2s - loss: 2.0779 - accuracy: 0.3622 - val_loss: 2.0524 - val_accuracy: 0.3764\n",
            "Epoch 11/50\n",
            "329/329 - 2s - loss: 2.0329 - accuracy: 0.3800 - val_loss: 2.0083 - val_accuracy: 0.3913\n",
            "Epoch 12/50\n",
            "329/329 - 2s - loss: 1.9922 - accuracy: 0.3973 - val_loss: 1.9705 - val_accuracy: 0.4049\n",
            "Epoch 13/50\n",
            "329/329 - 2s - loss: 1.9534 - accuracy: 0.4120 - val_loss: 1.9314 - val_accuracy: 0.4241\n",
            "Epoch 14/50\n",
            "329/329 - 2s - loss: 1.9172 - accuracy: 0.4256 - val_loss: 1.8975 - val_accuracy: 0.4296\n",
            "Epoch 15/50\n",
            "329/329 - 2s - loss: 1.8846 - accuracy: 0.4395 - val_loss: 1.8661 - val_accuracy: 0.4476\n",
            "Epoch 16/50\n",
            "329/329 - 2s - loss: 1.8532 - accuracy: 0.4531 - val_loss: 1.8362 - val_accuracy: 0.4582\n",
            "Epoch 17/50\n",
            "329/329 - 2s - loss: 1.8235 - accuracy: 0.4637 - val_loss: 1.8076 - val_accuracy: 0.4677\n",
            "Epoch 18/50\n",
            "329/329 - 2s - loss: 1.7939 - accuracy: 0.4800 - val_loss: 1.7775 - val_accuracy: 0.4833\n",
            "Epoch 19/50\n",
            "329/329 - 2s - loss: 1.7667 - accuracy: 0.4873 - val_loss: 1.7494 - val_accuracy: 0.4947\n",
            "Epoch 20/50\n",
            "329/329 - 2s - loss: 1.7406 - accuracy: 0.4986 - val_loss: 1.7250 - val_accuracy: 0.5039\n",
            "Epoch 21/50\n",
            "329/329 - 2s - loss: 1.7150 - accuracy: 0.5096 - val_loss: 1.6996 - val_accuracy: 0.5124\n",
            "Epoch 22/50\n",
            "329/329 - 2s - loss: 1.6914 - accuracy: 0.5188 - val_loss: 1.6776 - val_accuracy: 0.5168\n",
            "Epoch 23/50\n",
            "329/329 - 2s - loss: 1.6678 - accuracy: 0.5288 - val_loss: 1.6582 - val_accuracy: 0.5318\n",
            "Epoch 24/50\n",
            "329/329 - 2s - loss: 1.6460 - accuracy: 0.5377 - val_loss: 1.6360 - val_accuracy: 0.5350\n",
            "Epoch 25/50\n",
            "329/329 - 2s - loss: 1.6248 - accuracy: 0.5452 - val_loss: 1.6131 - val_accuracy: 0.5473\n",
            "Epoch 26/50\n",
            "329/329 - 2s - loss: 1.6047 - accuracy: 0.5525 - val_loss: 1.5971 - val_accuracy: 0.5588\n",
            "Epoch 27/50\n",
            "329/329 - 2s - loss: 1.5846 - accuracy: 0.5611 - val_loss: 1.5736 - val_accuracy: 0.5663\n",
            "Epoch 28/50\n",
            "329/329 - 2s - loss: 1.5645 - accuracy: 0.5690 - val_loss: 1.5538 - val_accuracy: 0.5716\n",
            "Epoch 29/50\n",
            "329/329 - 2s - loss: 1.5468 - accuracy: 0.5740 - val_loss: 1.5401 - val_accuracy: 0.5741\n",
            "Epoch 30/50\n",
            "329/329 - 2s - loss: 1.5277 - accuracy: 0.5820 - val_loss: 1.5191 - val_accuracy: 0.5850\n",
            "Epoch 31/50\n",
            "329/329 - 2s - loss: 1.5107 - accuracy: 0.5891 - val_loss: 1.5037 - val_accuracy: 0.5901\n",
            "Epoch 32/50\n",
            "329/329 - 2s - loss: 1.4943 - accuracy: 0.5935 - val_loss: 1.4854 - val_accuracy: 0.5919\n",
            "Epoch 33/50\n",
            "329/329 - 2s - loss: 1.4769 - accuracy: 0.5989 - val_loss: 1.4714 - val_accuracy: 0.5974\n",
            "Epoch 34/50\n",
            "329/329 - 2s - loss: 1.4615 - accuracy: 0.6048 - val_loss: 1.4563 - val_accuracy: 0.6024\n",
            "Epoch 35/50\n",
            "329/329 - 2s - loss: 1.4462 - accuracy: 0.6103 - val_loss: 1.4440 - val_accuracy: 0.6009\n",
            "Epoch 36/50\n",
            "329/329 - 2s - loss: 1.4317 - accuracy: 0.6128 - val_loss: 1.4275 - val_accuracy: 0.6122\n",
            "Epoch 37/50\n",
            "329/329 - 2s - loss: 1.4178 - accuracy: 0.6166 - val_loss: 1.4130 - val_accuracy: 0.6158\n",
            "Epoch 38/50\n",
            "329/329 - 2s - loss: 1.4036 - accuracy: 0.6217 - val_loss: 1.4000 - val_accuracy: 0.6214\n",
            "Epoch 39/50\n",
            "329/329 - 2s - loss: 1.3905 - accuracy: 0.6264 - val_loss: 1.3890 - val_accuracy: 0.6229\n",
            "Epoch 40/50\n",
            "329/329 - 2s - loss: 1.3772 - accuracy: 0.6307 - val_loss: 1.3741 - val_accuracy: 0.6293\n",
            "Epoch 41/50\n",
            "329/329 - 2s - loss: 1.3654 - accuracy: 0.6342 - val_loss: 1.3659 - val_accuracy: 0.6332\n",
            "Epoch 42/50\n",
            "329/329 - 2s - loss: 1.3532 - accuracy: 0.6370 - val_loss: 1.3540 - val_accuracy: 0.6363\n",
            "Epoch 43/50\n",
            "329/329 - 2s - loss: 1.3415 - accuracy: 0.6406 - val_loss: 1.3393 - val_accuracy: 0.6410\n",
            "Epoch 44/50\n",
            "329/329 - 2s - loss: 1.3304 - accuracy: 0.6458 - val_loss: 1.3294 - val_accuracy: 0.6442\n",
            "Epoch 45/50\n",
            "329/329 - 2s - loss: 1.3193 - accuracy: 0.6469 - val_loss: 1.3215 - val_accuracy: 0.6432\n",
            "Epoch 46/50\n",
            "329/329 - 2s - loss: 1.3085 - accuracy: 0.6511 - val_loss: 1.3113 - val_accuracy: 0.6459\n",
            "Epoch 47/50\n",
            "329/329 - 2s - loss: 1.2983 - accuracy: 0.6542 - val_loss: 1.3044 - val_accuracy: 0.6486\n",
            "Epoch 48/50\n",
            "329/329 - 2s - loss: 1.2885 - accuracy: 0.6560 - val_loss: 1.2901 - val_accuracy: 0.6523\n",
            "Epoch 49/50\n",
            "329/329 - 2s - loss: 1.2790 - accuracy: 0.6595 - val_loss: 1.2801 - val_accuracy: 0.6580\n",
            "Epoch 50/50\n",
            "329/329 - 3s - loss: 1.2692 - accuracy: 0.6624 - val_loss: 1.2704 - val_accuracy: 0.6618\n",
            "1313/1313 [==============================] - 3s 3ms/step - loss: 1.2600 - accuracy: 0.6680\n",
            "Try 8/10: Best_val_acc: [1.2599875926971436, 0.6680238246917725], lr: 1.2869165107815029e-05, Lambda: 0.010266030035164242\n",
            "\n",
            "Epoch 1/50\n",
            "329/329 - 2s - loss: 2.2962 - accuracy: 0.1565 - val_loss: 2.2182 - val_accuracy: 0.1878\n",
            "Epoch 2/50\n",
            "329/329 - 2s - loss: 1.8963 - accuracy: 0.3528 - val_loss: 1.6398 - val_accuracy: 0.4512\n",
            "Epoch 3/50\n",
            "329/329 - 2s - loss: 1.4971 - accuracy: 0.5230 - val_loss: 1.3832 - val_accuracy: 0.5801\n",
            "Epoch 4/50\n",
            "329/329 - 2s - loss: 1.3273 - accuracy: 0.5882 - val_loss: 1.2791 - val_accuracy: 0.6054\n",
            "Epoch 5/50\n",
            "329/329 - 2s - loss: 1.2219 - accuracy: 0.6269 - val_loss: 1.2517 - val_accuracy: 0.6208\n",
            "Epoch 6/50\n",
            "329/329 - 2s - loss: 1.1573 - accuracy: 0.6505 - val_loss: 1.1182 - val_accuracy: 0.6634\n",
            "Epoch 7/50\n",
            "329/329 - 2s - loss: 1.0873 - accuracy: 0.6739 - val_loss: 1.0772 - val_accuracy: 0.6797\n",
            "Epoch 8/50\n",
            "329/329 - 2s - loss: 1.0220 - accuracy: 0.6978 - val_loss: 1.0178 - val_accuracy: 0.6971\n",
            "Epoch 9/50\n",
            "329/329 - 2s - loss: 0.9827 - accuracy: 0.7127 - val_loss: 1.0077 - val_accuracy: 0.6997\n",
            "Epoch 10/50\n",
            "329/329 - 3s - loss: 0.9341 - accuracy: 0.7272 - val_loss: 0.9374 - val_accuracy: 0.7267\n",
            "Epoch 11/50\n",
            "329/329 - 4s - loss: 0.9021 - accuracy: 0.7368 - val_loss: 0.9490 - val_accuracy: 0.7217\n",
            "Epoch 12/50\n",
            "329/329 - 4s - loss: 0.8680 - accuracy: 0.7477 - val_loss: 0.9122 - val_accuracy: 0.7355\n",
            "Epoch 13/50\n",
            "329/329 - 2s - loss: 0.8466 - accuracy: 0.7534 - val_loss: 0.8830 - val_accuracy: 0.7488\n",
            "Epoch 14/50\n",
            "329/329 - 2s - loss: 0.8148 - accuracy: 0.7633 - val_loss: 0.8521 - val_accuracy: 0.7549\n",
            "Epoch 15/50\n",
            "329/329 - 2s - loss: 0.8029 - accuracy: 0.7671 - val_loss: 0.8201 - val_accuracy: 0.7668\n",
            "Epoch 16/50\n",
            "329/329 - 2s - loss: 0.7848 - accuracy: 0.7717 - val_loss: 0.8076 - val_accuracy: 0.7703\n",
            "Epoch 17/50\n",
            "329/329 - 2s - loss: 0.7619 - accuracy: 0.7780 - val_loss: 0.8650 - val_accuracy: 0.7428\n",
            "Epoch 18/50\n",
            "329/329 - 2s - loss: 0.7358 - accuracy: 0.7867 - val_loss: 0.8047 - val_accuracy: 0.7716\n",
            "Epoch 19/50\n",
            "329/329 - 2s - loss: 0.7305 - accuracy: 0.7888 - val_loss: 0.8000 - val_accuracy: 0.7703\n",
            "Epoch 20/50\n",
            "329/329 - 2s - loss: 0.7178 - accuracy: 0.7902 - val_loss: 0.7796 - val_accuracy: 0.7790\n",
            "Epoch 21/50\n",
            "329/329 - 2s - loss: 0.6926 - accuracy: 0.7997 - val_loss: 0.7520 - val_accuracy: 0.7884\n",
            "Epoch 22/50\n",
            "329/329 - 2s - loss: 0.6901 - accuracy: 0.7982 - val_loss: 0.8253 - val_accuracy: 0.7594\n",
            "Epoch 23/50\n",
            "329/329 - 2s - loss: 0.6730 - accuracy: 0.8043 - val_loss: 0.7359 - val_accuracy: 0.7918\n",
            "Epoch 24/50\n",
            "329/329 - 2s - loss: 0.6527 - accuracy: 0.8117 - val_loss: 0.7742 - val_accuracy: 0.7812\n",
            "Epoch 25/50\n",
            "329/329 - 2s - loss: 0.6477 - accuracy: 0.8113 - val_loss: 0.7448 - val_accuracy: 0.7879\n",
            "Epoch 26/50\n",
            "329/329 - 2s - loss: 0.6374 - accuracy: 0.8155 - val_loss: 0.7094 - val_accuracy: 0.8014\n",
            "Epoch 27/50\n",
            "329/329 - 2s - loss: 0.6296 - accuracy: 0.8157 - val_loss: 0.7373 - val_accuracy: 0.7942\n",
            "Epoch 28/50\n",
            "329/329 - 2s - loss: 0.6166 - accuracy: 0.8214 - val_loss: 0.7808 - val_accuracy: 0.7736\n",
            "Epoch 29/50\n",
            "329/329 - 2s - loss: 0.6132 - accuracy: 0.8203 - val_loss: 0.7079 - val_accuracy: 0.7986\n",
            "Epoch 30/50\n",
            "329/329 - 2s - loss: 0.5956 - accuracy: 0.8284 - val_loss: 0.7097 - val_accuracy: 0.8014\n",
            "Epoch 31/50\n",
            "329/329 - 2s - loss: 0.5833 - accuracy: 0.8301 - val_loss: 0.6774 - val_accuracy: 0.8110\n",
            "Epoch 32/50\n",
            "329/329 - 2s - loss: 0.5780 - accuracy: 0.8303 - val_loss: 0.6995 - val_accuracy: 0.8018\n",
            "Epoch 33/50\n",
            "329/329 - 2s - loss: 0.5732 - accuracy: 0.8325 - val_loss: 0.6942 - val_accuracy: 0.8067\n",
            "Epoch 34/50\n",
            "329/329 - 2s - loss: 0.5618 - accuracy: 0.8380 - val_loss: 0.6871 - val_accuracy: 0.8069\n",
            "Epoch 35/50\n",
            "329/329 - 2s - loss: 0.5608 - accuracy: 0.8351 - val_loss: 0.6673 - val_accuracy: 0.8143\n",
            "Epoch 36/50\n",
            "329/329 - 2s - loss: 0.5499 - accuracy: 0.8389 - val_loss: 0.6815 - val_accuracy: 0.8115\n",
            "Epoch 37/50\n",
            "329/329 - 2s - loss: 0.5379 - accuracy: 0.8435 - val_loss: 0.6960 - val_accuracy: 0.8042\n",
            "Epoch 38/50\n",
            "329/329 - 2s - loss: 0.5351 - accuracy: 0.8444 - val_loss: 0.7002 - val_accuracy: 0.8033\n",
            "Epoch 39/50\n",
            "329/329 - 2s - loss: 0.5374 - accuracy: 0.8431 - val_loss: 0.7002 - val_accuracy: 0.8036\n",
            "Epoch 40/50\n",
            "329/329 - 2s - loss: 0.5240 - accuracy: 0.8481 - val_loss: 0.6671 - val_accuracy: 0.8120\n",
            "Epoch 41/50\n",
            "329/329 - 2s - loss: 0.5171 - accuracy: 0.8487 - val_loss: 0.6714 - val_accuracy: 0.8098\n",
            "Epoch 42/50\n",
            "329/329 - 2s - loss: 0.5108 - accuracy: 0.8514 - val_loss: 0.7008 - val_accuracy: 0.8062\n",
            "Epoch 43/50\n",
            "329/329 - 2s - loss: 0.5064 - accuracy: 0.8514 - val_loss: 0.6584 - val_accuracy: 0.8152\n",
            "Epoch 44/50\n",
            "329/329 - 2s - loss: 0.5016 - accuracy: 0.8528 - val_loss: 0.6868 - val_accuracy: 0.8074\n",
            "Epoch 45/50\n",
            "329/329 - 2s - loss: 0.5016 - accuracy: 0.8520 - val_loss: 0.6770 - val_accuracy: 0.8109\n",
            "Epoch 46/50\n",
            "329/329 - 2s - loss: 0.4870 - accuracy: 0.8581 - val_loss: 0.6613 - val_accuracy: 0.8141\n",
            "Epoch 47/50\n",
            "329/329 - 2s - loss: 0.4920 - accuracy: 0.8565 - val_loss: 0.6390 - val_accuracy: 0.8211\n",
            "Epoch 48/50\n",
            "329/329 - 2s - loss: 0.4780 - accuracy: 0.8591 - val_loss: 0.6494 - val_accuracy: 0.8161\n",
            "Epoch 49/50\n",
            "329/329 - 2s - loss: 0.4789 - accuracy: 0.8582 - val_loss: 0.6447 - val_accuracy: 0.8196\n",
            "Epoch 50/50\n",
            "329/329 - 2s - loss: 0.4727 - accuracy: 0.8617 - val_loss: 0.6685 - val_accuracy: 0.8150\n",
            "1313/1313 [==============================] - 3s 2ms/step - loss: 0.4713 - accuracy: 0.8607\n",
            "Try 9/10: Best_val_acc: [0.4712737500667572, 0.8606904745101929], lr: 0.00046689498537088925, Lambda: 0.004743178681046317\n",
            "\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(1)\n",
        "tf.random.set_seed(2)\n",
        "for k in range(1,10):\n",
        "    lr = math.pow(10, np.random.uniform(-5.0, -1.0))\n",
        "    Lambda = math.pow(10, np.random.uniform(-4,-1))\n",
        "    best_acc = train_and_test_loop1(50, lr, Lambda, False)\n",
        "    print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 10, best_acc, lr, Lambda))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbfugK7CI0Du"
      },
      "source": [
        "### As you can see from above, Case 1, 5 and 9 yields good accuracy. It is better to focus on those values for learning rate and Lambda\n",
        "\n",
        "### Now run finer search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOBdn-x8I0Du",
        "outputId": "bb287b66-79f3-4a0f-d1a3-f3628bc18c55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "329/329 - 2s - loss: 2.2207 - accuracy: 0.2105 - val_loss: 1.9634 - val_accuracy: 0.3440\n",
            "Epoch 2/50\n",
            "329/329 - 3s - loss: 1.6909 - accuracy: 0.4510 - val_loss: 1.5074 - val_accuracy: 0.5226\n",
            "Epoch 3/50\n",
            "329/329 - 3s - loss: 1.4212 - accuracy: 0.5629 - val_loss: 1.3824 - val_accuracy: 0.5741\n",
            "Epoch 4/50\n",
            "329/329 - 2s - loss: 1.2814 - accuracy: 0.6191 - val_loss: 1.1978 - val_accuracy: 0.6474\n",
            "Epoch 5/50\n",
            "329/329 - 2s - loss: 1.1779 - accuracy: 0.6556 - val_loss: 1.1631 - val_accuracy: 0.6579\n",
            "Epoch 6/50\n",
            "329/329 - 2s - loss: 1.1134 - accuracy: 0.6744 - val_loss: 1.0773 - val_accuracy: 0.6848\n",
            "Epoch 7/50\n",
            "329/329 - 2s - loss: 1.0546 - accuracy: 0.6944 - val_loss: 1.0824 - val_accuracy: 0.6829\n",
            "Epoch 8/50\n",
            "329/329 - 2s - loss: 1.0153 - accuracy: 0.7030 - val_loss: 1.0265 - val_accuracy: 0.6991\n",
            "Epoch 9/50\n",
            "329/329 - 2s - loss: 0.9820 - accuracy: 0.7150 - val_loss: 1.0362 - val_accuracy: 0.6979\n",
            "Epoch 10/50\n",
            "329/329 - 2s - loss: 0.9468 - accuracy: 0.7280 - val_loss: 0.9527 - val_accuracy: 0.7242\n",
            "Epoch 11/50\n",
            "329/329 - 2s - loss: 0.9257 - accuracy: 0.7332 - val_loss: 0.9729 - val_accuracy: 0.7186\n",
            "Epoch 12/50\n",
            "329/329 - 2s - loss: 0.8978 - accuracy: 0.7407 - val_loss: 0.9544 - val_accuracy: 0.7242\n",
            "Epoch 13/50\n",
            "329/329 - 2s - loss: 0.8829 - accuracy: 0.7452 - val_loss: 0.9171 - val_accuracy: 0.7394\n",
            "Epoch 14/50\n",
            "329/329 - 2s - loss: 0.8582 - accuracy: 0.7539 - val_loss: 0.8652 - val_accuracy: 0.7545\n",
            "Epoch 15/50\n",
            "329/329 - 2s - loss: 0.8487 - accuracy: 0.7564 - val_loss: 0.8773 - val_accuracy: 0.7513\n",
            "Epoch 16/50\n",
            "329/329 - 2s - loss: 0.8257 - accuracy: 0.7613 - val_loss: 0.8522 - val_accuracy: 0.7591\n",
            "Epoch 17/50\n",
            "329/329 - 2s - loss: 0.8054 - accuracy: 0.7689 - val_loss: 0.8826 - val_accuracy: 0.7443\n",
            "Epoch 18/50\n",
            "329/329 - 2s - loss: 0.7966 - accuracy: 0.7717 - val_loss: 0.8525 - val_accuracy: 0.7581\n",
            "Epoch 19/50\n",
            "329/329 - 2s - loss: 0.7847 - accuracy: 0.7738 - val_loss: 0.8497 - val_accuracy: 0.7582\n",
            "Epoch 20/50\n",
            "329/329 - 2s - loss: 0.7691 - accuracy: 0.7793 - val_loss: 0.8003 - val_accuracy: 0.7758\n",
            "Epoch 21/50\n",
            "329/329 - 2s - loss: 0.7527 - accuracy: 0.7849 - val_loss: 0.8079 - val_accuracy: 0.7716\n",
            "Epoch 22/50\n",
            "329/329 - 2s - loss: 0.7397 - accuracy: 0.7862 - val_loss: 0.7898 - val_accuracy: 0.7787\n",
            "Epoch 23/50\n",
            "329/329 - 2s - loss: 0.7302 - accuracy: 0.7906 - val_loss: 0.7829 - val_accuracy: 0.7788\n",
            "Epoch 24/50\n",
            "329/329 - 2s - loss: 0.7162 - accuracy: 0.7969 - val_loss: 0.7910 - val_accuracy: 0.7782\n",
            "Epoch 25/50\n",
            "329/329 - 2s - loss: 0.7034 - accuracy: 0.7996 - val_loss: 0.7733 - val_accuracy: 0.7832\n",
            "Epoch 26/50\n",
            "329/329 - 2s - loss: 0.6980 - accuracy: 0.7989 - val_loss: 0.7517 - val_accuracy: 0.7909\n",
            "Epoch 27/50\n",
            "329/329 - 2s - loss: 0.6842 - accuracy: 0.8047 - val_loss: 0.7819 - val_accuracy: 0.7779\n",
            "Epoch 28/50\n",
            "329/329 - 2s - loss: 0.6774 - accuracy: 0.8057 - val_loss: 0.7662 - val_accuracy: 0.7815\n",
            "Epoch 29/50\n",
            "329/329 - 2s - loss: 0.6685 - accuracy: 0.8099 - val_loss: 0.7974 - val_accuracy: 0.7723\n",
            "Epoch 30/50\n",
            "329/329 - 2s - loss: 0.6545 - accuracy: 0.8125 - val_loss: 0.7489 - val_accuracy: 0.7883\n",
            "Epoch 31/50\n",
            "329/329 - 2s - loss: 0.6475 - accuracy: 0.8151 - val_loss: 0.7076 - val_accuracy: 0.8048\n",
            "Epoch 32/50\n",
            "329/329 - 2s - loss: 0.6344 - accuracy: 0.8178 - val_loss: 0.7407 - val_accuracy: 0.7918\n",
            "Epoch 33/50\n",
            "329/329 - 2s - loss: 0.6258 - accuracy: 0.8229 - val_loss: 0.7275 - val_accuracy: 0.7947\n",
            "Epoch 34/50\n",
            "329/329 - 2s - loss: 0.6140 - accuracy: 0.8248 - val_loss: 0.7357 - val_accuracy: 0.7943\n",
            "Epoch 35/50\n",
            "329/329 - 2s - loss: 0.6078 - accuracy: 0.8274 - val_loss: 0.7218 - val_accuracy: 0.8002\n",
            "Epoch 36/50\n",
            "329/329 - 2s - loss: 0.6019 - accuracy: 0.8273 - val_loss: 0.7311 - val_accuracy: 0.7965\n",
            "Epoch 37/50\n",
            "329/329 - 2s - loss: 0.5930 - accuracy: 0.8299 - val_loss: 0.7173 - val_accuracy: 0.7977\n",
            "Epoch 38/50\n",
            "329/329 - 2s - loss: 0.5875 - accuracy: 0.8332 - val_loss: 0.6948 - val_accuracy: 0.8077\n",
            "Epoch 39/50\n",
            "329/329 - 2s - loss: 0.5811 - accuracy: 0.8350 - val_loss: 0.7202 - val_accuracy: 0.7994\n",
            "Epoch 40/50\n",
            "329/329 - 2s - loss: 0.5723 - accuracy: 0.8379 - val_loss: 0.6795 - val_accuracy: 0.8115\n",
            "Epoch 41/50\n",
            "329/329 - 2s - loss: 0.5680 - accuracy: 0.8389 - val_loss: 0.6778 - val_accuracy: 0.8106\n",
            "Epoch 42/50\n",
            "329/329 - 2s - loss: 0.5597 - accuracy: 0.8414 - val_loss: 0.6708 - val_accuracy: 0.8163\n",
            "Epoch 43/50\n",
            "329/329 - 2s - loss: 0.5479 - accuracy: 0.8452 - val_loss: 0.6771 - val_accuracy: 0.8102\n",
            "Epoch 44/50\n",
            "329/329 - 2s - loss: 0.5461 - accuracy: 0.8457 - val_loss: 0.6846 - val_accuracy: 0.8096\n",
            "Epoch 45/50\n",
            "329/329 - 2s - loss: 0.5417 - accuracy: 0.8446 - val_loss: 0.6901 - val_accuracy: 0.8110\n",
            "Epoch 46/50\n",
            "329/329 - 2s - loss: 0.5299 - accuracy: 0.8511 - val_loss: 0.6566 - val_accuracy: 0.8210\n",
            "Epoch 47/50\n",
            "329/329 - 2s - loss: 0.5299 - accuracy: 0.8488 - val_loss: 0.6727 - val_accuracy: 0.8148\n",
            "Epoch 48/50\n",
            "329/329 - 2s - loss: 0.5200 - accuracy: 0.8512 - val_loss: 0.6533 - val_accuracy: 0.8208\n",
            "Epoch 49/50\n",
            "329/329 - 2s - loss: 0.5155 - accuracy: 0.8543 - val_loss: 0.6884 - val_accuracy: 0.8069\n",
            "Epoch 50/50\n",
            "329/329 - 2s - loss: 0.5089 - accuracy: 0.8550 - val_loss: 0.6907 - val_accuracy: 0.8088\n",
            "1313/1313 [==============================] - 2s 2ms/step - loss: 0.5260 - accuracy: 0.8478\n",
            "Try 1/10: Best_val_acc: [0.5260182619094849, 0.8477857112884521], lr: 0.00026122937099604316, Lambda: 0.002758347554916672\n",
            "\n",
            "Epoch 1/50\n",
            "329/329 - 2s - loss: 2.2399 - accuracy: 0.1884 - val_loss: 2.0966 - val_accuracy: 0.3011\n",
            "Epoch 2/50\n",
            "329/329 - 2s - loss: 1.9153 - accuracy: 0.3804 - val_loss: 1.7197 - val_accuracy: 0.4672\n",
            "Epoch 3/50\n",
            "329/329 - 2s - loss: 1.6074 - accuracy: 0.4952 - val_loss: 1.4873 - val_accuracy: 0.5465\n",
            "Epoch 4/50\n",
            "329/329 - 2s - loss: 1.4385 - accuracy: 0.5548 - val_loss: 1.3597 - val_accuracy: 0.5827\n",
            "Epoch 5/50\n",
            "329/329 - 2s - loss: 1.3297 - accuracy: 0.5941 - val_loss: 1.2721 - val_accuracy: 0.6197\n",
            "Epoch 6/50\n",
            "329/329 - 2s - loss: 1.2516 - accuracy: 0.6237 - val_loss: 1.2088 - val_accuracy: 0.6358\n",
            "Epoch 7/50\n",
            "329/329 - 2s - loss: 1.1943 - accuracy: 0.6391 - val_loss: 1.1569 - val_accuracy: 0.6593\n",
            "Epoch 8/50\n",
            "329/329 - 2s - loss: 1.1452 - accuracy: 0.6560 - val_loss: 1.1178 - val_accuracy: 0.6627\n",
            "Epoch 9/50\n",
            "329/329 - 2s - loss: 1.1132 - accuracy: 0.6662 - val_loss: 1.1463 - val_accuracy: 0.6535\n",
            "Epoch 10/50\n",
            "329/329 - 2s - loss: 1.0768 - accuracy: 0.6773 - val_loss: 1.0568 - val_accuracy: 0.6907\n",
            "Epoch 11/50\n",
            "329/329 - 2s - loss: 1.0502 - accuracy: 0.6859 - val_loss: 1.0452 - val_accuracy: 0.6921\n",
            "Epoch 12/50\n",
            "329/329 - 2s - loss: 1.0262 - accuracy: 0.6939 - val_loss: 1.0490 - val_accuracy: 0.6852\n",
            "Epoch 13/50\n",
            "329/329 - 2s - loss: 0.9963 - accuracy: 0.7038 - val_loss: 0.9972 - val_accuracy: 0.7032\n",
            "Epoch 14/50\n",
            "329/329 - 2s - loss: 0.9772 - accuracy: 0.7080 - val_loss: 0.9717 - val_accuracy: 0.7156\n",
            "Epoch 15/50\n",
            "329/329 - 2s - loss: 0.9604 - accuracy: 0.7129 - val_loss: 0.9587 - val_accuracy: 0.7173\n",
            "Epoch 16/50\n",
            "329/329 - 2s - loss: 0.9387 - accuracy: 0.7217 - val_loss: 0.9480 - val_accuracy: 0.7224\n",
            "Epoch 17/50\n",
            "329/329 - 2s - loss: 0.9192 - accuracy: 0.7270 - val_loss: 0.9532 - val_accuracy: 0.7170\n",
            "Epoch 18/50\n",
            "329/329 - 2s - loss: 0.9022 - accuracy: 0.7324 - val_loss: 0.9400 - val_accuracy: 0.7164\n",
            "Epoch 19/50\n",
            "329/329 - 2s - loss: 0.8943 - accuracy: 0.7326 - val_loss: 0.9224 - val_accuracy: 0.7272\n",
            "Epoch 20/50\n",
            "329/329 - 2s - loss: 0.8709 - accuracy: 0.7411 - val_loss: 0.9004 - val_accuracy: 0.7310\n",
            "Epoch 21/50\n",
            "329/329 - 2s - loss: 0.8614 - accuracy: 0.7439 - val_loss: 0.8854 - val_accuracy: 0.7384\n",
            "Epoch 22/50\n",
            "329/329 - 2s - loss: 0.8443 - accuracy: 0.7496 - val_loss: 0.9178 - val_accuracy: 0.7289\n",
            "Epoch 23/50\n",
            "329/329 - 2s - loss: 0.8297 - accuracy: 0.7536 - val_loss: 0.8763 - val_accuracy: 0.7379\n",
            "Epoch 24/50\n",
            "329/329 - 2s - loss: 0.8185 - accuracy: 0.7547 - val_loss: 0.8556 - val_accuracy: 0.7511\n",
            "Epoch 25/50\n",
            "329/329 - 2s - loss: 0.8065 - accuracy: 0.7609 - val_loss: 0.8462 - val_accuracy: 0.7532\n",
            "Epoch 26/50\n",
            "329/329 - 2s - loss: 0.7992 - accuracy: 0.7629 - val_loss: 0.8317 - val_accuracy: 0.7579\n",
            "Epoch 27/50\n",
            "329/329 - 2s - loss: 0.7873 - accuracy: 0.7663 - val_loss: 0.8305 - val_accuracy: 0.7600\n",
            "Epoch 28/50\n",
            "329/329 - 3s - loss: 0.7741 - accuracy: 0.7706 - val_loss: 0.8236 - val_accuracy: 0.7597\n",
            "Epoch 29/50\n",
            "329/329 - 2s - loss: 0.7655 - accuracy: 0.7710 - val_loss: 0.8562 - val_accuracy: 0.7459\n",
            "Epoch 30/50\n",
            "329/329 - 2s - loss: 0.7560 - accuracy: 0.7764 - val_loss: 0.8004 - val_accuracy: 0.7663\n",
            "Epoch 31/50\n",
            "329/329 - 3s - loss: 0.7457 - accuracy: 0.7771 - val_loss: 0.8166 - val_accuracy: 0.7631\n",
            "Epoch 32/50\n",
            "329/329 - 2s - loss: 0.7414 - accuracy: 0.7789 - val_loss: 0.8055 - val_accuracy: 0.7663\n",
            "Epoch 33/50\n",
            "329/329 - 3s - loss: 0.7263 - accuracy: 0.7841 - val_loss: 0.7858 - val_accuracy: 0.7718\n",
            "Epoch 34/50\n",
            "329/329 - 3s - loss: 0.7214 - accuracy: 0.7843 - val_loss: 0.7830 - val_accuracy: 0.7706\n",
            "Epoch 35/50\n",
            "329/329 - 3s - loss: 0.7113 - accuracy: 0.7888 - val_loss: 0.7870 - val_accuracy: 0.7701\n",
            "Epoch 36/50\n",
            "329/329 - 2s - loss: 0.7062 - accuracy: 0.7907 - val_loss: 0.7682 - val_accuracy: 0.7760\n",
            "Epoch 37/50\n",
            "329/329 - 2s - loss: 0.6929 - accuracy: 0.7942 - val_loss: 0.7915 - val_accuracy: 0.7686\n",
            "Epoch 38/50\n",
            "329/329 - 2s - loss: 0.6905 - accuracy: 0.7934 - val_loss: 0.7563 - val_accuracy: 0.7820\n",
            "Epoch 39/50\n",
            "329/329 - 2s - loss: 0.6816 - accuracy: 0.7970 - val_loss: 0.7530 - val_accuracy: 0.7838\n",
            "Epoch 40/50\n",
            "329/329 - 2s - loss: 0.6786 - accuracy: 0.7979 - val_loss: 0.7912 - val_accuracy: 0.7691\n",
            "Epoch 41/50\n",
            "329/329 - 2s - loss: 0.6660 - accuracy: 0.8019 - val_loss: 0.7858 - val_accuracy: 0.7673\n",
            "Epoch 42/50\n",
            "329/329 - 2s - loss: 0.6594 - accuracy: 0.8035 - val_loss: 0.7493 - val_accuracy: 0.7839\n",
            "Epoch 43/50\n",
            "329/329 - 2s - loss: 0.6563 - accuracy: 0.8038 - val_loss: 0.7497 - val_accuracy: 0.7842\n",
            "Epoch 44/50\n",
            "329/329 - 2s - loss: 0.6485 - accuracy: 0.8079 - val_loss: 0.7498 - val_accuracy: 0.7834\n",
            "Epoch 45/50\n",
            "329/329 - 2s - loss: 0.6437 - accuracy: 0.8092 - val_loss: 0.7343 - val_accuracy: 0.7877\n",
            "Epoch 46/50\n",
            "329/329 - 2s - loss: 0.6358 - accuracy: 0.8120 - val_loss: 0.7397 - val_accuracy: 0.7843\n",
            "Epoch 47/50\n",
            "329/329 - 2s - loss: 0.6333 - accuracy: 0.8122 - val_loss: 0.7507 - val_accuracy: 0.7798\n",
            "Epoch 48/50\n",
            "329/329 - 2s - loss: 0.6256 - accuracy: 0.8141 - val_loss: 0.7549 - val_accuracy: 0.7810\n",
            "Epoch 49/50\n",
            "329/329 - 2s - loss: 0.6246 - accuracy: 0.8149 - val_loss: 0.7258 - val_accuracy: 0.7902\n",
            "Epoch 50/50\n",
            "329/329 - 2s - loss: 0.6161 - accuracy: 0.8162 - val_loss: 0.7330 - val_accuracy: 0.7871\n",
            "1313/1313 [==============================] - 2s 2ms/step - loss: 0.6096 - accuracy: 0.8186\n",
            "Try 2/10: Best_val_acc: [0.6095544695854187, 0.8186190724372864], lr: 0.00010002633924311294, Lambda: 0.00040240664647146085\n",
            "\n",
            "Epoch 1/50\n",
            "329/329 - 2s - loss: 2.2153 - accuracy: 0.1829 - val_loss: 2.0906 - val_accuracy: 0.2229\n",
            "Epoch 2/50\n",
            "329/329 - 2s - loss: 1.8538 - accuracy: 0.3767 - val_loss: 1.6786 - val_accuracy: 0.4753\n",
            "Epoch 3/50\n",
            "329/329 - 2s - loss: 1.5599 - accuracy: 0.5130 - val_loss: 1.4409 - val_accuracy: 0.5628\n",
            "Epoch 4/50\n",
            "329/329 - 2s - loss: 1.3788 - accuracy: 0.5774 - val_loss: 1.3388 - val_accuracy: 0.5832\n",
            "Epoch 5/50\n",
            "329/329 - 2s - loss: 1.2660 - accuracy: 0.6127 - val_loss: 1.2224 - val_accuracy: 0.6282\n",
            "Epoch 6/50\n",
            "329/329 - 2s - loss: 1.1919 - accuracy: 0.6357 - val_loss: 1.1631 - val_accuracy: 0.6474\n",
            "Epoch 7/50\n",
            "329/329 - 2s - loss: 1.1408 - accuracy: 0.6530 - val_loss: 1.1180 - val_accuracy: 0.6681\n",
            "Epoch 8/50\n",
            "329/329 - 2s - loss: 1.1068 - accuracy: 0.6635 - val_loss: 1.1021 - val_accuracy: 0.6646\n",
            "Epoch 9/50\n",
            "329/329 - 2s - loss: 1.0707 - accuracy: 0.6761 - val_loss: 1.1349 - val_accuracy: 0.6414\n",
            "Epoch 10/50\n",
            "329/329 - 2s - loss: 1.0478 - accuracy: 0.6842 - val_loss: 1.0530 - val_accuracy: 0.6808\n",
            "Epoch 11/50\n",
            "329/329 - 2s - loss: 1.0216 - accuracy: 0.6916 - val_loss: 1.0521 - val_accuracy: 0.6812\n",
            "Epoch 12/50\n",
            "329/329 - 2s - loss: 0.9965 - accuracy: 0.6990 - val_loss: 0.9969 - val_accuracy: 0.7001\n",
            "Epoch 13/50\n",
            "329/329 - 2s - loss: 0.9707 - accuracy: 0.7078 - val_loss: 0.9964 - val_accuracy: 0.7053\n",
            "Epoch 14/50\n",
            "329/329 - 2s - loss: 0.9531 - accuracy: 0.7124 - val_loss: 0.9617 - val_accuracy: 0.7088\n",
            "Epoch 15/50\n",
            "329/329 - 2s - loss: 0.9411 - accuracy: 0.7161 - val_loss: 0.9458 - val_accuracy: 0.7178\n",
            "Epoch 16/50\n",
            "329/329 - 2s - loss: 0.9166 - accuracy: 0.7245 - val_loss: 0.9286 - val_accuracy: 0.7227\n",
            "Epoch 17/50\n",
            "329/329 - 2s - loss: 0.9018 - accuracy: 0.7292 - val_loss: 0.9377 - val_accuracy: 0.7172\n",
            "Epoch 18/50\n",
            "329/329 - 2s - loss: 0.8831 - accuracy: 0.7344 - val_loss: 0.9267 - val_accuracy: 0.7203\n",
            "Epoch 19/50\n",
            "329/329 - 2s - loss: 0.8703 - accuracy: 0.7370 - val_loss: 0.9264 - val_accuracy: 0.7163\n",
            "Epoch 20/50\n",
            "329/329 - 2s - loss: 0.8524 - accuracy: 0.7456 - val_loss: 0.8798 - val_accuracy: 0.7376\n",
            "Epoch 21/50\n",
            "329/329 - 2s - loss: 0.8445 - accuracy: 0.7443 - val_loss: 0.9031 - val_accuracy: 0.7259\n",
            "Epoch 22/50\n",
            "329/329 - 2s - loss: 0.8288 - accuracy: 0.7489 - val_loss: 0.8767 - val_accuracy: 0.7377\n",
            "Epoch 23/50\n",
            "329/329 - 2s - loss: 0.8168 - accuracy: 0.7533 - val_loss: 0.8487 - val_accuracy: 0.7478\n",
            "Epoch 24/50\n",
            "329/329 - 2s - loss: 0.8033 - accuracy: 0.7563 - val_loss: 0.8468 - val_accuracy: 0.7462\n",
            "Epoch 25/50\n",
            "329/329 - 2s - loss: 0.7905 - accuracy: 0.7616 - val_loss: 0.8577 - val_accuracy: 0.7439\n",
            "Epoch 26/50\n",
            "329/329 - 2s - loss: 0.7845 - accuracy: 0.7634 - val_loss: 0.8229 - val_accuracy: 0.7545\n",
            "Epoch 27/50\n",
            "329/329 - 2s - loss: 0.7759 - accuracy: 0.7666 - val_loss: 0.8414 - val_accuracy: 0.7508\n",
            "Epoch 28/50\n",
            "329/329 - 2s - loss: 0.7621 - accuracy: 0.7694 - val_loss: 0.8190 - val_accuracy: 0.7561\n",
            "Epoch 29/50\n",
            "329/329 - 2s - loss: 0.7554 - accuracy: 0.7723 - val_loss: 0.8067 - val_accuracy: 0.7589\n",
            "Epoch 30/50\n",
            "329/329 - 2s - loss: 0.7451 - accuracy: 0.7751 - val_loss: 0.8001 - val_accuracy: 0.7632\n",
            "Epoch 31/50\n",
            "329/329 - 2s - loss: 0.7373 - accuracy: 0.7768 - val_loss: 0.8172 - val_accuracy: 0.7524\n",
            "Epoch 32/50\n",
            "329/329 - 2s - loss: 0.7271 - accuracy: 0.7795 - val_loss: 0.8086 - val_accuracy: 0.7583\n",
            "Epoch 33/50\n",
            "329/329 - 2s - loss: 0.7155 - accuracy: 0.7830 - val_loss: 0.7978 - val_accuracy: 0.7632\n",
            "Epoch 34/50\n",
            "329/329 - 3s - loss: 0.7097 - accuracy: 0.7854 - val_loss: 0.7973 - val_accuracy: 0.7650\n",
            "Epoch 35/50\n",
            "329/329 - 3s - loss: 0.7050 - accuracy: 0.7868 - val_loss: 0.7850 - val_accuracy: 0.7663\n",
            "Epoch 36/50\n",
            "329/329 - 2s - loss: 0.6916 - accuracy: 0.7927 - val_loss: 0.7826 - val_accuracy: 0.7680\n",
            "Epoch 37/50\n",
            "329/329 - 2s - loss: 0.6861 - accuracy: 0.7939 - val_loss: 0.7645 - val_accuracy: 0.7744\n",
            "Epoch 38/50\n",
            "329/329 - 2s - loss: 0.6786 - accuracy: 0.7944 - val_loss: 0.7450 - val_accuracy: 0.7789\n",
            "Epoch 39/50\n",
            "329/329 - 2s - loss: 0.6750 - accuracy: 0.7962 - val_loss: 0.7475 - val_accuracy: 0.7787\n",
            "Epoch 40/50\n",
            "329/329 - 2s - loss: 0.6659 - accuracy: 0.7995 - val_loss: 0.7520 - val_accuracy: 0.7788\n",
            "Epoch 41/50\n",
            "329/329 - 2s - loss: 0.6611 - accuracy: 0.8005 - val_loss: 0.7454 - val_accuracy: 0.7792\n",
            "Epoch 42/50\n",
            "329/329 - 2s - loss: 0.6554 - accuracy: 0.8013 - val_loss: 0.7618 - val_accuracy: 0.7752\n",
            "Epoch 43/50\n",
            "329/329 - 2s - loss: 0.6454 - accuracy: 0.8056 - val_loss: 0.7333 - val_accuracy: 0.7841\n",
            "Epoch 44/50\n",
            "329/329 - 2s - loss: 0.6372 - accuracy: 0.8071 - val_loss: 0.7530 - val_accuracy: 0.7758\n",
            "Epoch 45/50\n",
            "329/329 - 2s - loss: 0.6336 - accuracy: 0.8080 - val_loss: 0.7353 - val_accuracy: 0.7823\n",
            "Epoch 46/50\n",
            "329/329 - 2s - loss: 0.6242 - accuracy: 0.8114 - val_loss: 0.7418 - val_accuracy: 0.7830\n",
            "Epoch 47/50\n",
            "329/329 - 2s - loss: 0.6209 - accuracy: 0.8125 - val_loss: 0.7311 - val_accuracy: 0.7854\n",
            "Epoch 48/50\n",
            "329/329 - 2s - loss: 0.6096 - accuracy: 0.8143 - val_loss: 0.7257 - val_accuracy: 0.7874\n",
            "Epoch 49/50\n",
            "329/329 - 2s - loss: 0.6097 - accuracy: 0.8162 - val_loss: 0.7159 - val_accuracy: 0.7916\n",
            "Epoch 50/50\n",
            "329/329 - 2s - loss: 0.6019 - accuracy: 0.8180 - val_loss: 0.7283 - val_accuracy: 0.7867\n",
            "1313/1313 [==============================] - 2s 2ms/step - loss: 0.6017 - accuracy: 0.8190\n",
            "Try 3/10: Best_val_acc: [0.601729154586792, 0.8189761638641357], lr: 0.00014020254295554104, Lambda: 0.0001529949829431263\n",
            "\n",
            "Epoch 1/50\n",
            "329/329 - 2s - loss: 2.2542 - accuracy: 0.1591 - val_loss: 2.1238 - val_accuracy: 0.2604\n",
            "Epoch 2/50\n",
            "329/329 - 2s - loss: 1.9296 - accuracy: 0.3618 - val_loss: 1.7313 - val_accuracy: 0.4388\n",
            "Epoch 3/50\n",
            "329/329 - 2s - loss: 1.5985 - accuracy: 0.4839 - val_loss: 1.4729 - val_accuracy: 0.5415\n",
            "Epoch 4/50\n",
            "329/329 - 2s - loss: 1.4006 - accuracy: 0.5587 - val_loss: 1.3133 - val_accuracy: 0.5953\n",
            "Epoch 5/50\n",
            "329/329 - 2s - loss: 1.2899 - accuracy: 0.5985 - val_loss: 1.2652 - val_accuracy: 0.6021\n",
            "Epoch 6/50\n",
            "329/329 - 2s - loss: 1.2210 - accuracy: 0.6228 - val_loss: 1.1848 - val_accuracy: 0.6416\n",
            "Epoch 7/50\n",
            "329/329 - 2s - loss: 1.1678 - accuracy: 0.6418 - val_loss: 1.1560 - val_accuracy: 0.6476\n",
            "Epoch 8/50\n",
            "329/329 - 2s - loss: 1.1224 - accuracy: 0.6555 - val_loss: 1.1192 - val_accuracy: 0.6598\n",
            "Epoch 9/50\n",
            "329/329 - 2s - loss: 1.0898 - accuracy: 0.6667 - val_loss: 1.1236 - val_accuracy: 0.6520\n",
            "Epoch 10/50\n",
            "329/329 - 2s - loss: 1.0584 - accuracy: 0.6771 - val_loss: 1.0553 - val_accuracy: 0.6822\n",
            "Epoch 11/50\n",
            "329/329 - 2s - loss: 1.0253 - accuracy: 0.6882 - val_loss: 1.0521 - val_accuracy: 0.6797\n",
            "Epoch 12/50\n",
            "329/329 - 2s - loss: 1.0026 - accuracy: 0.6950 - val_loss: 1.0141 - val_accuracy: 0.6973\n",
            "Epoch 13/50\n",
            "329/329 - 2s - loss: 0.9679 - accuracy: 0.7069 - val_loss: 0.9752 - val_accuracy: 0.7106\n",
            "Epoch 14/50\n",
            "329/329 - 2s - loss: 0.9452 - accuracy: 0.7135 - val_loss: 0.9738 - val_accuracy: 0.7088\n",
            "Epoch 15/50\n",
            "329/329 - 2s - loss: 0.9258 - accuracy: 0.7216 - val_loss: 0.9391 - val_accuracy: 0.7216\n",
            "Epoch 16/50\n",
            "329/329 - 2s - loss: 0.8995 - accuracy: 0.7295 - val_loss: 0.9225 - val_accuracy: 0.7230\n",
            "Epoch 17/50\n",
            "329/329 - 2s - loss: 0.8838 - accuracy: 0.7320 - val_loss: 0.9242 - val_accuracy: 0.7262\n",
            "Epoch 18/50\n",
            "329/329 - 2s - loss: 0.8653 - accuracy: 0.7391 - val_loss: 0.8952 - val_accuracy: 0.7367\n",
            "Epoch 19/50\n",
            "329/329 - 2s - loss: 0.8497 - accuracy: 0.7451 - val_loss: 0.9106 - val_accuracy: 0.7291\n",
            "Epoch 20/50\n",
            "329/329 - 2s - loss: 0.8313 - accuracy: 0.7508 - val_loss: 0.8734 - val_accuracy: 0.7410\n",
            "Epoch 21/50\n",
            "329/329 - 2s - loss: 0.8144 - accuracy: 0.7555 - val_loss: 0.8885 - val_accuracy: 0.7340\n",
            "Epoch 22/50\n",
            "329/329 - 2s - loss: 0.7967 - accuracy: 0.7616 - val_loss: 0.8693 - val_accuracy: 0.7433\n",
            "Epoch 23/50\n",
            "329/329 - 2s - loss: 0.7846 - accuracy: 0.7654 - val_loss: 0.8445 - val_accuracy: 0.7506\n",
            "Epoch 24/50\n",
            "329/329 - 2s - loss: 0.7741 - accuracy: 0.7670 - val_loss: 0.8278 - val_accuracy: 0.7557\n",
            "Epoch 25/50\n",
            "329/329 - 2s - loss: 0.7583 - accuracy: 0.7744 - val_loss: 0.8448 - val_accuracy: 0.7508\n",
            "Epoch 26/50\n",
            "329/329 - 2s - loss: 0.7517 - accuracy: 0.7769 - val_loss: 0.7998 - val_accuracy: 0.7668\n",
            "Epoch 27/50\n",
            "329/329 - 2s - loss: 0.7431 - accuracy: 0.7779 - val_loss: 0.8169 - val_accuracy: 0.7606\n",
            "Epoch 28/50\n",
            "329/329 - 2s - loss: 0.7306 - accuracy: 0.7823 - val_loss: 0.7916 - val_accuracy: 0.7677\n",
            "Epoch 29/50\n",
            "329/329 - 2s - loss: 0.7208 - accuracy: 0.7858 - val_loss: 0.7990 - val_accuracy: 0.7645\n",
            "Epoch 30/50\n",
            "329/329 - 2s - loss: 0.7076 - accuracy: 0.7880 - val_loss: 0.7738 - val_accuracy: 0.7738\n",
            "Epoch 31/50\n",
            "329/329 - 2s - loss: 0.6966 - accuracy: 0.7913 - val_loss: 0.8016 - val_accuracy: 0.7671\n",
            "Epoch 32/50\n",
            "329/329 - 2s - loss: 0.6916 - accuracy: 0.7943 - val_loss: 0.7780 - val_accuracy: 0.7747\n",
            "Epoch 33/50\n",
            "329/329 - 2s - loss: 0.6780 - accuracy: 0.7975 - val_loss: 0.7702 - val_accuracy: 0.7795\n",
            "Epoch 34/50\n",
            "329/329 - 2s - loss: 0.6734 - accuracy: 0.7991 - val_loss: 0.7824 - val_accuracy: 0.7736\n",
            "Epoch 35/50\n",
            "329/329 - 2s - loss: 0.6648 - accuracy: 0.8012 - val_loss: 0.7538 - val_accuracy: 0.7790\n",
            "Epoch 36/50\n",
            "329/329 - 2s - loss: 0.6545 - accuracy: 0.8060 - val_loss: 0.7503 - val_accuracy: 0.7852\n",
            "Epoch 37/50\n",
            "329/329 - 2s - loss: 0.6478 - accuracy: 0.8081 - val_loss: 0.7480 - val_accuracy: 0.7831\n",
            "Epoch 38/50\n",
            "329/329 - 2s - loss: 0.6383 - accuracy: 0.8113 - val_loss: 0.7343 - val_accuracy: 0.7888\n",
            "Epoch 39/50\n",
            "329/329 - 2s - loss: 0.6312 - accuracy: 0.8121 - val_loss: 0.7383 - val_accuracy: 0.7874\n",
            "Epoch 40/50\n",
            "329/329 - 2s - loss: 0.6281 - accuracy: 0.8138 - val_loss: 0.7513 - val_accuracy: 0.7854\n",
            "Epoch 41/50\n",
            "329/329 - 2s - loss: 0.6176 - accuracy: 0.8166 - val_loss: 0.7342 - val_accuracy: 0.7857\n",
            "Epoch 42/50\n",
            "329/329 - 2s - loss: 0.6098 - accuracy: 0.8182 - val_loss: 0.7279 - val_accuracy: 0.7919\n",
            "Epoch 43/50\n",
            "329/329 - 2s - loss: 0.6038 - accuracy: 0.8200 - val_loss: 0.7253 - val_accuracy: 0.7914\n",
            "Epoch 44/50\n",
            "329/329 - 2s - loss: 0.5984 - accuracy: 0.8222 - val_loss: 0.7287 - val_accuracy: 0.7923\n",
            "Epoch 45/50\n",
            "329/329 - 2s - loss: 0.5881 - accuracy: 0.8250 - val_loss: 0.7110 - val_accuracy: 0.7973\n",
            "Epoch 46/50\n",
            "329/329 - 2s - loss: 0.5825 - accuracy: 0.8265 - val_loss: 0.6969 - val_accuracy: 0.7996\n",
            "Epoch 47/50\n",
            "329/329 - 2s - loss: 0.5833 - accuracy: 0.8254 - val_loss: 0.7226 - val_accuracy: 0.7957\n",
            "Epoch 48/50\n",
            "329/329 - 2s - loss: 0.5734 - accuracy: 0.8299 - val_loss: 0.7068 - val_accuracy: 0.7992\n",
            "Epoch 49/50\n",
            "329/329 - 2s - loss: 0.5704 - accuracy: 0.8290 - val_loss: 0.7037 - val_accuracy: 0.7971\n",
            "Epoch 50/50\n",
            "329/329 - 2s - loss: 0.5612 - accuracy: 0.8328 - val_loss: 0.7026 - val_accuracy: 0.7994\n",
            "1313/1313 [==============================] - 2s 2ms/step - loss: 0.5474 - accuracy: 0.8382\n",
            "Try 4/10: Best_val_acc: [0.5473552346229553, 0.8381666541099548], lr: 0.00015355367376415115, Lambda: 0.000491045181846597\n",
            "\n",
            "Epoch 1/50\n",
            "329/329 - 2s - loss: 2.2268 - accuracy: 0.1883 - val_loss: 2.0199 - val_accuracy: 0.2939\n",
            "Epoch 2/50\n",
            "329/329 - 2s - loss: 1.7433 - accuracy: 0.4323 - val_loss: 1.5133 - val_accuracy: 0.5261\n",
            "Epoch 3/50\n",
            "329/329 - 2s - loss: 1.4258 - accuracy: 0.5517 - val_loss: 1.3465 - val_accuracy: 0.5784\n",
            "Epoch 4/50\n",
            "329/329 - 2s - loss: 1.2902 - accuracy: 0.6034 - val_loss: 1.2311 - val_accuracy: 0.6274\n",
            "Epoch 5/50\n",
            "329/329 - 2s - loss: 1.2177 - accuracy: 0.6294 - val_loss: 1.1682 - val_accuracy: 0.6473\n",
            "Epoch 6/50\n",
            "329/329 - 2s - loss: 1.1594 - accuracy: 0.6471 - val_loss: 1.1289 - val_accuracy: 0.6596\n",
            "Epoch 7/50\n",
            "329/329 - 2s - loss: 1.1134 - accuracy: 0.6638 - val_loss: 1.1021 - val_accuracy: 0.6690\n",
            "Epoch 8/50\n",
            "329/329 - 2s - loss: 1.0675 - accuracy: 0.6778 - val_loss: 1.0717 - val_accuracy: 0.6717\n",
            "Epoch 9/50\n",
            "329/329 - 2s - loss: 1.0277 - accuracy: 0.6919 - val_loss: 1.0947 - val_accuracy: 0.6686\n",
            "Epoch 10/50\n",
            "329/329 - 2s - loss: 0.9997 - accuracy: 0.6997 - val_loss: 0.9866 - val_accuracy: 0.7082\n",
            "Epoch 11/50\n",
            "329/329 - 2s - loss: 0.9676 - accuracy: 0.7104 - val_loss: 0.9884 - val_accuracy: 0.7048\n",
            "Epoch 12/50\n",
            "329/329 - 2s - loss: 0.9386 - accuracy: 0.7196 - val_loss: 0.9540 - val_accuracy: 0.7151\n",
            "Epoch 13/50\n",
            "329/329 - 2s - loss: 0.9166 - accuracy: 0.7275 - val_loss: 0.9546 - val_accuracy: 0.7187\n",
            "Epoch 14/50\n",
            "329/329 - 3s - loss: 0.8936 - accuracy: 0.7352 - val_loss: 0.9147 - val_accuracy: 0.7307\n",
            "Epoch 15/50\n",
            "329/329 - 3s - loss: 0.8798 - accuracy: 0.7356 - val_loss: 0.9435 - val_accuracy: 0.7211\n",
            "Epoch 16/50\n",
            "329/329 - 3s - loss: 0.8563 - accuracy: 0.7444 - val_loss: 0.9011 - val_accuracy: 0.7319\n",
            "Epoch 17/50\n",
            "329/329 - 4s - loss: 0.8415 - accuracy: 0.7489 - val_loss: 0.9208 - val_accuracy: 0.7288\n",
            "Epoch 18/50\n",
            "329/329 - 4s - loss: 0.8272 - accuracy: 0.7513 - val_loss: 0.8638 - val_accuracy: 0.7464\n",
            "Epoch 19/50\n",
            "329/329 - 3s - loss: 0.8164 - accuracy: 0.7549 - val_loss: 0.8994 - val_accuracy: 0.7316\n",
            "Epoch 20/50\n",
            "329/329 - 2s - loss: 0.7930 - accuracy: 0.7641 - val_loss: 0.8473 - val_accuracy: 0.7517\n",
            "Epoch 21/50\n",
            "329/329 - 2s - loss: 0.7828 - accuracy: 0.7653 - val_loss: 0.8500 - val_accuracy: 0.7499\n",
            "Epoch 22/50\n",
            "329/329 - 2s - loss: 0.7684 - accuracy: 0.7699 - val_loss: 0.8604 - val_accuracy: 0.7442\n",
            "Epoch 23/50\n",
            "329/329 - 2s - loss: 0.7524 - accuracy: 0.7751 - val_loss: 0.8483 - val_accuracy: 0.7503\n",
            "Epoch 24/50\n",
            "329/329 - 2s - loss: 0.7356 - accuracy: 0.7817 - val_loss: 0.8289 - val_accuracy: 0.7560\n",
            "Epoch 25/50\n",
            "329/329 - 2s - loss: 0.7261 - accuracy: 0.7841 - val_loss: 0.8370 - val_accuracy: 0.7577\n",
            "Epoch 26/50\n",
            "329/329 - 2s - loss: 0.7197 - accuracy: 0.7868 - val_loss: 0.7937 - val_accuracy: 0.7686\n",
            "Epoch 27/50\n",
            "329/329 - 2s - loss: 0.7088 - accuracy: 0.7891 - val_loss: 0.8026 - val_accuracy: 0.7697\n",
            "Epoch 28/50\n",
            "329/329 - 2s - loss: 0.6969 - accuracy: 0.7914 - val_loss: 0.7772 - val_accuracy: 0.7731\n",
            "Epoch 29/50\n",
            "329/329 - 2s - loss: 0.6864 - accuracy: 0.7963 - val_loss: 0.8203 - val_accuracy: 0.7591\n",
            "Epoch 30/50\n",
            "329/329 - 2s - loss: 0.6748 - accuracy: 0.7995 - val_loss: 0.7540 - val_accuracy: 0.7825\n",
            "Epoch 31/50\n",
            "329/329 - 2s - loss: 0.6622 - accuracy: 0.8030 - val_loss: 0.7494 - val_accuracy: 0.7846\n",
            "Epoch 32/50\n",
            "329/329 - 2s - loss: 0.6607 - accuracy: 0.8027 - val_loss: 0.7869 - val_accuracy: 0.7689\n",
            "Epoch 33/50\n",
            "329/329 - 2s - loss: 0.6438 - accuracy: 0.8085 - val_loss: 0.7445 - val_accuracy: 0.7867\n",
            "Epoch 34/50\n",
            "329/329 - 2s - loss: 0.6359 - accuracy: 0.8128 - val_loss: 0.7674 - val_accuracy: 0.7792\n",
            "Epoch 35/50\n",
            "329/329 - 2s - loss: 0.6303 - accuracy: 0.8143 - val_loss: 0.7299 - val_accuracy: 0.7934\n",
            "Epoch 36/50\n",
            "329/329 - 2s - loss: 0.6198 - accuracy: 0.8162 - val_loss: 0.7540 - val_accuracy: 0.7842\n",
            "Epoch 37/50\n",
            "329/329 - 2s - loss: 0.6065 - accuracy: 0.8224 - val_loss: 0.7228 - val_accuracy: 0.7934\n",
            "Epoch 38/50\n",
            "329/329 - 2s - loss: 0.6018 - accuracy: 0.8239 - val_loss: 0.7204 - val_accuracy: 0.7940\n",
            "Epoch 39/50\n",
            "329/329 - 2s - loss: 0.6044 - accuracy: 0.8195 - val_loss: 0.7217 - val_accuracy: 0.7951\n",
            "Epoch 40/50\n",
            "329/329 - 2s - loss: 0.5850 - accuracy: 0.8268 - val_loss: 0.7188 - val_accuracy: 0.7960\n",
            "Epoch 41/50\n",
            "329/329 - 2s - loss: 0.5827 - accuracy: 0.8279 - val_loss: 0.7188 - val_accuracy: 0.7931\n",
            "Epoch 42/50\n",
            "329/329 - 2s - loss: 0.5745 - accuracy: 0.8315 - val_loss: 0.7221 - val_accuracy: 0.7940\n",
            "Epoch 43/50\n",
            "329/329 - 2s - loss: 0.5690 - accuracy: 0.8326 - val_loss: 0.7090 - val_accuracy: 0.8034\n",
            "Epoch 44/50\n",
            "329/329 - 2s - loss: 0.5616 - accuracy: 0.8355 - val_loss: 0.7138 - val_accuracy: 0.7996\n",
            "Epoch 45/50\n",
            "329/329 - 2s - loss: 0.5555 - accuracy: 0.8367 - val_loss: 0.7014 - val_accuracy: 0.8002\n",
            "Epoch 46/50\n",
            "329/329 - 2s - loss: 0.5528 - accuracy: 0.8370 - val_loss: 0.6769 - val_accuracy: 0.8101\n",
            "Epoch 47/50\n",
            "329/329 - 2s - loss: 0.5453 - accuracy: 0.8393 - val_loss: 0.7337 - val_accuracy: 0.7933\n",
            "Epoch 48/50\n",
            "329/329 - 2s - loss: 0.5366 - accuracy: 0.8417 - val_loss: 0.6962 - val_accuracy: 0.8051\n",
            "Epoch 49/50\n",
            "329/329 - 2s - loss: 0.5393 - accuracy: 0.8414 - val_loss: 0.7182 - val_accuracy: 0.7941\n",
            "Epoch 50/50\n",
            "329/329 - 2s - loss: 0.5283 - accuracy: 0.8440 - val_loss: 0.6781 - val_accuracy: 0.8081\n",
            "1313/1313 [==============================] - 2s 2ms/step - loss: 0.5067 - accuracy: 0.8519\n",
            "Try 5/10: Best_val_acc: [0.506665825843811, 0.8519047498703003], lr: 0.0002493259452548489, Lambda: 0.0011957309429716362\n",
            "\n",
            "Epoch 1/50\n",
            "329/329 - 2s - loss: 2.2320 - accuracy: 0.1896 - val_loss: 2.0156 - val_accuracy: 0.3247\n",
            "Epoch 2/50\n",
            "329/329 - 2s - loss: 1.7480 - accuracy: 0.4203 - val_loss: 1.5368 - val_accuracy: 0.5127\n",
            "Epoch 3/50\n",
            "329/329 - 2s - loss: 1.4165 - accuracy: 0.5636 - val_loss: 1.3405 - val_accuracy: 0.5921\n",
            "Epoch 4/50\n",
            "329/329 - 2s - loss: 1.2573 - accuracy: 0.6187 - val_loss: 1.2044 - val_accuracy: 0.6409\n",
            "Epoch 5/50\n",
            "329/329 - 2s - loss: 1.1694 - accuracy: 0.6485 - val_loss: 1.2073 - val_accuracy: 0.6322\n",
            "Epoch 6/50\n",
            "329/329 - 2s - loss: 1.1089 - accuracy: 0.6700 - val_loss: 1.0830 - val_accuracy: 0.6832\n",
            "Epoch 7/50\n",
            "329/329 - 2s - loss: 1.0565 - accuracy: 0.6864 - val_loss: 1.0625 - val_accuracy: 0.6804\n",
            "Epoch 8/50\n",
            "329/329 - 2s - loss: 1.0159 - accuracy: 0.7006 - val_loss: 1.0338 - val_accuracy: 0.6941\n",
            "Epoch 9/50\n",
            "329/329 - 2s - loss: 0.9847 - accuracy: 0.7095 - val_loss: 1.0177 - val_accuracy: 0.6983\n",
            "Epoch 10/50\n",
            "329/329 - 2s - loss: 0.9510 - accuracy: 0.7194 - val_loss: 0.9707 - val_accuracy: 0.7132\n",
            "Epoch 11/50\n",
            "329/329 - 3s - loss: 0.9255 - accuracy: 0.7266 - val_loss: 0.9676 - val_accuracy: 0.7151\n",
            "Epoch 12/50\n",
            "329/329 - 3s - loss: 0.9007 - accuracy: 0.7350 - val_loss: 0.9464 - val_accuracy: 0.7208\n",
            "Epoch 13/50\n",
            "329/329 - 2s - loss: 0.8766 - accuracy: 0.7423 - val_loss: 0.9044 - val_accuracy: 0.7431\n",
            "Epoch 14/50\n",
            "329/329 - 2s - loss: 0.8532 - accuracy: 0.7484 - val_loss: 0.8885 - val_accuracy: 0.7427\n",
            "Epoch 15/50\n",
            "329/329 - 2s - loss: 0.8368 - accuracy: 0.7534 - val_loss: 0.8580 - val_accuracy: 0.7530\n",
            "Epoch 16/50\n",
            "329/329 - 2s - loss: 0.8166 - accuracy: 0.7608 - val_loss: 0.8699 - val_accuracy: 0.7471\n",
            "Epoch 17/50\n",
            "329/329 - 2s - loss: 0.7934 - accuracy: 0.7680 - val_loss: 0.8871 - val_accuracy: 0.7402\n",
            "Epoch 18/50\n",
            "329/329 - 2s - loss: 0.7759 - accuracy: 0.7736 - val_loss: 0.8508 - val_accuracy: 0.7587\n",
            "Epoch 19/50\n",
            "329/329 - 2s - loss: 0.7593 - accuracy: 0.7797 - val_loss: 0.8352 - val_accuracy: 0.7623\n",
            "Epoch 20/50\n",
            "329/329 - 2s - loss: 0.7487 - accuracy: 0.7824 - val_loss: 0.8288 - val_accuracy: 0.7612\n",
            "Epoch 21/50\n",
            "329/329 - 2s - loss: 0.7325 - accuracy: 0.7885 - val_loss: 0.8104 - val_accuracy: 0.7686\n",
            "Epoch 22/50\n",
            "329/329 - 2s - loss: 0.7187 - accuracy: 0.7922 - val_loss: 0.7950 - val_accuracy: 0.7749\n",
            "Epoch 23/50\n",
            "329/329 - 2s - loss: 0.7033 - accuracy: 0.7949 - val_loss: 0.7675 - val_accuracy: 0.7847\n",
            "Epoch 24/50\n",
            "329/329 - 2s - loss: 0.6879 - accuracy: 0.8023 - val_loss: 0.7707 - val_accuracy: 0.7824\n",
            "Epoch 25/50\n",
            "329/329 - 2s - loss: 0.6765 - accuracy: 0.8053 - val_loss: 0.8009 - val_accuracy: 0.7723\n",
            "Epoch 26/50\n",
            "329/329 - 2s - loss: 0.6697 - accuracy: 0.8085 - val_loss: 0.7686 - val_accuracy: 0.7847\n",
            "Epoch 27/50\n",
            "329/329 - 2s - loss: 0.6615 - accuracy: 0.8103 - val_loss: 0.7875 - val_accuracy: 0.7827\n",
            "Epoch 28/50\n",
            "329/329 - 2s - loss: 0.6502 - accuracy: 0.8121 - val_loss: 0.7443 - val_accuracy: 0.7893\n",
            "Epoch 29/50\n",
            "329/329 - 2s - loss: 0.6389 - accuracy: 0.8171 - val_loss: 0.7588 - val_accuracy: 0.7878\n",
            "Epoch 30/50\n",
            "329/329 - 2s - loss: 0.6301 - accuracy: 0.8190 - val_loss: 0.7154 - val_accuracy: 0.8027\n",
            "Epoch 31/50\n",
            "329/329 - 2s - loss: 0.6182 - accuracy: 0.8220 - val_loss: 0.7129 - val_accuracy: 0.8013\n",
            "Epoch 32/50\n",
            "329/329 - 2s - loss: 0.6146 - accuracy: 0.8235 - val_loss: 0.7518 - val_accuracy: 0.7913\n",
            "Epoch 33/50\n",
            "329/329 - 2s - loss: 0.6001 - accuracy: 0.8286 - val_loss: 0.7373 - val_accuracy: 0.7963\n",
            "Epoch 34/50\n",
            "329/329 - 2s - loss: 0.5971 - accuracy: 0.8278 - val_loss: 0.7425 - val_accuracy: 0.7952\n",
            "Epoch 35/50\n",
            "329/329 - 2s - loss: 0.5886 - accuracy: 0.8316 - val_loss: 0.7076 - val_accuracy: 0.8047\n",
            "Epoch 36/50\n",
            "329/329 - 2s - loss: 0.5800 - accuracy: 0.8328 - val_loss: 0.7148 - val_accuracy: 0.7994\n",
            "Epoch 37/50\n",
            "329/329 - 2s - loss: 0.5722 - accuracy: 0.8361 - val_loss: 0.7114 - val_accuracy: 0.8051\n",
            "Epoch 38/50\n",
            "329/329 - 2s - loss: 0.5665 - accuracy: 0.8380 - val_loss: 0.6742 - val_accuracy: 0.8160\n",
            "Epoch 39/50\n",
            "329/329 - 2s - loss: 0.5586 - accuracy: 0.8404 - val_loss: 0.6789 - val_accuracy: 0.8141\n",
            "Epoch 40/50\n",
            "329/329 - 2s - loss: 0.5553 - accuracy: 0.8410 - val_loss: 0.6884 - val_accuracy: 0.8119\n",
            "Epoch 41/50\n",
            "329/329 - 2s - loss: 0.5510 - accuracy: 0.8420 - val_loss: 0.6933 - val_accuracy: 0.8086\n",
            "Epoch 42/50\n",
            "329/329 - 2s - loss: 0.5421 - accuracy: 0.8444 - val_loss: 0.7019 - val_accuracy: 0.8059\n",
            "Epoch 43/50\n",
            "329/329 - 2s - loss: 0.5345 - accuracy: 0.8472 - val_loss: 0.6843 - val_accuracy: 0.8130\n",
            "Epoch 44/50\n",
            "329/329 - 2s - loss: 0.5301 - accuracy: 0.8495 - val_loss: 0.6956 - val_accuracy: 0.8096\n",
            "Epoch 45/50\n",
            "329/329 - 2s - loss: 0.5205 - accuracy: 0.8514 - val_loss: 0.6737 - val_accuracy: 0.8144\n",
            "Epoch 46/50\n",
            "329/329 - 2s - loss: 0.5216 - accuracy: 0.8523 - val_loss: 0.6768 - val_accuracy: 0.8163\n",
            "Epoch 47/50\n",
            "329/329 - 2s - loss: 0.5190 - accuracy: 0.8530 - val_loss: 0.6653 - val_accuracy: 0.8181\n",
            "Epoch 48/50\n",
            "329/329 - 2s - loss: 0.5117 - accuracy: 0.8535 - val_loss: 0.6851 - val_accuracy: 0.8136\n",
            "Epoch 49/50\n",
            "329/329 - 2s - loss: 0.5148 - accuracy: 0.8523 - val_loss: 0.6779 - val_accuracy: 0.8174\n",
            "Epoch 50/50\n",
            "329/329 - 2s - loss: 0.5015 - accuracy: 0.8559 - val_loss: 0.6745 - val_accuracy: 0.8147\n",
            "1313/1313 [==============================] - 2s 2ms/step - loss: 0.4909 - accuracy: 0.8617\n",
            "Try 6/10: Best_val_acc: [0.4909195005893707, 0.8616666793823242], lr: 0.0002625394157290996, Lambda: 0.002346599645859087\n",
            "\n",
            "Epoch 1/50\n",
            "329/329 - 2s - loss: 2.2665 - accuracy: 0.2024 - val_loss: 2.0820 - val_accuracy: 0.2907\n",
            "Epoch 2/50\n",
            "329/329 - 2s - loss: 1.8486 - accuracy: 0.4131 - val_loss: 1.6693 - val_accuracy: 0.4798\n",
            "Epoch 3/50\n",
            "329/329 - 2s - loss: 1.5478 - accuracy: 0.5296 - val_loss: 1.4253 - val_accuracy: 0.5811\n",
            "Epoch 4/50\n",
            "329/329 - 2s - loss: 1.4003 - accuracy: 0.5783 - val_loss: 1.3394 - val_accuracy: 0.5995\n",
            "Epoch 5/50\n",
            "329/329 - 2s - loss: 1.3072 - accuracy: 0.6101 - val_loss: 1.2899 - val_accuracy: 0.6166\n",
            "Epoch 6/50\n",
            "329/329 - 2s - loss: 1.2478 - accuracy: 0.6314 - val_loss: 1.1942 - val_accuracy: 0.6543\n",
            "Epoch 7/50\n",
            "329/329 - 2s - loss: 1.1889 - accuracy: 0.6519 - val_loss: 1.1700 - val_accuracy: 0.6603\n",
            "Epoch 8/50\n",
            "329/329 - 2s - loss: 1.1443 - accuracy: 0.6680 - val_loss: 1.1523 - val_accuracy: 0.6598\n",
            "Epoch 9/50\n",
            "329/329 - 2s - loss: 1.1075 - accuracy: 0.6806 - val_loss: 1.1557 - val_accuracy: 0.6576\n",
            "Epoch 10/50\n",
            "329/329 - 2s - loss: 1.0723 - accuracy: 0.6926 - val_loss: 1.0701 - val_accuracy: 0.6919\n",
            "Epoch 11/50\n",
            "329/329 - 2s - loss: 1.0424 - accuracy: 0.7035 - val_loss: 1.0979 - val_accuracy: 0.6847\n",
            "Epoch 12/50\n",
            "329/329 - 2s - loss: 1.0097 - accuracy: 0.7136 - val_loss: 1.0137 - val_accuracy: 0.7147\n",
            "Epoch 13/50\n",
            "329/329 - 2s - loss: 0.9805 - accuracy: 0.7232 - val_loss: 1.0193 - val_accuracy: 0.7113\n",
            "Epoch 14/50\n",
            "329/329 - 2s - loss: 0.9524 - accuracy: 0.7301 - val_loss: 0.9672 - val_accuracy: 0.7250\n",
            "Epoch 15/50\n",
            "329/329 - 2s - loss: 0.9333 - accuracy: 0.7376 - val_loss: 0.9490 - val_accuracy: 0.7354\n",
            "Epoch 16/50\n",
            "329/329 - 2s - loss: 0.9057 - accuracy: 0.7479 - val_loss: 0.9199 - val_accuracy: 0.7449\n",
            "Epoch 17/50\n",
            "329/329 - 2s - loss: 0.8843 - accuracy: 0.7543 - val_loss: 0.9556 - val_accuracy: 0.7312\n",
            "Epoch 18/50\n",
            "329/329 - 2s - loss: 0.8687 - accuracy: 0.7569 - val_loss: 0.9149 - val_accuracy: 0.7469\n",
            "Epoch 19/50\n",
            "329/329 - 2s - loss: 0.8532 - accuracy: 0.7626 - val_loss: 0.9071 - val_accuracy: 0.7465\n",
            "Epoch 20/50\n",
            "329/329 - 2s - loss: 0.8421 - accuracy: 0.7665 - val_loss: 0.8876 - val_accuracy: 0.7537\n",
            "Epoch 21/50\n",
            "329/329 - 2s - loss: 0.8233 - accuracy: 0.7733 - val_loss: 0.8674 - val_accuracy: 0.7592\n",
            "Epoch 22/50\n",
            "329/329 - 2s - loss: 0.8104 - accuracy: 0.7760 - val_loss: 0.8811 - val_accuracy: 0.7583\n",
            "Epoch 23/50\n",
            "329/329 - 2s - loss: 0.7972 - accuracy: 0.7793 - val_loss: 0.8534 - val_accuracy: 0.7643\n",
            "Epoch 24/50\n",
            "329/329 - 2s - loss: 0.7865 - accuracy: 0.7817 - val_loss: 0.8282 - val_accuracy: 0.7736\n",
            "Epoch 25/50\n",
            "329/329 - 2s - loss: 0.7711 - accuracy: 0.7863 - val_loss: 0.8567 - val_accuracy: 0.7577\n",
            "Epoch 26/50\n",
            "329/329 - 2s - loss: 0.7622 - accuracy: 0.7909 - val_loss: 0.8371 - val_accuracy: 0.7692\n",
            "Epoch 27/50\n",
            "329/329 - 2s - loss: 0.7538 - accuracy: 0.7936 - val_loss: 0.8442 - val_accuracy: 0.7656\n",
            "Epoch 28/50\n",
            "329/329 - 2s - loss: 0.7415 - accuracy: 0.7952 - val_loss: 0.8025 - val_accuracy: 0.7824\n",
            "Epoch 29/50\n",
            "329/329 - 2s - loss: 0.7322 - accuracy: 0.7975 - val_loss: 0.8206 - val_accuracy: 0.7728\n",
            "Epoch 30/50\n",
            "329/329 - 2s - loss: 0.7233 - accuracy: 0.8005 - val_loss: 0.7916 - val_accuracy: 0.7818\n",
            "Epoch 31/50\n",
            "329/329 - 2s - loss: 0.7185 - accuracy: 0.8004 - val_loss: 0.8131 - val_accuracy: 0.7766\n",
            "Epoch 32/50\n",
            "329/329 - 2s - loss: 0.7141 - accuracy: 0.8027 - val_loss: 0.7836 - val_accuracy: 0.7863\n",
            "Epoch 33/50\n",
            "329/329 - 2s - loss: 0.6954 - accuracy: 0.8091 - val_loss: 0.7789 - val_accuracy: 0.7891\n",
            "Epoch 34/50\n",
            "329/329 - 2s - loss: 0.6952 - accuracy: 0.8083 - val_loss: 0.7673 - val_accuracy: 0.7885\n",
            "Epoch 35/50\n",
            "329/329 - 2s - loss: 0.6838 - accuracy: 0.8124 - val_loss: 0.7968 - val_accuracy: 0.7846\n",
            "Epoch 36/50\n",
            "329/329 - 2s - loss: 0.6744 - accuracy: 0.8150 - val_loss: 0.7735 - val_accuracy: 0.7894\n",
            "Epoch 37/50\n",
            "329/329 - 2s - loss: 0.6721 - accuracy: 0.8162 - val_loss: 0.7714 - val_accuracy: 0.7889\n",
            "Epoch 38/50\n",
            "329/329 - 2s - loss: 0.6622 - accuracy: 0.8182 - val_loss: 0.7701 - val_accuracy: 0.7919\n",
            "Epoch 39/50\n",
            "329/329 - 2s - loss: 0.6549 - accuracy: 0.8197 - val_loss: 0.7404 - val_accuracy: 0.8018\n",
            "Epoch 40/50\n",
            "329/329 - 2s - loss: 0.6502 - accuracy: 0.8217 - val_loss: 0.7486 - val_accuracy: 0.7986\n",
            "Epoch 41/50\n",
            "329/329 - 2s - loss: 0.6450 - accuracy: 0.8228 - val_loss: 0.7594 - val_accuracy: 0.7909\n",
            "Epoch 42/50\n",
            "329/329 - 2s - loss: 0.6375 - accuracy: 0.8250 - val_loss: 0.7416 - val_accuracy: 0.7992\n",
            "Epoch 43/50\n",
            "329/329 - 2s - loss: 0.6336 - accuracy: 0.8254 - val_loss: 0.7502 - val_accuracy: 0.7978\n",
            "Epoch 44/50\n",
            "329/329 - 2s - loss: 0.6267 - accuracy: 0.8279 - val_loss: 0.7419 - val_accuracy: 0.7969\n",
            "Epoch 45/50\n",
            "329/329 - 3s - loss: 0.6163 - accuracy: 0.8309 - val_loss: 0.7307 - val_accuracy: 0.8048\n",
            "Epoch 46/50\n",
            "329/329 - 3s - loss: 0.6116 - accuracy: 0.8329 - val_loss: 0.7412 - val_accuracy: 0.7998\n",
            "Epoch 47/50\n",
            "329/329 - 3s - loss: 0.6085 - accuracy: 0.8318 - val_loss: 0.7466 - val_accuracy: 0.7979\n",
            "Epoch 48/50\n",
            "329/329 - 3s - loss: 0.6006 - accuracy: 0.8329 - val_loss: 0.7085 - val_accuracy: 0.8093\n",
            "Epoch 49/50\n",
            "329/329 - 2s - loss: 0.5978 - accuracy: 0.8358 - val_loss: 0.7345 - val_accuracy: 0.8023\n",
            "Epoch 50/50\n",
            "329/329 - 2s - loss: 0.5940 - accuracy: 0.8370 - val_loss: 0.7342 - val_accuracy: 0.8001\n",
            "1313/1313 [==============================] - 3s 2ms/step - loss: 0.5994 - accuracy: 0.8322\n",
            "Try 7/10: Best_val_acc: [0.5994123816490173, 0.8322380781173706], lr: 0.00016012245855333068, Lambda: 0.00570472708820368\n",
            "\n",
            "Epoch 1/50\n",
            "329/329 - 2s - loss: 2.2881 - accuracy: 0.1662 - val_loss: 2.1720 - val_accuracy: 0.2676\n",
            "Epoch 2/50\n",
            "329/329 - 2s - loss: 1.9720 - accuracy: 0.3490 - val_loss: 1.7861 - val_accuracy: 0.4185\n",
            "Epoch 3/50\n",
            "329/329 - 2s - loss: 1.6675 - accuracy: 0.4744 - val_loss: 1.5663 - val_accuracy: 0.5157\n",
            "Epoch 4/50\n",
            "329/329 - 2s - loss: 1.4908 - accuracy: 0.5425 - val_loss: 1.4046 - val_accuracy: 0.5783\n",
            "Epoch 5/50\n",
            "329/329 - 2s - loss: 1.3680 - accuracy: 0.5894 - val_loss: 1.3318 - val_accuracy: 0.5987\n",
            "Epoch 6/50\n",
            "329/329 - 2s - loss: 1.2819 - accuracy: 0.6164 - val_loss: 1.2470 - val_accuracy: 0.6242\n",
            "Epoch 7/50\n",
            "329/329 - 2s - loss: 1.2199 - accuracy: 0.6388 - val_loss: 1.2141 - val_accuracy: 0.6334\n",
            "Epoch 8/50\n",
            "329/329 - 2s - loss: 1.1680 - accuracy: 0.6517 - val_loss: 1.1612 - val_accuracy: 0.6514\n",
            "Epoch 9/50\n",
            "329/329 - 2s - loss: 1.1263 - accuracy: 0.6647 - val_loss: 1.1652 - val_accuracy: 0.6475\n",
            "Epoch 10/50\n",
            "329/329 - 2s - loss: 1.0864 - accuracy: 0.6790 - val_loss: 1.0795 - val_accuracy: 0.6786\n",
            "Epoch 11/50\n",
            "329/329 - 2s - loss: 1.0546 - accuracy: 0.6881 - val_loss: 1.0652 - val_accuracy: 0.6813\n",
            "Epoch 12/50\n",
            "329/329 - 2s - loss: 1.0255 - accuracy: 0.6975 - val_loss: 1.0349 - val_accuracy: 0.6921\n",
            "Epoch 13/50\n",
            "329/329 - 2s - loss: 0.9926 - accuracy: 0.7085 - val_loss: 1.0344 - val_accuracy: 0.6946\n",
            "Epoch 14/50\n",
            "329/329 - 2s - loss: 0.9696 - accuracy: 0.7164 - val_loss: 0.9802 - val_accuracy: 0.7127\n",
            "Epoch 15/50\n",
            "329/329 - 2s - loss: 0.9525 - accuracy: 0.7195 - val_loss: 0.9612 - val_accuracy: 0.7201\n",
            "Epoch 16/50\n",
            "329/329 - 2s - loss: 0.9219 - accuracy: 0.7308 - val_loss: 0.9540 - val_accuracy: 0.7223\n",
            "Epoch 17/50\n",
            "329/329 - 2s - loss: 0.9048 - accuracy: 0.7381 - val_loss: 0.9326 - val_accuracy: 0.7303\n",
            "Epoch 18/50\n",
            "329/329 - 2s - loss: 0.8894 - accuracy: 0.7406 - val_loss: 0.9447 - val_accuracy: 0.7226\n",
            "Epoch 19/50\n",
            "329/329 - 2s - loss: 0.8769 - accuracy: 0.7469 - val_loss: 0.9054 - val_accuracy: 0.7363\n",
            "Epoch 20/50\n",
            "329/329 - 2s - loss: 0.8592 - accuracy: 0.7504 - val_loss: 0.9032 - val_accuracy: 0.7362\n",
            "Epoch 21/50\n",
            "329/329 - 2s - loss: 0.8441 - accuracy: 0.7541 - val_loss: 0.8822 - val_accuracy: 0.7466\n",
            "Epoch 22/50\n",
            "329/329 - 2s - loss: 0.8276 - accuracy: 0.7599 - val_loss: 0.8761 - val_accuracy: 0.7474\n",
            "Epoch 23/50\n",
            "329/329 - 2s - loss: 0.8121 - accuracy: 0.7652 - val_loss: 0.8645 - val_accuracy: 0.7514\n",
            "Epoch 24/50\n",
            "329/329 - 2s - loss: 0.8039 - accuracy: 0.7680 - val_loss: 0.8424 - val_accuracy: 0.7588\n",
            "Epoch 25/50\n",
            "329/329 - 2s - loss: 0.7910 - accuracy: 0.7720 - val_loss: 0.8635 - val_accuracy: 0.7478\n",
            "Epoch 26/50\n",
            "329/329 - 2s - loss: 0.7850 - accuracy: 0.7742 - val_loss: 0.8288 - val_accuracy: 0.7637\n",
            "Epoch 27/50\n",
            "329/329 - 2s - loss: 0.7718 - accuracy: 0.7788 - val_loss: 0.8321 - val_accuracy: 0.7641\n",
            "Epoch 28/50\n",
            "329/329 - 2s - loss: 0.7591 - accuracy: 0.7817 - val_loss: 0.8314 - val_accuracy: 0.7632\n",
            "Epoch 29/50\n",
            "329/329 - 2s - loss: 0.7577 - accuracy: 0.7810 - val_loss: 0.8444 - val_accuracy: 0.7571\n",
            "Epoch 30/50\n",
            "329/329 - 2s - loss: 0.7436 - accuracy: 0.7847 - val_loss: 0.8092 - val_accuracy: 0.7704\n",
            "Epoch 31/50\n",
            "329/329 - 2s - loss: 0.7341 - accuracy: 0.7897 - val_loss: 0.8316 - val_accuracy: 0.7650\n",
            "Epoch 32/50\n",
            "329/329 - 2s - loss: 0.7289 - accuracy: 0.7891 - val_loss: 0.7990 - val_accuracy: 0.7748\n",
            "Epoch 33/50\n",
            "329/329 - 2s - loss: 0.7167 - accuracy: 0.7944 - val_loss: 0.7965 - val_accuracy: 0.7754\n",
            "Epoch 34/50\n",
            "329/329 - 2s - loss: 0.7117 - accuracy: 0.7957 - val_loss: 0.7831 - val_accuracy: 0.7796\n",
            "Epoch 35/50\n",
            "329/329 - 2s - loss: 0.7055 - accuracy: 0.7981 - val_loss: 0.8127 - val_accuracy: 0.7681\n",
            "Epoch 36/50\n",
            "329/329 - 2s - loss: 0.6942 - accuracy: 0.8009 - val_loss: 0.7970 - val_accuracy: 0.7751\n",
            "Epoch 37/50\n",
            "329/329 - 2s - loss: 0.6898 - accuracy: 0.8020 - val_loss: 0.8033 - val_accuracy: 0.7734\n",
            "Epoch 38/50\n",
            "329/329 - 2s - loss: 0.6815 - accuracy: 0.8043 - val_loss: 0.7594 - val_accuracy: 0.7882\n",
            "Epoch 39/50\n",
            "329/329 - 2s - loss: 0.6772 - accuracy: 0.8055 - val_loss: 0.7652 - val_accuracy: 0.7832\n",
            "Epoch 40/50\n",
            "329/329 - 2s - loss: 0.6669 - accuracy: 0.8096 - val_loss: 0.7670 - val_accuracy: 0.7859\n",
            "Epoch 41/50\n",
            "329/329 - 2s - loss: 0.6663 - accuracy: 0.8095 - val_loss: 0.7736 - val_accuracy: 0.7813\n",
            "Epoch 42/50\n",
            "329/329 - 3s - loss: 0.6568 - accuracy: 0.8123 - val_loss: 0.7487 - val_accuracy: 0.7903\n",
            "Epoch 43/50\n",
            "329/329 - 3s - loss: 0.6488 - accuracy: 0.8147 - val_loss: 0.7757 - val_accuracy: 0.7822\n",
            "Epoch 44/50\n",
            "329/329 - 2s - loss: 0.6419 - accuracy: 0.8153 - val_loss: 0.7505 - val_accuracy: 0.7916\n",
            "Epoch 45/50\n",
            "329/329 - 2s - loss: 0.6384 - accuracy: 0.8178 - val_loss: 0.7723 - val_accuracy: 0.7834\n",
            "Epoch 46/50\n",
            "329/329 - 2s - loss: 0.6338 - accuracy: 0.8184 - val_loss: 0.7505 - val_accuracy: 0.7871\n",
            "Epoch 47/50\n",
            "329/329 - 2s - loss: 0.6289 - accuracy: 0.8182 - val_loss: 0.7608 - val_accuracy: 0.7861\n",
            "Epoch 48/50\n",
            "329/329 - 2s - loss: 0.6221 - accuracy: 0.8197 - val_loss: 0.7367 - val_accuracy: 0.7943\n",
            "Epoch 49/50\n",
            "329/329 - 2s - loss: 0.6182 - accuracy: 0.8232 - val_loss: 0.7304 - val_accuracy: 0.7955\n",
            "Epoch 50/50\n",
            "329/329 - 2s - loss: 0.6117 - accuracy: 0.8257 - val_loss: 0.7402 - val_accuracy: 0.7947\n",
            "1313/1313 [==============================] - 3s 2ms/step - loss: 0.6073 - accuracy: 0.8252\n",
            "Try 8/10: Best_val_acc: [0.6072736382484436, 0.8252142667770386], lr: 0.00010650931539464164, Lambda: 0.002192476869880636\n",
            "\n",
            "Epoch 1/50\n",
            "329/329 - 2s - loss: 2.2096 - accuracy: 0.1979 - val_loss: 1.9594 - val_accuracy: 0.3298\n",
            "Epoch 2/50\n",
            "329/329 - 2s - loss: 1.7650 - accuracy: 0.4116 - val_loss: 1.5795 - val_accuracy: 0.4837\n",
            "Epoch 3/50\n",
            "329/329 - 2s - loss: 1.4729 - accuracy: 0.5304 - val_loss: 1.3763 - val_accuracy: 0.5731\n",
            "Epoch 4/50\n",
            "329/329 - 2s - loss: 1.3124 - accuracy: 0.5925 - val_loss: 1.2355 - val_accuracy: 0.6208\n",
            "Epoch 5/50\n",
            "329/329 - 2s - loss: 1.2103 - accuracy: 0.6263 - val_loss: 1.1341 - val_accuracy: 0.6643\n",
            "Epoch 6/50\n",
            "329/329 - 2s - loss: 1.1422 - accuracy: 0.6542 - val_loss: 1.0972 - val_accuracy: 0.6708\n",
            "Epoch 7/50\n",
            "329/329 - 2s - loss: 1.0796 - accuracy: 0.6744 - val_loss: 1.0824 - val_accuracy: 0.6705\n",
            "Epoch 8/50\n",
            "329/329 - 2s - loss: 1.0302 - accuracy: 0.6904 - val_loss: 1.0174 - val_accuracy: 0.6936\n",
            "Epoch 9/50\n",
            "329/329 - 2s - loss: 0.9938 - accuracy: 0.7013 - val_loss: 1.0543 - val_accuracy: 0.6771\n",
            "Epoch 10/50\n",
            "329/329 - 2s - loss: 0.9585 - accuracy: 0.7141 - val_loss: 0.9701 - val_accuracy: 0.7130\n",
            "Epoch 11/50\n",
            "329/329 - 2s - loss: 0.9292 - accuracy: 0.7239 - val_loss: 0.9956 - val_accuracy: 0.7012\n",
            "Epoch 12/50\n",
            "329/329 - 2s - loss: 0.8994 - accuracy: 0.7335 - val_loss: 0.9061 - val_accuracy: 0.7330\n",
            "Epoch 13/50\n",
            "329/329 - 2s - loss: 0.8692 - accuracy: 0.7409 - val_loss: 0.8990 - val_accuracy: 0.7373\n",
            "Epoch 14/50\n",
            "329/329 - 2s - loss: 0.8437 - accuracy: 0.7475 - val_loss: 0.8656 - val_accuracy: 0.7481\n",
            "Epoch 15/50\n",
            "329/329 - 2s - loss: 0.8259 - accuracy: 0.7548 - val_loss: 0.8686 - val_accuracy: 0.7456\n",
            "Epoch 16/50\n",
            "329/329 - 2s - loss: 0.8009 - accuracy: 0.7629 - val_loss: 0.8424 - val_accuracy: 0.7569\n",
            "Epoch 17/50\n",
            "329/329 - 2s - loss: 0.7777 - accuracy: 0.7686 - val_loss: 0.8328 - val_accuracy: 0.7568\n",
            "Epoch 18/50\n",
            "329/329 - 2s - loss: 0.7702 - accuracy: 0.7728 - val_loss: 0.8317 - val_accuracy: 0.7541\n",
            "Epoch 19/50\n",
            "329/329 - 2s - loss: 0.7499 - accuracy: 0.7768 - val_loss: 0.8283 - val_accuracy: 0.7601\n",
            "Epoch 20/50\n",
            "329/329 - 2s - loss: 0.7331 - accuracy: 0.7840 - val_loss: 0.8368 - val_accuracy: 0.7571\n",
            "Epoch 21/50\n",
            "329/329 - 2s - loss: 0.7227 - accuracy: 0.7867 - val_loss: 0.7985 - val_accuracy: 0.7669\n",
            "Epoch 22/50\n",
            "329/329 - 2s - loss: 0.6996 - accuracy: 0.7945 - val_loss: 0.7760 - val_accuracy: 0.7768\n",
            "Epoch 23/50\n",
            "329/329 - 2s - loss: 0.6883 - accuracy: 0.7963 - val_loss: 0.7574 - val_accuracy: 0.7839\n",
            "Epoch 24/50\n",
            "329/329 - 2s - loss: 0.6724 - accuracy: 0.8026 - val_loss: 0.7391 - val_accuracy: 0.7891\n",
            "Epoch 25/50\n",
            "329/329 - 2s - loss: 0.6647 - accuracy: 0.8042 - val_loss: 0.7633 - val_accuracy: 0.7814\n",
            "Epoch 26/50\n",
            "329/329 - 2s - loss: 0.6567 - accuracy: 0.8064 - val_loss: 0.7264 - val_accuracy: 0.7956\n",
            "Epoch 27/50\n",
            "329/329 - 2s - loss: 0.6440 - accuracy: 0.8099 - val_loss: 0.7616 - val_accuracy: 0.7859\n",
            "Epoch 28/50\n",
            "329/329 - 2s - loss: 0.6320 - accuracy: 0.8132 - val_loss: 0.7115 - val_accuracy: 0.7988\n",
            "Epoch 29/50\n",
            "329/329 - 2s - loss: 0.6254 - accuracy: 0.8153 - val_loss: 0.7569 - val_accuracy: 0.7807\n",
            "Epoch 30/50\n",
            "329/329 - 2s - loss: 0.6133 - accuracy: 0.8200 - val_loss: 0.7310 - val_accuracy: 0.7936\n",
            "Epoch 31/50\n",
            "329/329 - 2s - loss: 0.6035 - accuracy: 0.8230 - val_loss: 0.7319 - val_accuracy: 0.7926\n",
            "Epoch 32/50\n",
            "329/329 - 2s - loss: 0.5989 - accuracy: 0.8224 - val_loss: 0.7569 - val_accuracy: 0.7858\n",
            "Epoch 33/50\n",
            "329/329 - 2s - loss: 0.5927 - accuracy: 0.8249 - val_loss: 0.7085 - val_accuracy: 0.7987\n",
            "Epoch 34/50\n",
            "329/329 - 2s - loss: 0.5811 - accuracy: 0.8292 - val_loss: 0.6949 - val_accuracy: 0.8042\n",
            "Epoch 35/50\n",
            "329/329 - 2s - loss: 0.5825 - accuracy: 0.8271 - val_loss: 0.6718 - val_accuracy: 0.8141\n",
            "Epoch 36/50\n",
            "329/329 - 2s - loss: 0.5694 - accuracy: 0.8302 - val_loss: 0.7118 - val_accuracy: 0.7984\n",
            "Epoch 37/50\n",
            "329/329 - 2s - loss: 0.5607 - accuracy: 0.8341 - val_loss: 0.6920 - val_accuracy: 0.8078\n",
            "Epoch 38/50\n",
            "329/329 - 2s - loss: 0.5529 - accuracy: 0.8370 - val_loss: 0.6696 - val_accuracy: 0.8132\n",
            "Epoch 39/50\n",
            "329/329 - 2s - loss: 0.5457 - accuracy: 0.8397 - val_loss: 0.6627 - val_accuracy: 0.8160\n",
            "Epoch 40/50\n",
            "329/329 - 2s - loss: 0.5418 - accuracy: 0.8409 - val_loss: 0.6750 - val_accuracy: 0.8130\n",
            "Epoch 41/50\n",
            "329/329 - 2s - loss: 0.5439 - accuracy: 0.8382 - val_loss: 0.6959 - val_accuracy: 0.8008\n",
            "Epoch 42/50\n",
            "329/329 - 2s - loss: 0.5318 - accuracy: 0.8424 - val_loss: 0.6800 - val_accuracy: 0.8112\n",
            "Epoch 43/50\n",
            "329/329 - 2s - loss: 0.5209 - accuracy: 0.8457 - val_loss: 0.6632 - val_accuracy: 0.8149\n",
            "Epoch 44/50\n",
            "329/329 - 2s - loss: 0.5186 - accuracy: 0.8465 - val_loss: 0.6849 - val_accuracy: 0.8091\n",
            "Epoch 45/50\n",
            "329/329 - 2s - loss: 0.5126 - accuracy: 0.8506 - val_loss: 0.6789 - val_accuracy: 0.8115\n",
            "Epoch 46/50\n",
            "329/329 - 2s - loss: 0.5075 - accuracy: 0.8513 - val_loss: 0.6858 - val_accuracy: 0.8118\n",
            "Epoch 47/50\n",
            "329/329 - 2s - loss: 0.5063 - accuracy: 0.8512 - val_loss: 0.6508 - val_accuracy: 0.8218\n",
            "Epoch 48/50\n",
            "329/329 - 2s - loss: 0.4959 - accuracy: 0.8551 - val_loss: 0.6806 - val_accuracy: 0.8124\n",
            "Epoch 49/50\n",
            "329/329 - 2s - loss: 0.4958 - accuracy: 0.8547 - val_loss: 0.6712 - val_accuracy: 0.8133\n",
            "Epoch 50/50\n",
            "329/329 - 2s - loss: 0.4843 - accuracy: 0.8571 - val_loss: 0.6673 - val_accuracy: 0.8167\n",
            "1313/1313 [==============================] - 3s 2ms/step - loss: 0.4869 - accuracy: 0.8553\n",
            "Try 9/10: Best_val_acc: [0.48686909675598145, 0.8553095459938049], lr: 0.0002613995299936404, Lambda: 0.0013103269001464436\n",
            "\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(1)\n",
        "tf.random.set_seed(2)\n",
        "for k in range(1,10):\n",
        "    lr = math.pow(10, np.random.uniform(-4.0, -3.0))\n",
        "    Lambda = math.pow(10, np.random.uniform(-4,-2))\n",
        "    best_acc = train_and_test_loop1(50, lr, Lambda, False)\n",
        "    print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 10, best_acc, lr, Lambda))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdrGu7onI0Dw"
      },
      "source": [
        "### Running deep with lr=le-4 and Lambda=1e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEByk7BEI0Dw",
        "outputId": "aaf5c3fe-c5fb-4053-93d4-e2a18c0dd94a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "329/329 - 3s - loss: 2.2264 - accuracy: 0.1867 - val_loss: 2.0457 - val_accuracy: 0.3151\n",
            "Epoch 2/100\n",
            "329/329 - 3s - loss: 1.8452 - accuracy: 0.3932 - val_loss: 1.6337 - val_accuracy: 0.4987\n",
            "Epoch 3/100\n",
            "329/329 - 3s - loss: 1.5272 - accuracy: 0.5334 - val_loss: 1.4110 - val_accuracy: 0.5801\n",
            "Epoch 4/100\n",
            "329/329 - 3s - loss: 1.3492 - accuracy: 0.5956 - val_loss: 1.2868 - val_accuracy: 0.6195\n",
            "Epoch 5/100\n",
            "329/329 - 2s - loss: 1.2391 - accuracy: 0.6299 - val_loss: 1.2053 - val_accuracy: 0.6462\n",
            "Epoch 6/100\n",
            "329/329 - 3s - loss: 1.1594 - accuracy: 0.6572 - val_loss: 1.1330 - val_accuracy: 0.6627\n",
            "Epoch 7/100\n",
            "329/329 - 2s - loss: 1.1033 - accuracy: 0.6721 - val_loss: 1.0763 - val_accuracy: 0.6826\n",
            "Epoch 8/100\n",
            "329/329 - 2s - loss: 1.0553 - accuracy: 0.6882 - val_loss: 1.0530 - val_accuracy: 0.6826\n",
            "Epoch 9/100\n",
            "329/329 - 3s - loss: 1.0164 - accuracy: 0.6972 - val_loss: 1.0356 - val_accuracy: 0.6856\n",
            "Epoch 10/100\n",
            "329/329 - 3s - loss: 0.9837 - accuracy: 0.7077 - val_loss: 0.9839 - val_accuracy: 0.7063\n",
            "Epoch 11/100\n",
            "329/329 - 3s - loss: 0.9548 - accuracy: 0.7143 - val_loss: 0.9866 - val_accuracy: 0.7052\n",
            "Epoch 12/100\n",
            "329/329 - 3s - loss: 0.9314 - accuracy: 0.7213 - val_loss: 0.9398 - val_accuracy: 0.7222\n",
            "Epoch 13/100\n",
            "329/329 - 3s - loss: 0.9073 - accuracy: 0.7294 - val_loss: 0.9614 - val_accuracy: 0.7094\n",
            "Epoch 14/100\n",
            "329/329 - 3s - loss: 0.8873 - accuracy: 0.7327 - val_loss: 0.9085 - val_accuracy: 0.7286\n",
            "Epoch 15/100\n",
            "329/329 - 3s - loss: 0.8714 - accuracy: 0.7385 - val_loss: 0.8927 - val_accuracy: 0.7323\n",
            "Epoch 16/100\n",
            "329/329 - 3s - loss: 0.8474 - accuracy: 0.7464 - val_loss: 0.9044 - val_accuracy: 0.7289\n",
            "Epoch 17/100\n",
            "329/329 - 3s - loss: 0.8323 - accuracy: 0.7495 - val_loss: 0.8623 - val_accuracy: 0.7433\n",
            "Epoch 18/100\n",
            "329/329 - 3s - loss: 0.8176 - accuracy: 0.7559 - val_loss: 0.8554 - val_accuracy: 0.7442\n",
            "Epoch 19/100\n",
            "329/329 - 3s - loss: 0.8051 - accuracy: 0.7562 - val_loss: 0.8492 - val_accuracy: 0.7465\n",
            "Epoch 20/100\n",
            "329/329 - 3s - loss: 0.7920 - accuracy: 0.7612 - val_loss: 0.8328 - val_accuracy: 0.7527\n",
            "Epoch 21/100\n",
            "329/329 - 4s - loss: 0.7785 - accuracy: 0.7658 - val_loss: 0.8232 - val_accuracy: 0.7543\n",
            "Epoch 22/100\n",
            "329/329 - 4s - loss: 0.7588 - accuracy: 0.7710 - val_loss: 0.8097 - val_accuracy: 0.7592\n",
            "Epoch 23/100\n",
            "329/329 - 3s - loss: 0.7473 - accuracy: 0.7738 - val_loss: 0.8104 - val_accuracy: 0.7561\n",
            "Epoch 24/100\n",
            "329/329 - 3s - loss: 0.7361 - accuracy: 0.7770 - val_loss: 0.8275 - val_accuracy: 0.7491\n",
            "Epoch 25/100\n",
            "329/329 - 3s - loss: 0.7221 - accuracy: 0.7824 - val_loss: 0.7898 - val_accuracy: 0.7658\n",
            "Epoch 26/100\n",
            "329/329 - 3s - loss: 0.7170 - accuracy: 0.7831 - val_loss: 0.7695 - val_accuracy: 0.7715\n",
            "Epoch 27/100\n",
            "329/329 - 3s - loss: 0.7028 - accuracy: 0.7876 - val_loss: 0.7749 - val_accuracy: 0.7688\n",
            "Epoch 28/100\n",
            "329/329 - 3s - loss: 0.6898 - accuracy: 0.7923 - val_loss: 0.7669 - val_accuracy: 0.7724\n",
            "Epoch 29/100\n",
            "329/329 - 3s - loss: 0.6849 - accuracy: 0.7933 - val_loss: 0.7907 - val_accuracy: 0.7611\n",
            "Epoch 30/100\n",
            "329/329 - 3s - loss: 0.6702 - accuracy: 0.7984 - val_loss: 0.7513 - val_accuracy: 0.7794\n",
            "Epoch 31/100\n",
            "329/329 - 3s - loss: 0.6627 - accuracy: 0.8000 - val_loss: 0.7969 - val_accuracy: 0.7652\n",
            "Epoch 32/100\n",
            "329/329 - 3s - loss: 0.6557 - accuracy: 0.8024 - val_loss: 0.7456 - val_accuracy: 0.7809\n",
            "Epoch 33/100\n",
            "329/329 - 3s - loss: 0.6407 - accuracy: 0.8072 - val_loss: 0.7337 - val_accuracy: 0.7856\n",
            "Epoch 34/100\n",
            "329/329 - 3s - loss: 0.6339 - accuracy: 0.8076 - val_loss: 0.7382 - val_accuracy: 0.7817\n",
            "Epoch 35/100\n",
            "329/329 - 3s - loss: 0.6282 - accuracy: 0.8121 - val_loss: 0.7416 - val_accuracy: 0.7834\n",
            "Epoch 36/100\n",
            "329/329 - 3s - loss: 0.6195 - accuracy: 0.8137 - val_loss: 0.7240 - val_accuracy: 0.7877\n",
            "Epoch 37/100\n",
            "329/329 - 3s - loss: 0.6134 - accuracy: 0.8169 - val_loss: 0.7292 - val_accuracy: 0.7857\n",
            "Epoch 38/100\n",
            "329/329 - 3s - loss: 0.6029 - accuracy: 0.8200 - val_loss: 0.7005 - val_accuracy: 0.7971\n",
            "Epoch 39/100\n",
            "329/329 - 3s - loss: 0.5969 - accuracy: 0.8201 - val_loss: 0.7169 - val_accuracy: 0.7914\n",
            "Epoch 40/100\n",
            "329/329 - 3s - loss: 0.5857 - accuracy: 0.8254 - val_loss: 0.7046 - val_accuracy: 0.7977\n",
            "Epoch 41/100\n",
            "329/329 - 3s - loss: 0.5814 - accuracy: 0.8251 - val_loss: 0.7215 - val_accuracy: 0.7874\n",
            "Epoch 42/100\n",
            "329/329 - 3s - loss: 0.5727 - accuracy: 0.8280 - val_loss: 0.6974 - val_accuracy: 0.8000\n",
            "Epoch 43/100\n",
            "329/329 - 3s - loss: 0.5688 - accuracy: 0.8291 - val_loss: 0.6929 - val_accuracy: 0.8004\n",
            "Epoch 44/100\n",
            "329/329 - 2s - loss: 0.5598 - accuracy: 0.8305 - val_loss: 0.6981 - val_accuracy: 0.7993\n",
            "Epoch 45/100\n",
            "329/329 - 3s - loss: 0.5514 - accuracy: 0.8338 - val_loss: 0.6890 - val_accuracy: 0.8037\n",
            "Epoch 46/100\n",
            "329/329 - 3s - loss: 0.5458 - accuracy: 0.8375 - val_loss: 0.6809 - val_accuracy: 0.8037\n",
            "Epoch 47/100\n",
            "329/329 - 3s - loss: 0.5459 - accuracy: 0.8376 - val_loss: 0.6811 - val_accuracy: 0.8047\n",
            "Epoch 48/100\n",
            "329/329 - 3s - loss: 0.5344 - accuracy: 0.8398 - val_loss: 0.6742 - val_accuracy: 0.8075\n",
            "Epoch 49/100\n",
            "329/329 - 2s - loss: 0.5320 - accuracy: 0.8408 - val_loss: 0.6671 - val_accuracy: 0.8071\n",
            "Epoch 50/100\n",
            "329/329 - 3s - loss: 0.5266 - accuracy: 0.8430 - val_loss: 0.6820 - val_accuracy: 0.8033\n",
            "Epoch 51/100\n",
            "329/329 - 3s - loss: 0.5220 - accuracy: 0.8433 - val_loss: 0.6985 - val_accuracy: 0.7991\n",
            "Epoch 52/100\n",
            "329/329 - 2s - loss: 0.5193 - accuracy: 0.8455 - val_loss: 0.6591 - val_accuracy: 0.8104\n",
            "Epoch 53/100\n",
            "329/329 - 3s - loss: 0.5059 - accuracy: 0.8477 - val_loss: 0.6610 - val_accuracy: 0.8122\n",
            "Epoch 54/100\n",
            "329/329 - 3s - loss: 0.5070 - accuracy: 0.8477 - val_loss: 0.6962 - val_accuracy: 0.8003\n",
            "Epoch 55/100\n",
            "329/329 - 3s - loss: 0.5024 - accuracy: 0.8483 - val_loss: 0.6573 - val_accuracy: 0.8137\n",
            "Epoch 56/100\n",
            "329/329 - 3s - loss: 0.4949 - accuracy: 0.8510 - val_loss: 0.6690 - val_accuracy: 0.8111\n",
            "Epoch 57/100\n",
            "329/329 - 3s - loss: 0.4887 - accuracy: 0.8522 - val_loss: 0.6749 - val_accuracy: 0.8089\n",
            "Epoch 58/100\n",
            "329/329 - 2s - loss: 0.4824 - accuracy: 0.8565 - val_loss: 0.6752 - val_accuracy: 0.8081\n",
            "Epoch 59/100\n",
            "329/329 - 3s - loss: 0.4843 - accuracy: 0.8533 - val_loss: 0.6520 - val_accuracy: 0.8177\n",
            "Epoch 60/100\n",
            "329/329 - 3s - loss: 0.4750 - accuracy: 0.8565 - val_loss: 0.6574 - val_accuracy: 0.8171\n",
            "Epoch 61/100\n",
            "329/329 - 2s - loss: 0.4707 - accuracy: 0.8580 - val_loss: 0.6563 - val_accuracy: 0.8143\n",
            "Epoch 62/100\n",
            "329/329 - 3s - loss: 0.4650 - accuracy: 0.8600 - val_loss: 0.6385 - val_accuracy: 0.8208\n",
            "Epoch 63/100\n",
            "329/329 - 3s - loss: 0.4644 - accuracy: 0.8613 - val_loss: 0.6714 - val_accuracy: 0.8109\n",
            "Epoch 64/100\n",
            "329/329 - 3s - loss: 0.4604 - accuracy: 0.8616 - val_loss: 0.6484 - val_accuracy: 0.8178\n",
            "Epoch 65/100\n",
            "329/329 - 2s - loss: 0.4583 - accuracy: 0.8635 - val_loss: 0.6706 - val_accuracy: 0.8113\n",
            "Epoch 66/100\n",
            "329/329 - 2s - loss: 0.4542 - accuracy: 0.8626 - val_loss: 0.6411 - val_accuracy: 0.8193\n",
            "Epoch 67/100\n",
            "329/329 - 3s - loss: 0.4523 - accuracy: 0.8647 - val_loss: 0.6325 - val_accuracy: 0.8229\n",
            "Epoch 68/100\n",
            "329/329 - 3s - loss: 0.4425 - accuracy: 0.8673 - val_loss: 0.6501 - val_accuracy: 0.8198\n",
            "Epoch 69/100\n",
            "329/329 - 2s - loss: 0.4387 - accuracy: 0.8689 - val_loss: 0.6442 - val_accuracy: 0.8222\n",
            "Epoch 70/100\n",
            "329/329 - 3s - loss: 0.4354 - accuracy: 0.8701 - val_loss: 0.6550 - val_accuracy: 0.8138\n",
            "Epoch 71/100\n",
            "329/329 - 3s - loss: 0.4364 - accuracy: 0.8681 - val_loss: 0.6448 - val_accuracy: 0.8221\n",
            "Epoch 72/100\n",
            "329/329 - 3s - loss: 0.4316 - accuracy: 0.8696 - val_loss: 0.6345 - val_accuracy: 0.8262\n",
            "Epoch 73/100\n",
            "329/329 - 2s - loss: 0.4250 - accuracy: 0.8732 - val_loss: 0.6449 - val_accuracy: 0.8234\n",
            "Epoch 74/100\n",
            "329/329 - 3s - loss: 0.4222 - accuracy: 0.8736 - val_loss: 0.6444 - val_accuracy: 0.8185\n",
            "Epoch 75/100\n",
            "329/329 - 3s - loss: 0.4142 - accuracy: 0.8766 - val_loss: 0.6677 - val_accuracy: 0.8169\n",
            "Epoch 76/100\n",
            "329/329 - 3s - loss: 0.4129 - accuracy: 0.8768 - val_loss: 0.6550 - val_accuracy: 0.8200\n",
            "Epoch 77/100\n",
            "329/329 - 3s - loss: 0.4075 - accuracy: 0.8782 - val_loss: 0.6514 - val_accuracy: 0.8213\n",
            "Epoch 78/100\n",
            "329/329 - 3s - loss: 0.4078 - accuracy: 0.8785 - val_loss: 0.6249 - val_accuracy: 0.8275\n",
            "Epoch 79/100\n",
            "329/329 - 3s - loss: 0.4034 - accuracy: 0.8781 - val_loss: 0.6263 - val_accuracy: 0.8244\n",
            "Epoch 80/100\n",
            "329/329 - 3s - loss: 0.3998 - accuracy: 0.8806 - val_loss: 0.6348 - val_accuracy: 0.8268\n",
            "Epoch 81/100\n",
            "329/329 - 3s - loss: 0.3963 - accuracy: 0.8812 - val_loss: 0.6537 - val_accuracy: 0.8193\n",
            "Epoch 82/100\n",
            "329/329 - 3s - loss: 0.3919 - accuracy: 0.8810 - val_loss: 0.6498 - val_accuracy: 0.8206\n",
            "Epoch 83/100\n",
            "329/329 - 3s - loss: 0.3910 - accuracy: 0.8830 - val_loss: 0.6323 - val_accuracy: 0.8264\n",
            "Epoch 84/100\n",
            "329/329 - 3s - loss: 0.3855 - accuracy: 0.8839 - val_loss: 0.6409 - val_accuracy: 0.8256\n",
            "Epoch 85/100\n",
            "329/329 - 3s - loss: 0.3844 - accuracy: 0.8843 - val_loss: 0.6112 - val_accuracy: 0.8342\n",
            "Epoch 86/100\n",
            "329/329 - 3s - loss: 0.3772 - accuracy: 0.8873 - val_loss: 0.6476 - val_accuracy: 0.8247\n",
            "Epoch 87/100\n",
            "329/329 - 3s - loss: 0.3730 - accuracy: 0.8890 - val_loss: 0.6503 - val_accuracy: 0.8222\n",
            "Epoch 88/100\n",
            "329/329 - 3s - loss: 0.3777 - accuracy: 0.8878 - val_loss: 0.6314 - val_accuracy: 0.8264\n",
            "Epoch 89/100\n",
            "329/329 - 3s - loss: 0.3682 - accuracy: 0.8905 - val_loss: 0.6293 - val_accuracy: 0.8289\n",
            "Epoch 90/100\n",
            "329/329 - 3s - loss: 0.3637 - accuracy: 0.8892 - val_loss: 0.6209 - val_accuracy: 0.8303\n",
            "Epoch 91/100\n",
            "329/329 - 3s - loss: 0.3688 - accuracy: 0.8892 - val_loss: 0.6576 - val_accuracy: 0.8226\n",
            "Epoch 92/100\n",
            "329/329 - 3s - loss: 0.3603 - accuracy: 0.8924 - val_loss: 0.6343 - val_accuracy: 0.8290\n",
            "Epoch 93/100\n",
            "329/329 - 3s - loss: 0.3588 - accuracy: 0.8931 - val_loss: 0.6204 - val_accuracy: 0.8315\n",
            "Epoch 94/100\n",
            "329/329 - 2s - loss: 0.3541 - accuracy: 0.8941 - val_loss: 0.6273 - val_accuracy: 0.8304\n",
            "Epoch 95/100\n",
            "329/329 - 3s - loss: 0.3528 - accuracy: 0.8945 - val_loss: 0.6250 - val_accuracy: 0.8301\n",
            "Epoch 96/100\n",
            "329/329 - 3s - loss: 0.3547 - accuracy: 0.8940 - val_loss: 0.6436 - val_accuracy: 0.8266\n",
            "Epoch 97/100\n",
            "329/329 - 3s - loss: 0.3491 - accuracy: 0.8943 - val_loss: 0.6440 - val_accuracy: 0.8276\n",
            "Epoch 98/100\n",
            "329/329 - 2s - loss: 0.3412 - accuracy: 0.8980 - val_loss: 0.6263 - val_accuracy: 0.8312\n",
            "Epoch 99/100\n",
            "329/329 - 3s - loss: 0.3457 - accuracy: 0.8955 - val_loss: 0.6380 - val_accuracy: 0.8288\n",
            "Epoch 100/100\n",
            "329/329 - 3s - loss: 0.3405 - accuracy: 0.8976 - val_loss: 0.6267 - val_accuracy: 0.8341\n"
          ]
        }
      ],
      "source": [
        "lr = 1e-4\n",
        "Lambda = 1e-4\n",
        "iterations = 100\n",
        "model = model_nn(iterations,lr,Lambda)\n",
        "history = model.fit(X_train, y_train, epochs = iterations,batch_size=128,validation_data=(X_test,y_test), verbose = 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRvy53DAI0Dy"
      },
      "source": [
        "## Review Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "djVrCdtjI0D1",
        "outputId": "9f872ad0-0b49-4f02-ee51-e533aef1a739"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_28 (Flatten)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_140 (Dense)            (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_141 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_142 (Dense)            (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_143 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_144 (Dense)            (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 347,050\n",
            "Trainable params: 347,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REjp1C-WI0D2"
      },
      "source": [
        "### Cross-checking the prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwWY7nAdI0D3",
        "outputId": "a4eee0ff-56a3-40f3-abad-c73f454cd8be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(10,1))\n",
        "print(\"Label: {}\".format(y_test[704]))\n",
        "plt.imshow(X_test[704].reshape(32,32), cmap='gray')\n",
        "plt.axis('off');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wv2zPOE1I0D6",
        "outputId": "e19b0cad-bc12-4d58-b570-e6b2498e8057"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual label</th>\n",
              "      <th>Predicted</th>\n",
              "      <th>Correctly Predicted %</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>32.727093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>93.193680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>99.905983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>99.999710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>99.997375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>99.958984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>99.171547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>44.189598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>99.936691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>99.994934</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Actual label  Predicted  Correctly Predicted %\n",
              "0             1          1              32.727093\n",
              "1             7          7              93.193680\n",
              "2             2          2              99.905983\n",
              "3             9          9              99.999710\n",
              "4             0          0              99.997375\n",
              "5             9          9              99.958984\n",
              "6             1          1              99.171547\n",
              "7             8          8              44.189598\n",
              "8             4          1              99.936691\n",
              "9             4          4              99.994934"
            ]
          },
          "execution_count": 37,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res_test = model.predict(X_test)\n",
        "res_test = pd.DataFrame({'Actual label':np.argmax(y_test, axis=1),\n",
        "                         'Predicted':np.argmax(res_test, axis=1),\n",
        "                         'Correctly Predicted %':np.max(res_test, axis=1)*100})\n",
        "res_test.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ygPAgQZI0D8"
      },
      "source": [
        "## Conclusion and Interpretation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "TmpvlBewI0D9",
        "outputId": "76b1126f-09e3-46eb-eb70-d60cf34a94d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.6266974806785583\n",
            "Accuracy: 0.8341110944747925\n"
          ]
        }
      ],
      "source": [
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Loss:\", scores[0])\n",
        "print(\"Accuracy:\", scores[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "b6Ab7Pj6I0EA",
        "outputId": "40d58754-1677-4f90-caa2-9989501d92fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training and validation loss')"
            ]
          },
          "execution_count": 39,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "accuracy      = history.history['accuracy']\n",
        "val_accuracy  = history.history['val_accuracy']\n",
        "loss     = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs   = range(len(accuracy)) # Get number of epochs\n",
        "\n",
        "plt.plot  ( epochs, accuracy, label = 'training accuracy' )\n",
        "plt.plot  ( epochs, val_accuracy, label = 'validation accuracy' )\n",
        "plt.title ('Training and validation accuracy')\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.figure()\n",
        "\n",
        "plt.plot  ( epochs, loss, label = 'training loss' )\n",
        "plt.plot  ( epochs, val_loss, label = 'validation loss' )\n",
        "plt.legend(loc = 'upper right')\n",
        "plt.title ('Training and validation loss'   )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F43C9L_QI0EC"
      },
      "source": [
        "There are around 10 classes in the dataset which represent digits from 0-9.\n",
        "\n",
        "We tried training a Neural Network with dense hidden layers of different number of units and are able to achieve a final test accuracy of 83.41 %.\n",
        "\n",
        "Also we notice that after a certain point the model begins to overfit on our dataset as is clear from the plots above where the validation loss begins to increase after certain point and validation accuracy begins to decrease.\n",
        "\n",
        "Thus, with this amount of accuracy we are able to distinguish between the different digits in this dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojTap0ZmI0EC"
      },
      "source": [
        "### Additional hyperparameter check\n",
        "Just wanted to check 'for the above observed learning rate and l2 regularization values'.\n",
        "Is there a better Weight regularization option - using grid search and KerasClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkpP1G4sI0EC"
      },
      "outputs": [],
      "source": [
        "# let's create a function that creates the model (required for KerasClassifier)\n",
        "# while accepting the hyperparameters we want to tune\n",
        "# we also pass some default values such as optimizer=Adam\n",
        "\n",
        "# Compile model\n",
        "\n",
        "def create_model(init_mode,lr,Lambda, verb=True):\n",
        "    np.random.seed(1)\n",
        "    tf.random.set_seed(2)\n",
        "    # define model\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=X_train[0].shape))\n",
        "    model.add(Dense(256 , kernel_initializer=init_mode, activation='relu')) ###Multiple Dense units with Relu activation\n",
        "    model.add(Dense(128 , kernel_initializer=init_mode, activation='relu'))\n",
        "    model.add(Dense(64 , kernel_initializer=init_mode, activation='relu'))\n",
        "    model.add(Dense(32 , kernel_initializer=init_mode, activation='relu'))\n",
        "    model.add(Dense(10 , activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n",
        "    adam = optimizers.Adam(lr=lr, decay=1e-6)\n",
        "    # compile model\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3519
        },
        "id": "AcMjC4OjI0EF",
        "outputId": "e6cb9df5-5e96-4651-fa6e-11984dc31477"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "329/329 - 2s - loss: 2.2382 - accuracy: 0.1864 - val_loss: 2.1040 - val_accuracy: 0.2859\n",
            "Epoch 2/100\n",
            "329/329 - 2s - loss: 1.9254 - accuracy: 0.3512 - val_loss: 1.7418 - val_accuracy: 0.4314\n",
            "Epoch 3/100\n",
            "329/329 - 2s - loss: 1.6464 - accuracy: 0.4532 - val_loss: 1.5494 - val_accuracy: 0.5109\n",
            "Epoch 4/100\n",
            "329/329 - 2s - loss: 1.4810 - accuracy: 0.5294 - val_loss: 1.4055 - val_accuracy: 0.5656\n",
            "Epoch 5/100\n",
            "329/329 - 2s - loss: 1.3729 - accuracy: 0.5750 - val_loss: 1.3335 - val_accuracy: 0.5883\n",
            "Epoch 6/100\n",
            "329/329 - 2s - loss: 1.2832 - accuracy: 0.6114 - val_loss: 1.2476 - val_accuracy: 0.6292\n",
            "Epoch 7/100\n",
            "329/329 - 2s - loss: 1.2108 - accuracy: 0.6352 - val_loss: 1.1880 - val_accuracy: 0.6429\n",
            "Epoch 8/100\n",
            "329/329 - 2s - loss: 1.1485 - accuracy: 0.6572 - val_loss: 1.1356 - val_accuracy: 0.6623\n",
            "Epoch 9/100\n",
            "329/329 - 2s - loss: 1.1015 - accuracy: 0.6703 - val_loss: 1.1288 - val_accuracy: 0.6542\n",
            "Epoch 10/100\n",
            "329/329 - 2s - loss: 1.0571 - accuracy: 0.6848 - val_loss: 1.0648 - val_accuracy: 0.6781\n",
            "Epoch 11/100\n",
            "329/329 - 2s - loss: 1.0171 - accuracy: 0.6961 - val_loss: 1.0282 - val_accuracy: 0.6961\n",
            "Epoch 12/100\n",
            "329/329 - 2s - loss: 0.9862 - accuracy: 0.7055 - val_loss: 0.9925 - val_accuracy: 0.7104\n",
            "Epoch 13/100\n",
            "329/329 - 2s - loss: 0.9591 - accuracy: 0.7127 - val_loss: 0.9974 - val_accuracy: 0.7051\n",
            "Epoch 14/100\n",
            "329/329 - 2s - loss: 0.9336 - accuracy: 0.7202 - val_loss: 0.9598 - val_accuracy: 0.7203\n",
            "Epoch 15/100\n",
            "329/329 - 2s - loss: 0.9166 - accuracy: 0.7243 - val_loss: 0.9296 - val_accuracy: 0.7246\n",
            "Epoch 16/100\n",
            "329/329 - 2s - loss: 0.8893 - accuracy: 0.7348 - val_loss: 0.9653 - val_accuracy: 0.7135\n",
            "Epoch 17/100\n",
            "329/329 - 2s - loss: 0.8698 - accuracy: 0.7400 - val_loss: 0.9129 - val_accuracy: 0.7291\n",
            "Epoch 18/100\n",
            "329/329 - 5s - loss: 0.8543 - accuracy: 0.7448 - val_loss: 0.8919 - val_accuracy: 0.7344\n",
            "Epoch 19/100\n",
            "329/329 - 4s - loss: 0.8387 - accuracy: 0.7495 - val_loss: 0.9144 - val_accuracy: 0.7314\n",
            "Epoch 20/100\n",
            "329/329 - 3s - loss: 0.8291 - accuracy: 0.7539 - val_loss: 0.8992 - val_accuracy: 0.7311\n",
            "Epoch 21/100\n",
            "329/329 - 2s - loss: 0.8172 - accuracy: 0.7566 - val_loss: 0.8552 - val_accuracy: 0.7503\n",
            "Epoch 22/100\n",
            "329/329 - 2s - loss: 0.7970 - accuracy: 0.7626 - val_loss: 0.8575 - val_accuracy: 0.7489\n",
            "Epoch 23/100\n",
            "329/329 - 2s - loss: 0.7852 - accuracy: 0.7648 - val_loss: 0.8324 - val_accuracy: 0.7562\n",
            "Epoch 24/100\n",
            "329/329 - 2s - loss: 0.7769 - accuracy: 0.7667 - val_loss: 0.8677 - val_accuracy: 0.7456\n",
            "Epoch 25/100\n",
            "329/329 - 2s - loss: 0.7631 - accuracy: 0.7714 - val_loss: 0.8266 - val_accuracy: 0.7580\n",
            "Epoch 26/100\n",
            "329/329 - 2s - loss: 0.7559 - accuracy: 0.7746 - val_loss: 0.8354 - val_accuracy: 0.7526\n",
            "Epoch 27/100\n",
            "329/329 - 2s - loss: 0.7445 - accuracy: 0.7751 - val_loss: 0.8093 - val_accuracy: 0.7646\n",
            "Epoch 28/100\n",
            "329/329 - 2s - loss: 0.7312 - accuracy: 0.7821 - val_loss: 0.8116 - val_accuracy: 0.7629\n",
            "Epoch 29/100\n",
            "329/329 - 2s - loss: 0.7283 - accuracy: 0.7813 - val_loss: 0.8364 - val_accuracy: 0.7512\n",
            "Epoch 30/100\n",
            "329/329 - 2s - loss: 0.7143 - accuracy: 0.7856 - val_loss: 0.8031 - val_accuracy: 0.7630\n",
            "Epoch 31/100\n",
            "329/329 - 2s - loss: 0.7101 - accuracy: 0.7886 - val_loss: 0.8081 - val_accuracy: 0.7619\n",
            "Epoch 32/100\n",
            "329/329 - 2s - loss: 0.7014 - accuracy: 0.7902 - val_loss: 0.8004 - val_accuracy: 0.7639\n",
            "Epoch 33/100\n",
            "329/329 - 2s - loss: 0.6902 - accuracy: 0.7933 - val_loss: 0.7739 - val_accuracy: 0.7777\n",
            "Epoch 34/100\n",
            "329/329 - 2s - loss: 0.6816 - accuracy: 0.7952 - val_loss: 0.7849 - val_accuracy: 0.7691\n",
            "Epoch 35/100\n",
            "329/329 - 2s - loss: 0.6749 - accuracy: 0.7978 - val_loss: 0.7800 - val_accuracy: 0.7701\n",
            "Epoch 36/100\n",
            "329/329 - 2s - loss: 0.6665 - accuracy: 0.7993 - val_loss: 0.7536 - val_accuracy: 0.7796\n",
            "Epoch 37/100\n",
            "329/329 - 2s - loss: 0.6607 - accuracy: 0.8019 - val_loss: 0.7670 - val_accuracy: 0.7778\n",
            "Epoch 38/100\n",
            "329/329 - 2s - loss: 0.6515 - accuracy: 0.8045 - val_loss: 0.7443 - val_accuracy: 0.7848\n",
            "Epoch 39/100\n",
            "329/329 - 2s - loss: 0.6435 - accuracy: 0.8068 - val_loss: 0.7256 - val_accuracy: 0.7914\n",
            "Epoch 40/100\n",
            "329/329 - 2s - loss: 0.6352 - accuracy: 0.8095 - val_loss: 0.7367 - val_accuracy: 0.7862\n",
            "Epoch 41/100\n",
            "329/329 - 2s - loss: 0.6302 - accuracy: 0.8115 - val_loss: 0.7296 - val_accuracy: 0.7891\n",
            "Epoch 42/100\n",
            "329/329 - 2s - loss: 0.6249 - accuracy: 0.8128 - val_loss: 0.7434 - val_accuracy: 0.7849\n",
            "Epoch 43/100\n",
            "329/329 - 2s - loss: 0.6174 - accuracy: 0.8139 - val_loss: 0.7551 - val_accuracy: 0.7793\n",
            "Epoch 44/100\n",
            "329/329 - 2s - loss: 0.6116 - accuracy: 0.8173 - val_loss: 0.7379 - val_accuracy: 0.7837\n",
            "Epoch 45/100\n",
            "329/329 - 2s - loss: 0.6066 - accuracy: 0.8187 - val_loss: 0.7430 - val_accuracy: 0.7853\n",
            "Epoch 46/100\n",
            "329/329 - 2s - loss: 0.5987 - accuracy: 0.8210 - val_loss: 0.7173 - val_accuracy: 0.7909\n",
            "Epoch 47/100\n",
            "329/329 - 2s - loss: 0.5968 - accuracy: 0.8221 - val_loss: 0.7406 - val_accuracy: 0.7879\n",
            "Epoch 48/100\n",
            "329/329 - 2s - loss: 0.5862 - accuracy: 0.8241 - val_loss: 0.7142 - val_accuracy: 0.7959\n",
            "Epoch 49/100\n",
            "329/329 - 2s - loss: 0.5867 - accuracy: 0.8234 - val_loss: 0.7075 - val_accuracy: 0.7957\n",
            "Epoch 50/100\n",
            "329/329 - 2s - loss: 0.5766 - accuracy: 0.8255 - val_loss: 0.7087 - val_accuracy: 0.7939\n",
            "Epoch 51/100\n",
            "329/329 - 2s - loss: 0.5761 - accuracy: 0.8268 - val_loss: 0.7281 - val_accuracy: 0.7882\n",
            "Epoch 52/100\n",
            "329/329 - 2s - loss: 0.5684 - accuracy: 0.8290 - val_loss: 0.6928 - val_accuracy: 0.8009\n",
            "Epoch 53/100\n",
            "329/329 - 2s - loss: 0.5641 - accuracy: 0.8305 - val_loss: 0.7018 - val_accuracy: 0.7988\n",
            "Epoch 54/100\n",
            "329/329 - 2s - loss: 0.5578 - accuracy: 0.8326 - val_loss: 0.7026 - val_accuracy: 0.7986\n",
            "Epoch 55/100\n",
            "329/329 - 2s - loss: 0.5505 - accuracy: 0.8355 - val_loss: 0.6787 - val_accuracy: 0.8067\n",
            "Epoch 56/100\n",
            "329/329 - 2s - loss: 0.5483 - accuracy: 0.8348 - val_loss: 0.6852 - val_accuracy: 0.8035\n",
            "Epoch 57/100\n",
            "329/329 - 2s - loss: 0.5457 - accuracy: 0.8360 - val_loss: 0.6916 - val_accuracy: 0.8009\n",
            "Epoch 58/100\n",
            "329/329 - 2s - loss: 0.5348 - accuracy: 0.8397 - val_loss: 0.6715 - val_accuracy: 0.8091\n",
            "Epoch 59/100\n",
            "329/329 - 2s - loss: 0.5366 - accuracy: 0.8400 - val_loss: 0.6690 - val_accuracy: 0.8116\n",
            "Epoch 60/100\n",
            "329/329 - 2s - loss: 0.5285 - accuracy: 0.8408 - val_loss: 0.6872 - val_accuracy: 0.8036\n",
            "Epoch 61/100\n",
            "329/329 - 2s - loss: 0.5250 - accuracy: 0.8436 - val_loss: 0.6774 - val_accuracy: 0.8075\n",
            "Epoch 62/100\n",
            "329/329 - 2s - loss: 0.5209 - accuracy: 0.8443 - val_loss: 0.6683 - val_accuracy: 0.8121\n",
            "Epoch 63/100\n",
            "329/329 - 2s - loss: 0.5176 - accuracy: 0.8437 - val_loss: 0.6696 - val_accuracy: 0.8106\n",
            "Epoch 64/100\n",
            "329/329 - 2s - loss: 0.5144 - accuracy: 0.8451 - val_loss: 0.7126 - val_accuracy: 0.7979\n",
            "Epoch 65/100\n",
            "329/329 - 2s - loss: 0.5096 - accuracy: 0.8463 - val_loss: 0.6992 - val_accuracy: 0.8012\n",
            "Epoch 66/100\n",
            "329/329 - 2s - loss: 0.5028 - accuracy: 0.8485 - val_loss: 0.6515 - val_accuracy: 0.8185\n",
            "Epoch 67/100\n",
            "329/329 - 2s - loss: 0.5019 - accuracy: 0.8486 - val_loss: 0.6986 - val_accuracy: 0.8032\n",
            "Epoch 68/100\n",
            "329/329 - 2s - loss: 0.4977 - accuracy: 0.8501 - val_loss: 0.6513 - val_accuracy: 0.8186\n",
            "Epoch 69/100\n",
            "329/329 - 2s - loss: 0.4946 - accuracy: 0.8517 - val_loss: 0.6713 - val_accuracy: 0.8123\n",
            "Epoch 70/100\n",
            "329/329 - 2s - loss: 0.4923 - accuracy: 0.8520 - val_loss: 0.6496 - val_accuracy: 0.8175\n",
            "Epoch 71/100\n",
            "329/329 - 2s - loss: 0.4873 - accuracy: 0.8524 - val_loss: 0.6549 - val_accuracy: 0.8163\n",
            "Epoch 72/100\n",
            "329/329 - 2s - loss: 0.4861 - accuracy: 0.8539 - val_loss: 0.6601 - val_accuracy: 0.8151\n",
            "Epoch 73/100\n",
            "329/329 - 2s - loss: 0.4826 - accuracy: 0.8557 - val_loss: 0.6369 - val_accuracy: 0.8218\n",
            "Epoch 74/100\n",
            "329/329 - 2s - loss: 0.4763 - accuracy: 0.8575 - val_loss: 0.6672 - val_accuracy: 0.8129\n",
            "Epoch 75/100\n",
            "329/329 - 2s - loss: 0.4686 - accuracy: 0.8591 - val_loss: 0.6763 - val_accuracy: 0.8098\n",
            "Epoch 76/100\n",
            "329/329 - 2s - loss: 0.4687 - accuracy: 0.8589 - val_loss: 0.6868 - val_accuracy: 0.8091\n",
            "Epoch 77/100\n",
            "329/329 - 2s - loss: 0.4644 - accuracy: 0.8612 - val_loss: 0.6625 - val_accuracy: 0.8121\n",
            "Epoch 78/100\n",
            "329/329 - 2s - loss: 0.4634 - accuracy: 0.8611 - val_loss: 0.6443 - val_accuracy: 0.8202\n",
            "Epoch 79/100\n",
            "329/329 - 2s - loss: 0.4579 - accuracy: 0.8625 - val_loss: 0.7026 - val_accuracy: 0.8043\n",
            "Epoch 80/100\n",
            "329/329 - 2s - loss: 0.4613 - accuracy: 0.8588 - val_loss: 0.6578 - val_accuracy: 0.8149\n",
            "Epoch 81/100\n",
            "329/329 - 2s - loss: 0.4539 - accuracy: 0.8626 - val_loss: 0.7202 - val_accuracy: 0.7991\n",
            "Epoch 82/100\n",
            "329/329 - 2s - loss: 0.4504 - accuracy: 0.8651 - val_loss: 0.6787 - val_accuracy: 0.8119\n",
            "Epoch 83/100\n",
            "329/329 - 2s - loss: 0.4506 - accuracy: 0.8640 - val_loss: 0.6417 - val_accuracy: 0.8219\n",
            "Epoch 84/100\n",
            "329/329 - 2s - loss: 0.4438 - accuracy: 0.8661 - val_loss: 0.6475 - val_accuracy: 0.8203\n",
            "Epoch 85/100\n",
            "329/329 - 2s - loss: 0.4393 - accuracy: 0.8672 - val_loss: 0.6412 - val_accuracy: 0.8240\n",
            "Epoch 86/100\n",
            "329/329 - 2s - loss: 0.4387 - accuracy: 0.8669 - val_loss: 0.6659 - val_accuracy: 0.8139\n",
            "Epoch 87/100\n",
            "329/329 - 2s - loss: 0.4346 - accuracy: 0.8691 - val_loss: 0.6690 - val_accuracy: 0.8158\n",
            "Epoch 88/100\n",
            "329/329 - 2s - loss: 0.4325 - accuracy: 0.8718 - val_loss: 0.6625 - val_accuracy: 0.8157\n",
            "Epoch 89/100\n",
            "329/329 - 2s - loss: 0.4317 - accuracy: 0.8697 - val_loss: 0.6704 - val_accuracy: 0.8123\n",
            "Epoch 90/100\n",
            "329/329 - 2s - loss: 0.4252 - accuracy: 0.8719 - val_loss: 0.6351 - val_accuracy: 0.8232\n",
            "Epoch 91/100\n",
            "329/329 - 2s - loss: 0.4292 - accuracy: 0.8706 - val_loss: 0.6313 - val_accuracy: 0.8250\n",
            "Epoch 92/100\n",
            "329/329 - 2s - loss: 0.4226 - accuracy: 0.8730 - val_loss: 0.6300 - val_accuracy: 0.8249\n",
            "Epoch 93/100\n",
            "329/329 - 2s - loss: 0.4181 - accuracy: 0.8743 - val_loss: 0.6522 - val_accuracy: 0.8225\n",
            "Epoch 94/100\n",
            "329/329 - 2s - loss: 0.4197 - accuracy: 0.8742 - val_loss: 0.6427 - val_accuracy: 0.8244\n",
            "Epoch 95/100\n",
            "329/329 - 2s - loss: 0.4073 - accuracy: 0.8781 - val_loss: 0.6581 - val_accuracy: 0.8172\n",
            "Epoch 96/100\n",
            "329/329 - 2s - loss: 0.4149 - accuracy: 0.8730 - val_loss: 0.7032 - val_accuracy: 0.8048\n",
            "Epoch 97/100\n",
            "329/329 - 2s - loss: 0.4119 - accuracy: 0.8746 - val_loss: 0.6322 - val_accuracy: 0.8267\n",
            "Epoch 98/100\n",
            "329/329 - 2s - loss: 0.4027 - accuracy: 0.8783 - val_loss: 0.6395 - val_accuracy: 0.8236\n",
            "Epoch 99/100\n",
            "329/329 - 2s - loss: 0.4026 - accuracy: 0.8793 - val_loss: 0.6524 - val_accuracy: 0.8227\n",
            "Epoch 100/100\n",
            "329/329 - 2s - loss: 0.3963 - accuracy: 0.8799 - val_loss: 0.6474 - val_accuracy: 0.8250\n",
            "CPU times: user 5min 41s, sys: 24 s, total: 6min 5s\n",
            "Wall time: 1h 26s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 100\n",
        "model_CV = KerasClassifier(build_fn=create_model, epochs=epochs,\n",
        "                           batch_size=batch_size, verbose=2)\n",
        "# define the grid search parameters\n",
        "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero',\n",
        "             'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
        "\n",
        "lr = [math.pow(10, np.random.uniform(-4.0, -4.0))]\n",
        "Lambda = [math.pow(10, np.random.uniform(-4,-4))]\n",
        "param_grid = dict(init_mode=init_mode ,lr=lr ,Lambda=Lambda)\n",
        "grid = GridSearchCV(estimator=model_CV, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X_train, y_train , validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "CjLYSW0-I0EG",
        "outputId": "3016cc23-b4e6-434f-ea9f-4011f2621829"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Accuracy for 0.8032142917315165 using {'Lambda': 0.0001, 'init_mode': 'he_uniform', 'lr': 0.0001}\n",
            " mean=0.7454, std=0.007884 using {'Lambda': 0.0001, 'init_mode': 'uniform', 'lr': 0.0001}\n",
            " mean=0.7993, std=0.005469 using {'Lambda': 0.0001, 'init_mode': 'lecun_uniform', 'lr': 0.0001}\n",
            " mean=0.777, std=0.002403 using {'Lambda': 0.0001, 'init_mode': 'normal', 'lr': 0.0001}\n",
            " mean=0.09774, std=0.001852 using {'Lambda': 0.0001, 'init_mode': 'zero', 'lr': 0.0001}\n",
            " mean=0.794, std=0.003252 using {'Lambda': 0.0001, 'init_mode': 'glorot_normal', 'lr': 0.0001}\n",
            " mean=0.8019, std=0.001419 using {'Lambda': 0.0001, 'init_mode': 'glorot_uniform', 'lr': 0.0001}\n",
            " mean=0.7949, std=0.001258 using {'Lambda': 0.0001, 'init_mode': 'he_normal', 'lr': 0.0001}\n",
            " mean=0.8032, std=0.001012 using {'Lambda': 0.0001, 'init_mode': 'he_uniform', 'lr': 0.0001}\n"
          ]
        }
      ],
      "source": [
        "# print results\n",
        "print(f'Best Accuracy for {grid_result.best_score_} using {grid_result.best_params_}')\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f' mean={mean:.4}, std={stdev:.4} using {param}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "McA6SHs8I0EJ",
        "outputId": "57dacdcd-085d-44ce-fc22-275b3fdb9ac2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.6266974806785583\n",
            "Accuracy: 0.8341110944747925\n"
          ]
        }
      ],
      "source": [
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Loss:\", scores[0])\n",
        "print(\"Accuracy:\", scores[1])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "giKxq5xeI0C_",
        "sCViMDYiI0DK",
        "6Rg1JvaWI0Dr",
        "r3vrbSbAI0Ds",
        "nbfugK7CI0Du",
        "ZdrGu7onI0Dw",
        "REjp1C-WI0D2"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}